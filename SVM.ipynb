{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary packages and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in our resampling process, we import the datasets individually according to their non-SMOTEd and SMOTEd datasets, allowing for possible 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1 = pd.read_csv('./smote_train_data/fold_1.csv')\n",
    "fold2 = pd.read_csv('./smote_train_data/fold_2.csv')\n",
    "fold3 = pd.read_csv('./smote_train_data/fold_3.csv')\n",
    "fold4 = pd.read_csv('./smote_train_data/fold_4.csv')\n",
    "fold5 = pd.read_csv('./smote_train_data/fold_5.csv')\n",
    "\n",
    "smote_fold_1 = pd.read_csv('./smote_train_data/smote_fold_1.csv')\n",
    "smote_fold_2 = pd.read_csv('./smote_train_data/smote_fold_2.csv')\n",
    "smote_fold_3 = pd.read_csv('./smote_train_data/smote_fold_3.csv')\n",
    "smote_fold_4 = pd.read_csv('./smote_train_data/smote_fold_4.csv')\n",
    "smote_fold_5 = pd.read_csv('./smote_train_data/smote_fold_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try building a base SVM model with the given dataset first. We utilise SMOTEd folds 1 to 4 to make up the training data, and non-SMOTEd fold 5 as the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_year</th>\n",
       "      <th>creation_month</th>\n",
       "      <th>creation_day</th>\n",
       "      <th>region_101</th>\n",
       "      <th>region_103</th>\n",
       "      <th>region_104</th>\n",
       "      <th>region_105</th>\n",
       "      <th>region_106</th>\n",
       "      <th>region_107</th>\n",
       "      <th>region_199</th>\n",
       "      <th>...</th>\n",
       "      <th>meter_coefficient_50</th>\n",
       "      <th>reading_remark_6</th>\n",
       "      <th>reading_remark_7</th>\n",
       "      <th>reading_remark_8</th>\n",
       "      <th>reading_remark_9</th>\n",
       "      <th>meter_type_0</th>\n",
       "      <th>meter_type_1</th>\n",
       "      <th>is_index_discrepancy_False</th>\n",
       "      <th>is_index_discrepancy_True</th>\n",
       "      <th>fraud_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40951</th>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.051793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.115537</td>\n",
       "      <td>15.111554</td>\n",
       "      <td>34.665339</td>\n",
       "      <td>19.613545</td>\n",
       "      <td>54.223107</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40952</th>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.270349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.719186</td>\n",
       "      <td>26.188954</td>\n",
       "      <td>34.367442</td>\n",
       "      <td>21.811046</td>\n",
       "      <td>56.178488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40953</th>\n",
       "      <td>1984</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.886777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.238548</td>\n",
       "      <td>31.125325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.125325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40954</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.700108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.288482</td>\n",
       "      <td>14.288482</td>\n",
       "      <td>17.638536</td>\n",
       "      <td>17.638536</td>\n",
       "      <td>35.019376</td>\n",
       "      <td>0.257696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40955</th>\n",
       "      <td>1991</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.465940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.795639</td>\n",
       "      <td>2.329699</td>\n",
       "      <td>10.591278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.591278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163828 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       creation_year  creation_month  creation_day  region_101  region_103  \\\n",
       "0               1985               2             5           0           0   \n",
       "1               1996              12            31           0           0   \n",
       "2               1999               9             8           1           0   \n",
       "3               2016               4            25           0           0   \n",
       "4               2008              11            22           1           0   \n",
       "...              ...             ...           ...         ...         ...   \n",
       "40951           2001               5             7           0           0   \n",
       "40952           2005               5            11           0           0   \n",
       "40953           1984              11            21           0           0   \n",
       "40954           2010               6            21           0           0   \n",
       "40955           1991              11            25           0           0   \n",
       "\n",
       "       region_104  region_105  region_106  region_107  region_199  ...  \\\n",
       "0               1           0           0           0           0  ...   \n",
       "1               0           0           0           0           0  ...   \n",
       "2               0           0           0           0           0  ...   \n",
       "3               0           0           0           0           0  ...   \n",
       "4               0           0           0           0           0  ...   \n",
       "...           ...         ...         ...         ...         ...  ...   \n",
       "40951           1           0           0           0           0  ...   \n",
       "40952           0           0           0           0           0  ...   \n",
       "40953           0           0           0           0           0  ...   \n",
       "40954           0           0           0           0           0  ...   \n",
       "40955           0           0           0           0           0  ...   \n",
       "\n",
       "       meter_coefficient_50  reading_remark_6  reading_remark_7  \\\n",
       "0                       0.0         12.000000               0.0   \n",
       "1                       0.0         53.000000               0.0   \n",
       "2                       0.0         19.000000               0.0   \n",
       "3                       0.0          0.000000               0.0   \n",
       "4                       0.0          7.000000               0.0   \n",
       "...                     ...               ...               ...   \n",
       "40951                   0.0         29.051793               0.0   \n",
       "40952                   0.0         20.270349               0.0   \n",
       "40953                   0.0         21.886777               0.0   \n",
       "40954                   0.0         12.700108               0.0   \n",
       "40955                   0.0          3.465940               0.0   \n",
       "\n",
       "       reading_remark_8  reading_remark_9  meter_type_0  meter_type_1  \\\n",
       "0              0.000000          2.000000      8.000000      6.000000   \n",
       "1             10.000000          3.000000     32.000000     34.000000   \n",
       "2             14.000000          1.000000     34.000000      0.000000   \n",
       "3              0.000000          6.000000      6.000000      0.000000   \n",
       "4              7.000000         16.000000     30.000000      0.000000   \n",
       "...                 ...               ...           ...           ...   \n",
       "40951         10.115537         15.111554     34.665339     19.613545   \n",
       "40952          9.719186         26.188954     34.367442     21.811046   \n",
       "40953          9.000000          0.238548     31.125325      0.000000   \n",
       "40954          8.288482         14.288482     17.638536     17.638536   \n",
       "40955          4.795639          2.329699     10.591278      0.000000   \n",
       "\n",
       "       is_index_discrepancy_False  is_index_discrepancy_True  fraud_status  \n",
       "0                       14.000000                   0.000000           0.0  \n",
       "1                       66.000000                   0.000000           0.0  \n",
       "2                       34.000000                   0.000000           0.0  \n",
       "3                        6.000000                   0.000000           0.0  \n",
       "4                       30.000000                   0.000000           0.0  \n",
       "...                           ...                        ...           ...  \n",
       "40951                   54.223107                   0.055777           1.0  \n",
       "40952                   56.178488                   0.000000           1.0  \n",
       "40953                   31.125325                   0.000000           1.0  \n",
       "40954                   35.019376                   0.257696           1.0  \n",
       "40955                   10.591278                   0.000000           1.0  \n",
       "\n",
       "[163828 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_year</th>\n",
       "      <th>creation_month</th>\n",
       "      <th>creation_day</th>\n",
       "      <th>region_101</th>\n",
       "      <th>region_103</th>\n",
       "      <th>region_104</th>\n",
       "      <th>region_105</th>\n",
       "      <th>region_106</th>\n",
       "      <th>region_107</th>\n",
       "      <th>region_199</th>\n",
       "      <th>...</th>\n",
       "      <th>meter_coefficient_50</th>\n",
       "      <th>reading_remark_6</th>\n",
       "      <th>reading_remark_7</th>\n",
       "      <th>reading_remark_8</th>\n",
       "      <th>reading_remark_9</th>\n",
       "      <th>meter_type_0</th>\n",
       "      <th>meter_type_1</th>\n",
       "      <th>is_index_discrepancy_False</th>\n",
       "      <th>is_index_discrepancy_True</th>\n",
       "      <th>fraud_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21673</th>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21674</th>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21675</th>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21676</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21677</th>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21678 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       creation_year  creation_month  creation_day  region_101  region_103  \\\n",
       "0               1989              12            29           0           0   \n",
       "1               1984              11            12           0           0   \n",
       "2               2010               5             5           1           0   \n",
       "3               1998               6            23           1           0   \n",
       "4               1999              12            22           0           0   \n",
       "...              ...             ...           ...         ...         ...   \n",
       "21673           2007               9             6           0           0   \n",
       "21674           2012              10            13           0           0   \n",
       "21675           2018              11            10           0           0   \n",
       "21676           2010               1             8           0           0   \n",
       "21677           2001              11            14           0           0   \n",
       "\n",
       "       region_104  region_105  region_106  region_107  region_199  ...  \\\n",
       "0               0           0           0           0           0  ...   \n",
       "1               1           0           0           0           0  ...   \n",
       "2               0           0           0           0           0  ...   \n",
       "3               0           0           0           0           0  ...   \n",
       "4               0           0           0           0           0  ...   \n",
       "...           ...         ...         ...         ...         ...  ...   \n",
       "21673           0           0           0           0           0  ...   \n",
       "21674           0           0           0           0           0  ...   \n",
       "21675           1           0           0           0           0  ...   \n",
       "21676           0           0           0           1           0  ...   \n",
       "21677           0           0           0           0           0  ...   \n",
       "\n",
       "       meter_coefficient_50  reading_remark_6  reading_remark_7  \\\n",
       "0                       0.0              22.0               0.0   \n",
       "1                       0.0              52.0               0.0   \n",
       "2                       0.0              22.0               0.0   \n",
       "3                       0.0               1.0               0.0   \n",
       "4                       0.0              38.0               0.0   \n",
       "...                     ...               ...               ...   \n",
       "21673                   0.0              12.0               0.0   \n",
       "21674                   0.0               0.0               0.0   \n",
       "21675                   0.0               1.0               0.0   \n",
       "21676                   0.0               5.0               0.0   \n",
       "21677                   0.0              19.0               0.0   \n",
       "\n",
       "       reading_remark_8  reading_remark_9  meter_type_0  meter_type_1  \\\n",
       "0                   5.0              13.0          40.0           0.0   \n",
       "1                  11.0               3.0          35.0          31.0   \n",
       "2                   7.0               0.0          17.0          12.0   \n",
       "3                   1.0               1.0           3.0           0.0   \n",
       "4                  17.0               1.0          34.0          22.0   \n",
       "...                 ...               ...           ...           ...   \n",
       "21673              11.0              12.0          35.0           0.0   \n",
       "21674               0.0               4.0           4.0           0.0   \n",
       "21675               0.0               2.0           3.0           0.0   \n",
       "21676               0.0               0.0           3.0           2.0   \n",
       "21677               5.0              13.0          37.0           0.0   \n",
       "\n",
       "       is_index_discrepancy_False  is_index_discrepancy_True  fraud_status  \n",
       "0                            40.0                        0.0           0.0  \n",
       "1                            66.0                        0.0           1.0  \n",
       "2                            28.0                        1.0           0.0  \n",
       "3                             3.0                        0.0           0.0  \n",
       "4                            56.0                        0.0           1.0  \n",
       "...                           ...                        ...           ...  \n",
       "21673                        35.0                        0.0           0.0  \n",
       "21674                         4.0                        0.0           0.0  \n",
       "21675                         3.0                        0.0           0.0  \n",
       "21676                         5.0                        0.0           0.0  \n",
       "21677                        37.0                        0.0           1.0  \n",
       "\n",
       "[21678 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.concat([smote_fold_1, smote_fold_2, smote_fold_3, smote_fold_4])\n",
    "val_data = fold5\n",
    "\n",
    "display(train_data)\n",
    "display(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling of numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is key especially to SVM models, which utilises distance between data points and decision boundary to determine the hyperplane's position. If features are not scaled, those with larger ranges will dominate the distance calculations, leading to skewed or suboptimal hyperplanes. We perform feature scaling on the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creation_year', 'creation_month', 'creation_day', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_std', 'consumption_level_2_min', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_min', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_min', 'consumption_level_4_max', 'consumption_level_4_median', 'consumption_level_4_sum', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_std', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_mean', 'total_consumption_std', 'total_consumption_min', 'total_consumption_max', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'months_number_median', 'meter_number_count', 'meter_code_count', 'no_of_invoices', 'time_since_last_invoice_mean', 'time_since_last_invoice_std', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'meter_status_2.0', 'meter_status_3.0', 'meter_status_4.0', 'meter_coefficient_0', 'meter_coefficient_2', 'meter_coefficient_3', 'meter_coefficient_4', 'meter_coefficient_10', 'meter_coefficient_11', 'meter_coefficient_20', 'meter_coefficient_30', 'meter_coefficient_33', 'meter_coefficient_40', 'meter_coefficient_50', 'reading_remark_6', 'reading_remark_7', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_False', 'is_index_discrepancy_True']\n"
     ]
    }
   ],
   "source": [
    "numerical_features = train_data.drop(columns=['fraud_status', 'region_101',\n",
    "                   'region_103', 'region_104', 'region_105', 'region_106', 'region_107',\n",
    "                   'region_199', 'region_206', 'region_301', 'region_302', 'region_303',\n",
    "                   'region_304', 'region_305', 'region_306', 'region_307', 'region_308',\n",
    "                   'region_309', 'region_310', 'region_311', 'region_312', 'region_313',\n",
    "                   'region_371', 'region_372', 'region_379', 'region_399', 'district_62',\n",
    "                   'district_63', 'district_69', 'client_catg_11', 'client_catg_12', 'client_catg_51'\n",
    "                   ]).columns\n",
    "\n",
    "numerical_features = list(numerical_features)\n",
    "\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fit the scaler to the numerical features of the train data and perform scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_year</th>\n",
       "      <th>creation_month</th>\n",
       "      <th>creation_day</th>\n",
       "      <th>region_101</th>\n",
       "      <th>region_103</th>\n",
       "      <th>region_104</th>\n",
       "      <th>region_105</th>\n",
       "      <th>region_106</th>\n",
       "      <th>region_107</th>\n",
       "      <th>region_199</th>\n",
       "      <th>...</th>\n",
       "      <th>meter_coefficient_50</th>\n",
       "      <th>reading_remark_6</th>\n",
       "      <th>reading_remark_7</th>\n",
       "      <th>reading_remark_8</th>\n",
       "      <th>reading_remark_9</th>\n",
       "      <th>meter_type_0</th>\n",
       "      <th>meter_type_1</th>\n",
       "      <th>is_index_discrepancy_False</th>\n",
       "      <th>is_index_discrepancy_True</th>\n",
       "      <th>fraud_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.455290</td>\n",
       "      <td>-1.571095</td>\n",
       "      <td>-1.545187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.452078</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-1.206243</td>\n",
       "      <td>-0.888334</td>\n",
       "      <td>-1.160868</td>\n",
       "      <td>-0.462351</td>\n",
       "      <td>-0.961610</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.436198</td>\n",
       "      <td>1.519945</td>\n",
       "      <td>1.699035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>2.007816</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>0.382250</td>\n",
       "      <td>-0.804254</td>\n",
       "      <td>0.318692</td>\n",
       "      <td>1.423188</td>\n",
       "      <td>0.994903</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.158263</td>\n",
       "      <td>0.592633</td>\n",
       "      <td>-1.170854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.032096</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>1.017647</td>\n",
       "      <td>-0.972415</td>\n",
       "      <td>0.441989</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-0.209105</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.416698</td>\n",
       "      <td>-0.952887</td>\n",
       "      <td>0.950368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-1.172047</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-1.206243</td>\n",
       "      <td>-0.552011</td>\n",
       "      <td>-1.284165</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-1.262612</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.675540</td>\n",
       "      <td>1.210841</td>\n",
       "      <td>0.576035</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.752065</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-0.094298</td>\n",
       "      <td>0.288798</td>\n",
       "      <td>0.195396</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-0.359606</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40951</th>\n",
       "      <td>0.027026</td>\n",
       "      <td>-0.643783</td>\n",
       "      <td>-1.295632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>0.570986</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>0.400603</td>\n",
       "      <td>0.214096</td>\n",
       "      <td>0.483006</td>\n",
       "      <td>0.454394</td>\n",
       "      <td>0.551794</td>\n",
       "      <td>-0.046568</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40952</th>\n",
       "      <td>0.397606</td>\n",
       "      <td>-0.643783</td>\n",
       "      <td>-0.796520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>0.044122</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>0.337643</td>\n",
       "      <td>1.145494</td>\n",
       "      <td>0.464641</td>\n",
       "      <td>0.602376</td>\n",
       "      <td>0.625366</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40953</th>\n",
       "      <td>-1.547935</td>\n",
       "      <td>1.210841</td>\n",
       "      <td>0.451257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>0.141103</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>0.223401</td>\n",
       "      <td>-1.036439</td>\n",
       "      <td>0.264770</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-0.317265</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40954</th>\n",
       "      <td>0.860829</td>\n",
       "      <td>-0.334679</td>\n",
       "      <td>0.451257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.410073</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>0.110377</td>\n",
       "      <td>0.144892</td>\n",
       "      <td>-0.566668</td>\n",
       "      <td>0.321396</td>\n",
       "      <td>-0.170751</td>\n",
       "      <td>0.066744</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40955</th>\n",
       "      <td>-0.899421</td>\n",
       "      <td>1.210841</td>\n",
       "      <td>0.950368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.964099</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-0.444459</td>\n",
       "      <td>-0.860613</td>\n",
       "      <td>-1.001120</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-1.089864</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163828 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       creation_year  creation_month  creation_day  region_101  region_103  \\\n",
       "0          -1.455290       -1.571095     -1.545187           0           0   \n",
       "1          -0.436198        1.519945      1.699035           0           0   \n",
       "2          -0.158263        0.592633     -1.170854           1           0   \n",
       "3           1.416698       -0.952887      0.950368           0           0   \n",
       "4           0.675540        1.210841      0.576035           1           0   \n",
       "...              ...             ...           ...         ...         ...   \n",
       "40951       0.027026       -0.643783     -1.295632           0           0   \n",
       "40952       0.397606       -0.643783     -0.796520           0           0   \n",
       "40953      -1.547935        1.210841      0.451257           0           0   \n",
       "40954       0.860829       -0.334679      0.451257           0           0   \n",
       "40955      -0.899421        1.210841      0.950368           0           0   \n",
       "\n",
       "       region_104  region_105  region_106  region_107  region_199  ...  \\\n",
       "0               1           0           0           0           0  ...   \n",
       "1               0           0           0           0           0  ...   \n",
       "2               0           0           0           0           0  ...   \n",
       "3               0           0           0           0           0  ...   \n",
       "4               0           0           0           0           0  ...   \n",
       "...           ...         ...         ...         ...         ...  ...   \n",
       "40951           1           0           0           0           0  ...   \n",
       "40952           0           0           0           0           0  ...   \n",
       "40953           0           0           0           0           0  ...   \n",
       "40954           0           0           0           0           0  ...   \n",
       "40955           0           0           0           0           0  ...   \n",
       "\n",
       "       meter_coefficient_50  reading_remark_6  reading_remark_7  \\\n",
       "0                 -0.002471         -0.452078          -0.03849   \n",
       "1                 -0.002471          2.007816          -0.03849   \n",
       "2                 -0.002471         -0.032096          -0.03849   \n",
       "3                 -0.002471         -1.172047          -0.03849   \n",
       "4                 -0.002471         -0.752065          -0.03849   \n",
       "...                     ...               ...               ...   \n",
       "40951             -0.002471          0.570986          -0.03849   \n",
       "40952             -0.002471          0.044122          -0.03849   \n",
       "40953             -0.002471          0.141103          -0.03849   \n",
       "40954             -0.002471         -0.410073          -0.03849   \n",
       "40955             -0.002471         -0.964099          -0.03849   \n",
       "\n",
       "       reading_remark_8  reading_remark_9  meter_type_0  meter_type_1  \\\n",
       "0             -1.206243         -0.888334     -1.160868     -0.462351   \n",
       "1              0.382250         -0.804254      0.318692      1.423188   \n",
       "2              1.017647         -0.972415      0.441989     -0.866395   \n",
       "3             -1.206243         -0.552011     -1.284165     -0.866395   \n",
       "4             -0.094298          0.288798      0.195396     -0.866395   \n",
       "...                 ...               ...           ...           ...   \n",
       "40951          0.400603          0.214096      0.483006      0.454394   \n",
       "40952          0.337643          1.145494      0.464641      0.602376   \n",
       "40953          0.223401         -1.036439      0.264770     -0.866395   \n",
       "40954          0.110377          0.144892     -0.566668      0.321396   \n",
       "40955         -0.444459         -0.860613     -1.001120     -0.866395   \n",
       "\n",
       "       is_index_discrepancy_False  is_index_discrepancy_True  fraud_status  \n",
       "0                       -0.961610                  -0.077868           0.0  \n",
       "1                        0.994903                  -0.077868           0.0  \n",
       "2                       -0.209105                  -0.077868           0.0  \n",
       "3                       -1.262612                  -0.077868           0.0  \n",
       "4                       -0.359606                  -0.077868           0.0  \n",
       "...                           ...                        ...           ...  \n",
       "40951                    0.551794                  -0.046568           1.0  \n",
       "40952                    0.625366                  -0.077868           1.0  \n",
       "40953                   -0.317265                  -0.077868           1.0  \n",
       "40954                   -0.170751                   0.066744           1.0  \n",
       "40955                   -1.089864                  -0.077868           1.0  \n",
       "\n",
       "[163828 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler with the training data and scale the data.\n",
    "train_data_scaled = train_data.copy()\n",
    "train_data_scaled[numerical_features] = scaler.fit_transform(train_data_scaled[numerical_features])\n",
    "\n",
    "# Display the scaled data\n",
    "display(train_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which, we use the scalar as defined before to transform the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_year</th>\n",
       "      <th>creation_month</th>\n",
       "      <th>creation_day</th>\n",
       "      <th>region_101</th>\n",
       "      <th>region_103</th>\n",
       "      <th>region_104</th>\n",
       "      <th>region_105</th>\n",
       "      <th>region_106</th>\n",
       "      <th>region_107</th>\n",
       "      <th>region_199</th>\n",
       "      <th>...</th>\n",
       "      <th>meter_coefficient_50</th>\n",
       "      <th>reading_remark_6</th>\n",
       "      <th>reading_remark_7</th>\n",
       "      <th>reading_remark_8</th>\n",
       "      <th>reading_remark_9</th>\n",
       "      <th>meter_type_0</th>\n",
       "      <th>meter_type_1</th>\n",
       "      <th>is_index_discrepancy_False</th>\n",
       "      <th>is_index_discrepancy_True</th>\n",
       "      <th>fraud_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.084711</td>\n",
       "      <td>1.519945</td>\n",
       "      <td>1.449480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>0.147896</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-0.411996</td>\n",
       "      <td>0.036555</td>\n",
       "      <td>0.811879</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.547935</td>\n",
       "      <td>1.210841</td>\n",
       "      <td>-0.671743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>1.947819</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>0.541099</td>\n",
       "      <td>-0.804254</td>\n",
       "      <td>0.503637</td>\n",
       "      <td>1.221166</td>\n",
       "      <td>0.994903</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.860829</td>\n",
       "      <td>-0.643783</td>\n",
       "      <td>-1.545187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>0.147896</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-0.094298</td>\n",
       "      <td>-1.056496</td>\n",
       "      <td>-0.606033</td>\n",
       "      <td>-0.058307</td>\n",
       "      <td>-0.434856</td>\n",
       "      <td>0.483305</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.250908</td>\n",
       "      <td>-0.334679</td>\n",
       "      <td>0.700813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-1.112049</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-1.047394</td>\n",
       "      <td>-0.972415</td>\n",
       "      <td>-1.469110</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-1.375487</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.158263</td>\n",
       "      <td>1.519945</td>\n",
       "      <td>0.576035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>1.107855</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>1.494195</td>\n",
       "      <td>-0.972415</td>\n",
       "      <td>0.441989</td>\n",
       "      <td>0.615100</td>\n",
       "      <td>0.618650</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21673</th>\n",
       "      <td>0.582895</td>\n",
       "      <td>0.592633</td>\n",
       "      <td>-1.420409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.452078</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>0.541099</td>\n",
       "      <td>-0.047526</td>\n",
       "      <td>0.503637</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-0.171480</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21674</th>\n",
       "      <td>1.046119</td>\n",
       "      <td>0.901737</td>\n",
       "      <td>-0.546965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-1.172047</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-1.206243</td>\n",
       "      <td>-0.720173</td>\n",
       "      <td>-1.407462</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-1.337862</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21675</th>\n",
       "      <td>1.601988</td>\n",
       "      <td>1.210841</td>\n",
       "      <td>-0.921298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-1.112049</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-1.206243</td>\n",
       "      <td>-0.888334</td>\n",
       "      <td>-1.469110</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-1.375487</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21676</th>\n",
       "      <td>0.860829</td>\n",
       "      <td>-1.880199</td>\n",
       "      <td>-1.170854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.872060</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-1.206243</td>\n",
       "      <td>-1.056496</td>\n",
       "      <td>-1.469110</td>\n",
       "      <td>-0.731714</td>\n",
       "      <td>-1.300237</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21677</th>\n",
       "      <td>0.027026</td>\n",
       "      <td>1.210841</td>\n",
       "      <td>-0.422187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.032096</td>\n",
       "      <td>-0.03849</td>\n",
       "      <td>-0.411996</td>\n",
       "      <td>0.036555</td>\n",
       "      <td>0.626934</td>\n",
       "      <td>-0.866395</td>\n",
       "      <td>-0.096229</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21678 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       creation_year  creation_month  creation_day  region_101  region_103  \\\n",
       "0          -1.084711        1.519945      1.449480           0           0   \n",
       "1          -1.547935        1.210841     -0.671743           0           0   \n",
       "2           0.860829       -0.643783     -1.545187           1           0   \n",
       "3          -0.250908       -0.334679      0.700813           1           0   \n",
       "4          -0.158263        1.519945      0.576035           0           0   \n",
       "...              ...             ...           ...         ...         ...   \n",
       "21673       0.582895        0.592633     -1.420409           0           0   \n",
       "21674       1.046119        0.901737     -0.546965           0           0   \n",
       "21675       1.601988        1.210841     -0.921298           0           0   \n",
       "21676       0.860829       -1.880199     -1.170854           0           0   \n",
       "21677       0.027026        1.210841     -0.422187           0           0   \n",
       "\n",
       "       region_104  region_105  region_106  region_107  region_199  ...  \\\n",
       "0               0           0           0           0           0  ...   \n",
       "1               1           0           0           0           0  ...   \n",
       "2               0           0           0           0           0  ...   \n",
       "3               0           0           0           0           0  ...   \n",
       "4               0           0           0           0           0  ...   \n",
       "...           ...         ...         ...         ...         ...  ...   \n",
       "21673           0           0           0           0           0  ...   \n",
       "21674           0           0           0           0           0  ...   \n",
       "21675           1           0           0           0           0  ...   \n",
       "21676           0           0           0           1           0  ...   \n",
       "21677           0           0           0           0           0  ...   \n",
       "\n",
       "       meter_coefficient_50  reading_remark_6  reading_remark_7  \\\n",
       "0                 -0.002471          0.147896          -0.03849   \n",
       "1                 -0.002471          1.947819          -0.03849   \n",
       "2                 -0.002471          0.147896          -0.03849   \n",
       "3                 -0.002471         -1.112049          -0.03849   \n",
       "4                 -0.002471          1.107855          -0.03849   \n",
       "...                     ...               ...               ...   \n",
       "21673             -0.002471         -0.452078          -0.03849   \n",
       "21674             -0.002471         -1.172047          -0.03849   \n",
       "21675             -0.002471         -1.112049          -0.03849   \n",
       "21676             -0.002471         -0.872060          -0.03849   \n",
       "21677             -0.002471         -0.032096          -0.03849   \n",
       "\n",
       "       reading_remark_8  reading_remark_9  meter_type_0  meter_type_1  \\\n",
       "0             -0.411996          0.036555      0.811879     -0.866395   \n",
       "1              0.541099         -0.804254      0.503637      1.221166   \n",
       "2             -0.094298         -1.056496     -0.606033     -0.058307   \n",
       "3             -1.047394         -0.972415     -1.469110     -0.866395   \n",
       "4              1.494195         -0.972415      0.441989      0.615100   \n",
       "...                 ...               ...           ...           ...   \n",
       "21673          0.541099         -0.047526      0.503637     -0.866395   \n",
       "21674         -1.206243         -0.720173     -1.407462     -0.866395   \n",
       "21675         -1.206243         -0.888334     -1.469110     -0.866395   \n",
       "21676         -1.206243         -1.056496     -1.469110     -0.731714   \n",
       "21677         -0.411996          0.036555      0.626934     -0.866395   \n",
       "\n",
       "       is_index_discrepancy_False  is_index_discrepancy_True  fraud_status  \n",
       "0                        0.016647                  -0.077868           0.0  \n",
       "1                        0.994903                  -0.077868           1.0  \n",
       "2                       -0.434856                   0.483305           0.0  \n",
       "3                       -1.375487                  -0.077868           0.0  \n",
       "4                        0.618650                  -0.077868           1.0  \n",
       "...                           ...                        ...           ...  \n",
       "21673                   -0.171480                  -0.077868           0.0  \n",
       "21674                   -1.337862                  -0.077868           0.0  \n",
       "21675                   -1.375487                  -0.077868           0.0  \n",
       "21676                   -1.300237                  -0.077868           0.0  \n",
       "21677                   -0.096229                  -0.077868           1.0  \n",
       "\n",
       "[21678 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform the validation data with the scaler\n",
    "val_data_scaled = val_data.copy()\n",
    "val_data_scaled[numerical_features] = scaler.transform(val_data_scaled[numerical_features])\n",
    "\n",
    "# Display the scaled data\n",
    "display(val_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the base SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we begin our model building process. As we experiment in this initial process, we will focus on f1-score of the fraud class, since there are downsides to both false positives and false negatives. While recall is more important than precision due to the greater severity in false negatives which is costly for the company, it is important to also minimise false positives as performing investigations on regular customers will incur cost and potentially affect consumer-supplier relations.\n",
    "\n",
    "Firstly, we split our train and validation datasets into their features (X) and target variable (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_scaled.drop(columns=['fraud_status'])\n",
    "y_train = train_data_scaled['fraud_status']\n",
    "\n",
    "X_val = val_data_scaled.drop(columns=['fraud_status'])\n",
    "y_val = val_data_scaled['fraud_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created our base SVM model using a Radial Basis Function (RBF) kernel as it can model non-linear relationships between features. Mapping data into higher-dimensional spaces, it allows for separation of classes that are not linearly separable.\n",
    "\n",
    "Looking at the classificaiton report of the base model, we notice that the model performs extremely well in predicting the majority class, with high evaluation scores for non-frauds. However, it performs poorly in predicting frauds. The f1-score for fraud class is 0.26. The accuracy is very high at 0.94, but this is attributed to the imbalance in classes for the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.36      0.20      0.26      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.66      0.59      0.61     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an SVM model with default hyperparameters\n",
    "svm_model = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the validation data\n",
    "val_predictions = svm_model.predict(X_val)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Validation data classification report: \")\n",
    "print(classification_report(y_val, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[20063   415]\n",
      " [  963   237]]\n"
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "print(\"Confusion matrix: \")\n",
    "print(confusion_matrix(y_val, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ROC-AUC Score however, is pretty decent at 0.80. It achieves a decent trade-off between minimizing false positives and false negatives across thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: \n",
      "0.8018973207018916\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display ROC-AUC score\n",
    "val_probabilities = svm_model.decision_function(X_val)\n",
    "roc_auc = roc_auc_score(y_val, val_probabilities)\n",
    "\n",
    "print(\"ROC-AUC score: \")\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_val, val_probabilities)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for baseline SVM model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our initial base model comprised of all 102 features, thers is a possibility of curse of dimensionality. Hence, we experiment with PCA to consider if training an SVM model with principle components might be more meaningful at separating the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "PCA(random_state=42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the PCA\n",
    "pca = PCA(random_state=42)\n",
    "\n",
    "# Fit the PCA with the training data\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the graph of Cumulative explained variance against no. of components, we observe that the cumulative explained variance of appears to increase steadily from 0.6 to 0.9. 40 components make up 95% of the variance, which is a big drop compared to the original 102 features. We then transform our train and validation features according to these principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "# Plot the cumulative explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: \n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Select the number of components that explain 95% of the variance\n",
    "n_components = len(cumulative_explained_variance[cumulative_explained_variance < 0.95])\n",
    "print(\"Number of components: \")\n",
    "print(n_components)\n",
    "\n",
    "# Fit PCA with the optimal number of components\n",
    "pca_optimal = PCA(n_components=n_components, random_state=42)\n",
    "X_train_reduced = pca_optimal.fit_transform(X_train)\n",
    "X_val_reduced = pca_optimal.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which, we retrain our base model again using the new reduced train datasets, and validating it against the reduced validation dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVM model with the reduced data\n",
    "svm_model_reduced = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "svm_model_reduced.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall of fraud class has risen drastically, but at the expense of precision for the fraud class. Here, we observe the precision recall trade-off firsthand. There is also a drop in accuracy and there are many more false positives. However, f1-score of the fraud class did not really improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data classification report (PCA): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.82      0.89     20478\n",
      "         1.0       0.17      0.63      0.27      1200\n",
      "\n",
      "    accuracy                           0.81     21678\n",
      "   macro avg       0.57      0.73      0.58     21678\n",
      "weighted avg       0.93      0.81      0.85     21678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the validation data\n",
    "val_predictions_reduced = svm_model_reduced.predict(X_val_reduced)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Validation data classification report (PCA): \")\n",
    "print(classification_report(y_val, val_predictions_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (PCA): \n",
      "[[16717  3761]\n",
      " [  439   761]]\n"
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "print(\"Confusion matrix (PCA): \")\n",
    "print(confusion_matrix(y_val, val_predictions_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ROC-AUC score is observed to be approximately the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: \n",
      "0.8017220309600548\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display ROC-AUC score\n",
    "val_probabilities_reduced = svm_model_reduced.decision_function(X_val_reduced)\n",
    "roc_auc = roc_auc_score(y_val, val_probabilities_reduced)\n",
    "\n",
    "print(\"ROC-AUC score: \")\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_val, val_probabilities_reduced)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for baseline SVM model with PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimenting with a base model and PCA, we move onto explore other methods of model improvement.\n",
    "\n",
    "We tried two things in order:\n",
    "1. Feature Selection\n",
    "- LightGBM Feature Importance Test\n",
    "- Recursive Feature Elimination (RFE) using LightGBM and 5-fold cross validation.\n",
    "2. After selecting n best features, we conducted hyperparameter tuning with 5-fold cross validation.\n",
    "\n",
    "We used optuna to streamline our process of doing these checks to reduce total computational time and maximise efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we conduct Feature Selection. THis is important in reducing the dimensionality of the dataset by identifying and retaining the most relevant features for the task, reducing risk of noise, improve model interpretability, and reduce overfitting. This is especially so for SVM that is sensitive to irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Feature importance test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM is a gradient-boosting framework that provides a feature importance score for each feature, based on its contribution to the model's predictive performance. In this run, we utilise the defined train & validation data from before, with scaled smote_fold 1 to 4 as train data and scaled fold 5 as the test data. We use LGBM because its tree structure evaluates feature splits and their contributions to reducing error, and for its methods of leaf-wise tree growth. This allows it to grow deeper trees selectively and reduces computational time significantly, which is more suited for our large dataset and high dimensional feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_feature_importance_selection(X_train, y_train, trial_number):\n",
    "    # Train LightGBM on all features\n",
    "    print(f\"[Trial {trial_number}] Training LightGBM on all features for importance ranking...\")\n",
    "    lgbm = LGBMClassifier(random_state=42, class_weight='balanced', n_jobs=-1, verbose=-1)\n",
    "    lgbm.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importance and rank features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': lgbm.feature_importances_\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    return feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    # Get `k` from the trial\n",
    "    k = trial.suggest_int('k', 1, X_train.shape[1], step=2)\n",
    "    print(f\"\\n[Trial {trial.number}] Evaluating Top {k} Features...\")\n",
    "\n",
    "    # Get feature importance and select top `k` features\n",
    "    feature_importance = perform_feature_importance_selection(X_train, y_train, trial.number)\n",
    "    selected_features = feature_importance['feature'].iloc[:k].tolist()\n",
    "    print(f\"[Trial {trial.number}] Selected Features: {selected_features}\")\n",
    "\n",
    "    # Subset the dataset\n",
    "    X_train_reduced = X_train[selected_features]\n",
    "    X_val_reduced = X_val[selected_features]\n",
    "\n",
    "    # Train LightGBM on reduced dataset\n",
    "    print(f\"[Trial {trial.number}] Training LightGBM on Top {k} Features...\")\n",
    "    lgbm = LGBMClassifier(random_state=42, class_weight='balanced', n_jobs=-1, verbose=-1)\n",
    "    lgbm.fit(X_train_reduced, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    print(f\"[Trial {trial.number}] Evaluating on validation set...\")\n",
    "    val_predictions = lgbm.predict(X_val_reduced)\n",
    "    f1 = f1_score(y_val, val_predictions, pos_label=1.0)\n",
    "    print(f\"[Trial {trial.number}] F1-Score with Top {k} Features: {f1:.4f}\")\n",
    "\n",
    "    # Print Classification Report\n",
    "    print(f\"[Trial {trial.number}] Classification Report:\\n\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "\n",
    "    # Log selected features for this trial\n",
    "    trial.set_user_attr(\"selected_features\", selected_features)\n",
    "\n",
    "    return f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:09:25,776] A new study created in memory with name: feature_importance_study\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the search space for `k`\n",
    "search_space = {'k': list(range(1, X_train.shape[1] + 1, 2))}  # Step size = 2\n",
    "\n",
    "# Use GridSampler for deterministic search\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler, study_name='feature_importance_study')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 0] Evaluating Top 59 Features...\n",
      "[Trial 0] Training LightGBM on all features for importance ranking...\n",
      "\n",
      "[Trial 1] Evaluating Top 23 Features...\n",
      "[Trial 1] Training LightGBM on all features for importance ranking...\n",
      "\n",
      "[Trial 2] Evaluating Top 21 Features...\n",
      "[Trial 2] Training LightGBM on all features for importance ranking...\n",
      "\n",
      "[Trial 3] Evaluating Top 45 Features...\n",
      "[Trial 3] Training LightGBM on all features for importance ranking...\n",
      "\n",
      "[Trial 4] Evaluating Top 5 Features...\n",
      "[Trial 4] Training LightGBM on all features for importance ranking...\n",
      "[Trial 3] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309']\n",
      "[Trial 1] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean']\n",
      "[Trial 4] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year']\n",
      "[Trial 0] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304']\n",
      "[Trial 4] Training LightGBM on Top 5 Features...\n",
      "[Trial 1] Training LightGBM on Top 23 Features...\n",
      "[Trial 2] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean']\n",
      "[Trial 3] Training LightGBM on Top 45 Features...\n",
      "[Trial 0] Training LightGBM on Top 59 Features...\n",
      "[Trial 2] Training LightGBM on Top 21 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:09:35,959] Trial 4 finished with value: 0.016142050040355124 and parameters: {'k': 5}. Best is trial 4 with value: 0.016142050040355124.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 4] Evaluating on validation set...\n",
      "[Trial 4] F1-Score with Top 5 Features: 0.0161\n",
      "[Trial 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     20478\n",
      "         1.0       0.26      0.01      0.02      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.60      0.50      0.49     21678\n",
      "weighted avg       0.91      0.94      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 5] Evaluating Top 57 Features...\n",
      "[Trial 5] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:36,410] Trial 1 finished with value: 0.15807560137457044 and parameters: {'k': 23}. Best is trial 1 with value: 0.15807560137457044.\n",
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:36,420] Trial 2 finished with value: 0.15912208504801098 and parameters: {'k': 21}. Best is trial 2 with value: 0.15912208504801098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 2] Evaluating on validation set...\n",
      "[Trial 1] Evaluating on validation set...\n",
      "[Trial 1] F1-Score with Top 23 Features: 0.1581\n",
      "[Trial 1] Classification Report:\n",
      "\n",
      "[Trial 2] F1-Score with Top 21 Features: 0.1591\n",
      "[Trial 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.45      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.54      0.56     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 6] Evaluating Top 91 Features...\n",
      "[Trial 6] Training LightGBM on all features for importance ranking...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.45      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.54      0.56     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 7] Evaluating Top 65 Features...\n",
      "[Trial 7] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:37,067] Trial 3 finished with value: 0.19223173140223832 and parameters: {'k': 45}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 3] Evaluating on validation set...\n",
      "[Trial 3] F1-Score with Top 45 Features: 0.1922\n",
      "[Trial 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.12      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.56      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 8] Evaluating Top 53 Features...\n",
      "[Trial 8] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:37,366] Trial 0 finished with value: 0.1629327902240326 and parameters: {'k': 59}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Evaluating on validation set...\n",
      "[Trial 0] F1-Score with Top 59 Features: 0.1629\n",
      "[Trial 0] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.44      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.69      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 9] Evaluating Top 9 Features...\n",
      "[Trial 9] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 5] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std']\n",
      "[Trial 5] Training LightGBM on Top 57 Features...\n",
      "[Trial 6] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30', 'meter_coefficient_10', 'meter_coefficient_11']\n",
      "[Trial 6] Training LightGBM on Top 91 Features...\n",
      "[Trial 8] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311']\n",
      "[Trial 8] Training LightGBM on Top 53 Features...\n",
      "[Trial 9] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min']\n",
      "[Trial 9] Training LightGBM on Top 9 Features...\n",
      "[Trial 7] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313']\n",
      "[Trial 7] Training LightGBM on Top 65 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:09:45,940] Trial 9 finished with value: 0.05500381970970206 and parameters: {'k': 9}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 9] Evaluating on validation set...\n",
      "[Trial 9] F1-Score with Top 9 Features: 0.0550\n",
      "[Trial 9] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     20478\n",
      "         1.0       0.33      0.03      0.06      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.64      0.51      0.51     21678\n",
      "weighted avg       0.91      0.94      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 10] Evaluating Top 67 Features...\n",
      "[Trial 10] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:46,667] Trial 8 finished with value: 0.1732706514439221 and parameters: {'k': 53}. Best is trial 3 with value: 0.19223173140223832.\n",
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:46,700] Trial 6 finished with value: 0.1800818553888131 and parameters: {'k': 91}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 8] Evaluating on validation set...\n",
      "[Trial 6] Evaluating on validation set...\n",
      "[Trial 8] F1-Score with Top 53 Features: 0.1733\n",
      "[Trial 8] Classification Report:\n",
      "\n",
      "[Trial 6] F1-Score with Top 91 Features: 0.1801\n",
      "[Trial 6] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.45      0.11      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 11] Evaluating Top 83 Features...\n",
      "[Trial 11] Training LightGBM on all features for importance ranking...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 12] Evaluating Top 55 Features...\n",
      "[Trial 12] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:48,144] Trial 5 finished with value: 0.168135593220339 and parameters: {'k': 57}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 5] Evaluating on validation set...\n",
      "[Trial 5] F1-Score with Top 57 Features: 0.1681\n",
      "[Trial 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.45      0.10      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 13] Evaluating Top 71 Features...\n",
      "[Trial 13] Training LightGBM on all features for importance ranking...\n",
      "[Trial 7] Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:48,350] Trial 7 finished with value: 0.15955983493810177 and parameters: {'k': 65}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 7] F1-Score with Top 65 Features: 0.1596\n",
      "[Trial 7] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.54      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 14] Evaluating Top 69 Features...\n",
      "[Trial 14] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 10] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307']\n",
      "[Trial 10] Training LightGBM on Top 67 Features...\n",
      "[Trial 11] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median']\n",
      "[Trial 12] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min']\n",
      "[Trial 11] Training LightGBM on Top 83 Features...\n",
      "[Trial 12] Training LightGBM on Top 55 Features...\n",
      "[Trial 14] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12']\n",
      "[Trial 14] Training LightGBM on Top 69 Features...\n",
      "[Trial 13] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min']\n",
      "[Trial 13] Training LightGBM on Top 71 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:09:56,862] Trial 10 finished with value: 0.17598908594815826 and parameters: {'k': 67}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 10] Evaluating on validation set...\n",
      "[Trial 10] F1-Score with Top 67 Features: 0.1760\n",
      "[Trial 10] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.48      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 15] Evaluating Top 15 Features...\n",
      "[Trial 15] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:57,526] Trial 12 finished with value: 0.17532029669588672 and parameters: {'k': 55}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 12] Evaluating on validation set...\n",
      "[Trial 12] F1-Score with Top 55 Features: 0.1753\n",
      "[Trial 12] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 16] Evaluating Top 29 Features...\n",
      "[Trial 16] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:57,805] Trial 11 finished with value: 0.1800818553888131 and parameters: {'k': 83}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 11] Evaluating on validation set...\n",
      "[Trial 11] F1-Score with Top 83 Features: 0.1801\n",
      "[Trial 11] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 17] Evaluating Top 93 Features...\n",
      "[Trial 17] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:09:59,206] Trial 14 finished with value: 0.16928327645051194 and parameters: {'k': 69}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 14] Evaluating on validation set...\n",
      "[Trial 14] F1-Score with Top 69 Features: 0.1693\n",
      "[Trial 14] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.47      0.10      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 18] Evaluating Top 37 Features...\n",
      "[Trial 18] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:00,930] Trial 13 finished with value: 0.1702127659574468 and parameters: {'k': 71}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 13] Evaluating on validation set...\n",
      "[Trial 13] F1-Score with Top 71 Features: 0.1702\n",
      "[Trial 13] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.48      0.10      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 19] Evaluating Top 97 Features...\n",
      "[Trial 19] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 15] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median']\n",
      "[Trial 15] Training LightGBM on Top 15 Features...\n",
      "[Trial 16] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0']\n",
      "[Trial 16] Training LightGBM on Top 29 Features...\n",
      "[Trial 17] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30', 'meter_coefficient_10', 'meter_coefficient_11', 'meter_coefficient_4', 'meter_coefficient_3']\n",
      "[Trial 17] Training LightGBM on Top 93 Features...\n",
      "[Trial 18] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum']\n",
      "[Trial 18] Training LightGBM on Top 37 Features...\n",
      "[Trial 19] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30', 'meter_coefficient_10', 'meter_coefficient_11', 'meter_coefficient_4', 'meter_coefficient_3', 'meter_coefficient_2', 'meter_coefficient_0', 'meter_status_4.0', 'meter_status_3.0']\n",
      "[Trial 19] Training LightGBM on Top 97 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:10:07,364] Trial 15 finished with value: 0.1394395078605605 and parameters: {'k': 15}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 15] Evaluating on validation set...\n",
      "[Trial 15] F1-Score with Top 15 Features: 0.1394\n",
      "[Trial 15] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.39      0.09      0.14      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.67      0.54      0.55     21678\n",
      "weighted avg       0.92      0.94      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 20] Evaluating Top 85 Features...\n",
      "[Trial 20] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:08,056] Trial 16 finished with value: 0.1748107364074329 and parameters: {'k': 29}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 16] Evaluating on validation set...\n",
      "[Trial 16] F1-Score with Top 29 Features: 0.1748\n",
      "[Trial 16] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.73      0.55      0.57     21678\n",
      "weighted avg       0.93      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 21] Evaluating Top 31 Features...\n",
      "[Trial 21] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:08,808] Trial 17 finished with value: 0.1800818553888131 and parameters: {'k': 93}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 17] Evaluating on validation set...\n",
      "[Trial 17] F1-Score with Top 93 Features: 0.1801\n",
      "[Trial 17] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 22] Evaluating Top 63 Features...\n",
      "[Trial 22] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:09,955] Trial 18 finished with value: 0.18229854689564068 and parameters: {'k': 37}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 18] Evaluating on validation set...\n",
      "[Trial 18] F1-Score with Top 37 Features: 0.1823\n",
      "[Trial 18] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.44      0.12      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.69      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 23] Evaluating Top 61 Features...\n",
      "[Trial 23] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:11,856] Trial 19 finished with value: 0.16175462645647704 and parameters: {'k': 97}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 19] Evaluating on validation set...\n",
      "[Trial 19] F1-Score with Top 97 Features: 0.1618\n",
      "[Trial 19] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 24] Evaluating Top 33 Features...\n",
      "[Trial 24] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 20] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20']\n",
      "[Trial 20] Training LightGBM on Top 85 Features...\n",
      "[Trial 21] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104']\n",
      "[Trial 21] Training LightGBM on Top 31 Features...\n",
      "[Trial 22] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min']\n",
      "[Trial 22] Training LightGBM on Top 63 Features...\n",
      "[Trial 23] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302']\n",
      "[Trial 23] Training LightGBM on Top 61 Features...\n",
      "[Trial 24] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301']\n",
      "[Trial 24] Training LightGBM on Top 33 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:10:18,517] Trial 20 finished with value: 0.1800818553888131 and parameters: {'k': 85}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 20] Evaluating on validation set...\n",
      "[Trial 20] F1-Score with Top 85 Features: 0.1801\n",
      "[Trial 20] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 25] Evaluating Top 87 Features...\n",
      "[Trial 25] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:19,863] Trial 21 finished with value: 0.18508655126498003 and parameters: {'k': 31}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 21] Evaluating on validation set...\n",
      "[Trial 21] F1-Score with Top 31 Features: 0.1851\n",
      "[Trial 21] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.12      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 26] Evaluating Top 41 Features...\n",
      "[Trial 26] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:20,369] Trial 23 finished with value: 0.17962466487935658 and parameters: {'k': 61}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 23] Evaluating on validation set...\n",
      "[Trial 23] F1-Score with Top 61 Features: 0.1796\n",
      "[Trial 23] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 27] Evaluating Top 101 Features...\n",
      "[Trial 27] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:21,041] Trial 22 finished with value: 0.17432432432432432 and parameters: {'k': 63}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 22] Evaluating on validation set...\n",
      "[Trial 22] F1-Score with Top 63 Features: 0.1743\n",
      "[Trial 22] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.11      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 28] Evaluating Top 17 Features...\n",
      "[Trial 28] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:22,631] Trial 24 finished with value: 0.17940199335548174 and parameters: {'k': 33}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 24] Evaluating on validation set...\n",
      "[Trial 24] F1-Score with Top 33 Features: 0.1794\n",
      "[Trial 24] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.44      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 29] Evaluating Top 27 Features...\n",
      "[Trial 29] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 25] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40']\n",
      "[Trial 25] Training LightGBM on Top 87 Features...\n",
      "[Trial 27] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30', 'meter_coefficient_10', 'meter_coefficient_11', 'meter_coefficient_4', 'meter_coefficient_3', 'meter_coefficient_2', 'meter_coefficient_0', 'meter_status_4.0', 'meter_status_3.0', 'meter_status_2.0', 'consumption_level_4_min', 'region_199', 'region_206']\n",
      "[Trial 27] Training LightGBM on Top 101 Features...\n",
      "[Trial 28] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max']\n",
      "[Trial 28] Training LightGBM on Top 17 Features...\n",
      "[Trial 26] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105']\n",
      "[Trial 26] Training LightGBM on Top 41 Features...\n",
      "[Trial 29] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean']\n",
      "[Trial 29] Training LightGBM on Top 27 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:10:29,489] Trial 25 finished with value: 0.1800818553888131 and parameters: {'k': 87}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 25] Evaluating on validation set...\n",
      "[Trial 25] F1-Score with Top 87 Features: 0.1801\n",
      "[Trial 25] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 30] Evaluating Top 51 Features...\n",
      "[Trial 30] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:30,552] Trial 28 finished with value: 0.14744027303754267 and parameters: {'k': 17}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 28] Evaluating on validation set...\n",
      "[Trial 28] F1-Score with Top 17 Features: 0.1474\n",
      "[Trial 28] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.41      0.09      0.15      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.54      0.56     21678\n",
      "weighted avg       0.92      0.94      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 31] Evaluating Top 11 Features...\n",
      "[Trial 31] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:31,770] Trial 26 finished with value: 0.18169672678690715 and parameters: {'k': 41}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 26] Evaluating on validation set...\n",
      "[Trial 26] F1-Score with Top 41 Features: 0.1817\n",
      "[Trial 26] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 32] Evaluating Top 35 Features...\n",
      "[Trial 32] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:32,125] Trial 29 finished with value: 0.16884008236101578 and parameters: {'k': 27}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 29] Evaluating on validation set...\n",
      "[Trial 29] F1-Score with Top 27 Features: 0.1688\n",
      "[Trial 29] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.48      0.10      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 33] Evaluating Top 75 Features...\n",
      "[Trial 33] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:32,987] Trial 27 finished with value: 0.1800818553888131 and parameters: {'k': 101}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 27] Evaluating on validation set...\n",
      "[Trial 27] F1-Score with Top 101 Features: 0.1801\n",
      "[Trial 27] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 34] Evaluating Top 81 Features...\n",
      "[Trial 34] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 30] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11']\n",
      "[Trial 30] Training LightGBM on Top 51 Features...\n",
      "[Trial 31] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9']\n",
      "[Trial 31] Training LightGBM on Top 11 Features...\n",
      "[Trial 32] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103']\n",
      "[Trial 32] Training LightGBM on Top 35 Features...\n",
      "[Trial 33] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False']\n",
      "[Trial 33] Training LightGBM on Top 75 Features...\n",
      "[Trial 34] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min']\n",
      "[Trial 34] Training LightGBM on Top 81 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:10:40,118] Trial 30 finished with value: 0.17828418230563003 and parameters: {'k': 51}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 30] Evaluating on validation set...\n",
      "[Trial 30] F1-Score with Top 51 Features: 0.1783\n",
      "[Trial 30] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 35] Evaluating Top 3 Features...\n",
      "[Trial 35] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:40,786] Trial 31 finished with value: 0.07196401799100449 and parameters: {'k': 11}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 31] Evaluating on validation set...\n",
      "[Trial 31] F1-Score with Top 11 Features: 0.0720\n",
      "[Trial 31] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     20478\n",
      "         1.0       0.36      0.04      0.07      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.65      0.52      0.52     21678\n",
      "weighted avg       0.91      0.94      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 36] Evaluating Top 25 Features...\n",
      "[Trial 36] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:42,449] Trial 32 finished with value: 0.17572099262240107 and parameters: {'k': 35}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 32] Evaluating on validation set...\n",
      "[Trial 32] F1-Score with Top 35 Features: 0.1757\n",
      "[Trial 32] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.45      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 37] Evaluating Top 77 Features...\n",
      "[Trial 37] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:43,561] Trial 34 finished with value: 0.15470383275261324 and parameters: {'k': 81}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 34] Evaluating on validation set...\n",
      "[Trial 34] F1-Score with Top 81 Features: 0.1547\n",
      "[Trial 34] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.47      0.09      0.15      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.54      0.56     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 38] Evaluating Top 49 Features...\n",
      "[Trial 38] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:44,732] Trial 33 finished with value: 0.15934065934065933 and parameters: {'k': 75}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 33] Evaluating on validation set...\n",
      "[Trial 33] F1-Score with Top 75 Features: 0.1593\n",
      "[Trial 33] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.45      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.54      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 39] Evaluating Top 13 Features...\n",
      "[Trial 39] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 35] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max']\n",
      "[Trial 35] Training LightGBM on Top 3 Features...\n",
      "[Trial 36] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean']\n",
      "[Trial 36] Training LightGBM on Top 25 Features...\n",
      "[Trial 37] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum']\n",
      "[Trial 37] Training LightGBM on Top 77 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:10:50,687] Trial 35 finished with value: 0.14562002275312855 and parameters: {'k': 3}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 35] Evaluating on validation set...\n",
      "[Trial 35] F1-Score with Top 3 Features: 0.1456\n",
      "[Trial 35] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.96     20478\n",
      "         1.0       0.23      0.11      0.15      1200\n",
      "\n",
      "    accuracy                           0.93     21678\n",
      "   macro avg       0.59      0.54      0.55     21678\n",
      "weighted avg       0.91      0.93      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 40] Evaluating Top 47 Features...\n",
      "[Trial 40] Training LightGBM on all features for importance ranking...\n",
      "[Trial 38] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max']\n",
      "[Trial 38] Training LightGBM on Top 49 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:51,687] Trial 36 finished with value: 0.16290212183436004 and parameters: {'k': 25}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 36] Evaluating on validation set...\n",
      "[Trial 36] F1-Score with Top 25 Features: 0.1629\n",
      "[Trial 36] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 41] Evaluating Top 73 Features...\n",
      "[Trial 41] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 39] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum']\n",
      "[Trial 39] Training LightGBM on Top 13 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:10:53,885] Trial 37 finished with value: 0.1623108665749656 and parameters: {'k': 77}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 37] Evaluating on validation set...\n",
      "[Trial 37] F1-Score with Top 77 Features: 0.1623\n",
      "[Trial 37] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 42] Evaluating Top 43 Features...\n",
      "[Trial 42] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:56,018] Trial 38 finished with value: 0.1870026525198939 and parameters: {'k': 49}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 38] Evaluating on validation set...\n",
      "[Trial 38] F1-Score with Top 49 Features: 0.1870\n",
      "[Trial 38] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.46      0.12      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 43] Evaluating Top 39 Features...\n",
      "[Trial 43] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:10:56,532] Trial 39 finished with value: 0.11863224005582694 and parameters: {'k': 13}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 39] Evaluating on validation set...\n",
      "[Trial 39] F1-Score with Top 13 Features: 0.1186\n",
      "[Trial 39] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.36      0.07      0.12      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.66      0.53      0.54     21678\n",
      "weighted avg       0.92      0.94      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 44] Evaluating Top 19 Features...\n",
      "[Trial 44] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 40] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std']\n",
      "[Trial 40] Training LightGBM on Top 47 Features...\n",
      "[Trial 41] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median']\n",
      "[Trial 41] Training LightGBM on Top 73 Features...\n",
      "[Trial 42] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306']\n",
      "[Trial 42] Training LightGBM on Top 43 Features...\n",
      "[Trial 43] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month']\n",
      "[Trial 43] Training LightGBM on Top 39 Features...\n",
      "[Trial 44] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63']\n",
      "[Trial 44] Training LightGBM on Top 19 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:11:03,764] Trial 41 finished with value: 0.16997943797121315 and parameters: {'k': 73}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 41] Evaluating on validation set...\n",
      "[Trial 41] F1-Score with Top 73 Features: 0.1700\n",
      "[Trial 41] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.48      0.10      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 45] Evaluating Top 79 Features...\n",
      "[Trial 45] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:11:04,084] Trial 42 finished with value: 0.18654230512991338 and parameters: {'k': 43}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 42] Evaluating on validation set...\n",
      "[Trial 42] F1-Score with Top 43 Features: 0.1865\n",
      "[Trial 42] Classification Report:\n",
      "\n",
      "[Trial 40] Evaluating on validation set...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.47      0.12      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 46] Evaluating Top 99 Features...\n",
      "[Trial 46] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:11:04,202] Trial 40 finished with value: 0.1711229946524064 and parameters: {'k': 47}. Best is trial 3 with value: 0.19223173140223832.\n",
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 40] F1-Score with Top 47 Features: 0.1711\n",
      "[Trial 40] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.43      0.11      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.69      0.55      0.57     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 47] Evaluating Top 7 Features...\n",
      "[Trial 47] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:11:07,532] Trial 44 finished with value: 0.13956734124214934 and parameters: {'k': 19}. Best is trial 3 with value: 0.19223173140223832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 44] Evaluating on validation set...\n",
      "[Trial 44] F1-Score with Top 19 Features: 0.1396\n",
      "[Trial 44] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.43      0.08      0.14      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.69      0.54      0.56     21678\n",
      "weighted avg       0.92      0.94      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 48] Evaluating Top 1 Features...\n",
      "[Trial 48] Training LightGBM on all features for importance ranking...\n",
      "[Trial 43] Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:11:07,712] Trial 43 finished with value: 0.1801200800533689 and parameters: {'k': 39}. Best is trial 3 with value: 0.19223173140223832.\n",
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 43] F1-Score with Top 39 Features: 0.1801\n",
      "[Trial 43] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.45      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.70      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 49] Evaluating Top 95 Features...\n",
      "[Trial 49] Training LightGBM on all features for importance ranking...\n",
      "[Trial 45] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372']\n",
      "[Trial 45] Training LightGBM on Top 79 Features...\n",
      "[Trial 46] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30', 'meter_coefficient_10', 'meter_coefficient_11', 'meter_coefficient_4', 'meter_coefficient_3', 'meter_coefficient_2', 'meter_coefficient_0', 'meter_status_4.0', 'meter_status_3.0', 'meter_status_2.0', 'consumption_level_4_min']\n",
      "[Trial 46] Training LightGBM on Top 99 Features...\n",
      "[Trial 47] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0']\n",
      "[Trial 47] Training LightGBM on Top 7 Features...\n",
      "[Trial 48] Selected Features: ['meter_number_count']\n",
      "[Trial 48] Training LightGBM on Top 1 Features...\n",
      "[Trial 49] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30', 'meter_coefficient_10', 'meter_coefficient_11', 'meter_coefficient_4', 'meter_coefficient_3', 'meter_coefficient_2', 'meter_coefficient_0']\n",
      "[Trial 49] Training LightGBM on Top 95 Features...\n",
      "[Trial 46] Evaluating on validation set...\n",
      "[Trial 46] F1-Score with Top 99 Features: 0.1801\n",
      "[Trial 46] Classification Report:\n",
      "\n",
      "[Trial 48] Evaluating on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:11:14,364] Trial 46 finished with value: 0.1800818553888131 and parameters: {'k': 99}. Best is trial 3 with value: 0.19223173140223832.\n",
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:11:14,418] Trial 48 finished with value: 0.1963470319634703 and parameters: {'k': 1}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 50] Evaluating Top 89 Features...\n",
      "[Trial 50] Training LightGBM on all features for importance ranking...\n",
      "[Trial 48] F1-Score with Top 1 Features: 0.1963\n",
      "[Trial 48] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20478\n",
      "         1.0       0.15      0.29      0.20      1200\n",
      "\n",
      "    accuracy                           0.87     21678\n",
      "   macro avg       0.55      0.60      0.56     21678\n",
      "weighted avg       0.91      0.87      0.89     21678\n",
      "\n",
      "\n",
      "[Trial 51] Evaluating Top 89 Features...\n",
      "[Trial 51] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:11:15,413] Trial 47 finished with value: 0.023942537909018357 and parameters: {'k': 7}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 47] Evaluating on validation set...\n",
      "[Trial 47] F1-Score with Top 7 Features: 0.0239\n",
      "[Trial 47] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     20478\n",
      "         1.0       0.28      0.01      0.02      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.61      0.51      0.50     21678\n",
      "weighted avg       0.91      0.94      0.92     21678\n",
      "\n",
      "\n",
      "[Trial 52] Evaluating Top 79 Features...\n",
      "[Trial 52] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:11:16,434] Trial 45 finished with value: 0.158004158004158 and parameters: {'k': 79}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 45] Evaluating on validation set...\n",
      "[Trial 45] F1-Score with Top 79 Features: 0.1580\n",
      "[Trial 45] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.47      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.54      0.56     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 53] Evaluating Top 89 Features...\n",
      "[Trial 53] Training LightGBM on all features for importance ranking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n",
      "[I 2024-11-30 02:11:20,188] Trial 49 finished with value: 0.1800818553888131 and parameters: {'k': 95}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 49] Evaluating on validation set...\n",
      "[Trial 49] F1-Score with Top 95 Features: 0.1801\n",
      "[Trial 49] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "[Trial 54] Evaluating Top 89 Features...\n",
      "[Trial 54] Training LightGBM on all features for importance ranking...\n",
      "[Trial 50] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30']\n",
      "[Trial 50] Training LightGBM on Top 89 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbs/anaconda3/envs/fraud_detection/lib/python3.12/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [1, 102] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 101].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 52] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372']\n",
      "[Trial 52] Training LightGBM on Top 79 Features...\n",
      "[Trial 53] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30']\n",
      "[Trial 53] Training LightGBM on Top 89 Features...\n",
      "[Trial 51] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30']\n",
      "[Trial 51] Training LightGBM on Top 89 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:11:25,858] Trial 50 finished with value: 0.1800818553888131 and parameters: {'k': 89}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 54] Selected Features: ['meter_number_count', 'meter_code_count', 'months_number_max', 'reading_remark_8', 'creation_year', 'months_number_min', 'meter_status_1.0', 'old_index_mean', 'time_since_last_invoice_min', 'old_index_median', 'reading_remark_9', 'region_101', 'consumption_level_1_sum', 'old_index_min', 'time_since_last_invoice_median', 'district_69', 'old_index_max', 'district_62', 'district_63', 'reading_remark_6', 'consumption_level_2_mean', 'meter_type_1', 'time_since_last_invoice_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_1_max', 'consumption_level_1_mean', 'is_index_discrepancy_True', 'meter_type_0', 'consumption_level_4_mean', 'region_104', 'diff_in_index_sum', 'region_301', 'time_since_last_invoice_max', 'region_103', 'creation_day', 'total_consumption_sum', 'consumption_level_1_std', 'creation_month', 'consumption_level_2_sum', 'region_105', 'region_312', 'region_306', 'diff_in_index_mean', 'region_309', 'region_107', 'consumption_level_2_std', 'total_consumption_max', 'consumption_level_3_max', 'consumption_level_3_sum', 'client_catg_11', 'months_number_median', 'region_311', 'diff_in_index_max', 'diff_in_index_min', 'total_consumption_mean', 'diff_in_index_std', 'time_since_last_invoice_std', 'region_304', 'region_310', 'region_302', 'total_consumption_std', 'consumption_level_1_min', 'region_106', 'region_313', 'region_305', 'region_307', 'region_371', 'client_catg_12', 'region_303', 'total_consumption_min', 'consumption_level_4_max', 'consumption_level_2_median', 'client_catg_51', 'is_index_discrepancy_False', 'region_308', 'consumption_level_4_sum', 'region_379', 'region_372', 'no_of_invoices', 'consumption_level_3_min', 'consumption_level_2_min', 'consumption_level_4_median', 'reading_remark_7', 'meter_coefficient_20', 'meter_coefficient_50', 'meter_coefficient_40', 'meter_coefficient_33', 'meter_coefficient_30']\n",
      "[Trial 54] Training LightGBM on Top 89 Features...\n",
      "[Trial 50] Evaluating on validation set...\n",
      "[Trial 50] F1-Score with Top 89 Features: 0.1801\n",
      "[Trial 50] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:11:27,287] Trial 53 finished with value: 0.1800818553888131 and parameters: {'k': 89}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 53] Evaluating on validation set...\n",
      "[Trial 53] F1-Score with Top 89 Features: 0.1801\n",
      "[Trial 53] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:11:27,691] Trial 52 finished with value: 0.158004158004158 and parameters: {'k': 79}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 52] Evaluating on validation set...\n",
      "[Trial 52] F1-Score with Top 79 Features: 0.1580\n",
      "[Trial 52] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.47      0.10      0.16      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.71      0.54      0.56     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:11:28,008] Trial 51 finished with value: 0.1800818553888131 and parameters: {'k': 89}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 51] Evaluating on validation set...\n",
      "[Trial 51] F1-Score with Top 89 Features: 0.1801\n",
      "[Trial 51] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 02:11:28,583] Trial 54 finished with value: 0.1800818553888131 and parameters: {'k': 89}. Best is trial 48 with value: 0.1963470319634703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 54] Evaluating on validation set...\n",
      "[Trial 54] F1-Score with Top 89 Features: 0.1801\n",
      "[Trial 54] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.50      0.11      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.72      0.55      0.58     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "\n",
      "Best result:\n",
      "Optimal number of features: 1\n",
      "Best F1-Score: 0.1963\n",
      "Selected Features: ['meter_number_count']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the study (n_jobs allows parallel trials)\n",
    "study.optimize(objective, n_jobs=5)\n",
    "\n",
    "# Print the best result\n",
    "print(\"\\nBest result:\")\n",
    "print(f\"Optimal number of features: {study.best_params['k']}\")\n",
    "print(f\"Best F1-Score: {study.best_value:.4f}\")\n",
    "print(f\"Selected Features: {study.best_trial.user_attrs['selected_features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the feature importance test showed that 1 optimal feature - `meter_number_count` resulted in the best F1-score. While this shows that this feature is very important, the low f1-score indicates that further methods may be required to improve predictive accuracy, such as using cross validation to ensure that its not overfitted to the present training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-fold validation for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then went on to perform RFE with 5-fold cross validation using LGBM as a base model. For each iteration of cross validation, we use the non-SMOTEd fold data as the validation set. Additionally, we also perform random sampling of the train_data for each iteration to reduce computational time. This approach evalutes subsets of features to identify the optimal number and combination that contribute most effectively to the model's performance based on F1-score as well. We include trial pruning with Optuna, to prune away folds that have resulted in low f1-score to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [fold1, fold2, fold3, fold4, fold5]  # Non-SMOTEd folds\n",
    "smote_folds = [smote_fold_1, smote_fold_2, smote_fold_3, smote_fold_4, smote_fold_5]  # SMOTEd folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.exceptions import TrialPruned\n",
    "\n",
    "def perform_rfe_with_cv(smote_folds, folds, n_features, trial_number, trial):\n",
    "    print(f\"\\n[Trial {trial_number}] Evaluating RFE with {n_features} features using 5-fold CV...\")\n",
    "    \n",
    "    # Initialize arrays to store F1-scores\n",
    "    f1_scores = []\n",
    "\n",
    "    # Loop through each fold\n",
    "    for i in range(5):\n",
    "        print(f\"  [Trial {trial_number}] - Fold {i + 1}/5\")\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        print(f\"    [Trial {trial_number} - Fold {i + 1}] Preparing data\")\n",
    "        train_smote_folds = [smote_folds[j] for j in range(5) if j != i]\n",
    "        val_fold = folds[i]  # Non-SMOTEd validation data\n",
    "\n",
    "        # Concatenate training data\n",
    "        train_data = pd.concat(train_smote_folds, axis=0)\n",
    "        val_data = val_fold\n",
    "\n",
    "        # Sample 10% of the train data\n",
    "        train_data, _ = train_test_split(train_data, test_size=0.9, stratify=train_data['fraud_status'], random_state=42)\n",
    "\n",
    "        # Separate features and target\n",
    "        X_train = train_data.drop(columns=['fraud_status'])\n",
    "        y_train = train_data['fraud_status']\n",
    "        X_val = val_data.drop(columns=['fraud_status'])\n",
    "        y_val = val_data['fraud_status']\n",
    "\n",
    "        # Standard scaling\n",
    "        print(f\"    [Trial {trial_number} - Fold {i + 1}] Applying StandardScaler\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        # Initialize LightGBM for RFE\n",
    "        lgbm = LGBMClassifier(random_state=42,\n",
    "                              n_estimators=50,\n",
    "                              class_weight='balanced', \n",
    "                              n_jobs=-1,\n",
    "                              verbose=-1)\n",
    "\n",
    "        # Perform RFE\n",
    "        print(f\"    [Trial {trial_number} - Fold {i + 1}] Training LGBM with RFE\")\n",
    "        rfe = RFE(estimator=lgbm, n_features_to_select=n_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        # Get reduced validation data\n",
    "        X_val_reduced = X_val[:, rfe.support_]\n",
    "\n",
    "        # Train LightGBM on reduced training data\n",
    "        lgbm.fit(X_train[:, rfe.support_], y_train)\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        print(f\"    [Trial {trial_number} - Fold {i + 1}] Evaluating on validation set\")\n",
    "        val_predictions = lgbm.predict(X_val_reduced)\n",
    "        f1 = f1_score(y_val, val_predictions, pos_label=1.0)\n",
    "        print(f\"    [Trial {trial_number} - Fold {i + 1}] F1-Score: {f1:.4f}\")\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Print Classification Report\n",
    "        print(f\"    [Trial {trial_number} - Fold {i + 1}] Classification Report:\\n\")\n",
    "        print(classification_report(y_val, val_predictions))\n",
    "\n",
    "        # Report intermediate score to Optuna for pruning\n",
    "        trial.report(np.mean(f1_scores), step=i)\n",
    "        if trial.should_prune():\n",
    "            print(f\"    [Trial {trial_number}] Pruned after Fold {i + 1}\")\n",
    "            raise TrialPruned()\n",
    "\n",
    "    # Return mean F1-score across folds and selected feature indices\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    print(f\"[Trial {trial_number}] Mean F1-Score Across 5 Folds: {mean_f1:.4f}\")\n",
    "    return mean_f1, rfe.support_\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Get the number of features from the trial\n",
    "    n_features = trial.suggest_int('n_features', 1, smote_folds[0].shape[1] - 1)  # Exclude the target column\n",
    "    print(f\"\\n[Trial {trial.number}] Evaluating Top {n_features} Features with RFE and 5-Fold CV...\")\n",
    "\n",
    "    # Perform RFE with 5-fold CV and pruning\n",
    "    try:\n",
    "        mean_f1, selected_features = perform_rfe_with_cv(\n",
    "            smote_folds, folds, \n",
    "            n_features=n_features,\n",
    "            trial_number=trial.number,\n",
    "            trial=trial\n",
    "        )\n",
    "    except TrialPruned:\n",
    "        raise\n",
    "\n",
    "    # Map selected feature indices back to column names\n",
    "    selected_feature_names = smote_folds[0].drop(columns=['fraud_status']).columns[selected_features].tolist()\n",
    "    trial.set_user_attr(\"selected_features\", selected_feature_names)\n",
    "    print(f\"[Trial {trial.number}] Selected Features: {selected_feature_names}\")\n",
    "\n",
    "    return mean_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 12:25:19,454] A new study created in memory with name: rfe_cv_study\n"
     ]
    }
   ],
   "source": [
    "# Define the search space for `n_features`\n",
    "search_space = {'n_features': list(range(1, smote_folds[0].shape[1], 5))}  # Step size = 10\n",
    "\n",
    "# Use GridSampler for deterministic search\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler, study_name='rfe_cv_study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 0] Evaluating Top 41 Features with RFE and 5-Fold CV...\n",
      "[Trial 1] Evaluating Top 66 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 1] Evaluating RFE with 66 features using 5-fold CV...\n",
      "  [Trial 1] - Fold 1/5\n",
      "    [Trial 1 - Fold 1] Preparing data\n",
      "\n",
      "[Trial 2] Evaluating Top 101 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 2] Evaluating RFE with 101 features using 5-fold CV...\n",
      "  [Trial 2] - Fold 1/5\n",
      "    [Trial 2 - Fold 1] Preparing data\n",
      "\n",
      "\n",
      "[Trial 0] Evaluating RFE with 41 features using 5-fold CV...\n",
      "  [Trial 0] - Fold 1/5\n",
      "    [Trial 0 - Fold 1] Preparing data\n",
      "\n",
      "[Trial 3] Evaluating Top 6 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 3] Evaluating RFE with 6 features using 5-fold CV...\n",
      "  [Trial 3] - Fold 1/5\n",
      "    [Trial 3 - Fold 1] Preparing data\n",
      "\n",
      "[Trial 4] Evaluating Top 56 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 4] Evaluating RFE with 56 features using 5-fold CV...\n",
      "  [Trial 4] - Fold 1/5\n",
      "    [Trial 4 - Fold 1] Preparing data\n",
      "    [Trial 0 - Fold 1] Applying StandardScaler    [Trial 2 - Fold 1] Applying StandardScaler\n",
      "    [Trial 4 - Fold 1] Applying StandardScaler\n",
      "    [Trial 3 - Fold 1] Applying StandardScaler\n",
      "\n",
      "    [Trial 1 - Fold 1] Applying StandardScaler\n",
      "    [Trial 1 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 3 - Fold 1] Training LGBM with RFE    [Trial 2 - Fold 1] Training LGBM with RFE\n",
      "\n",
      "    [Trial 4 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 0 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 2 - Fold 1] Evaluating on validation set\n",
      "    [Trial 2 - Fold 1] F1-Score: 0.1974\n",
      "    [Trial 2 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.39      0.13      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 2] - Fold 2/5\n",
      "    [Trial 2 - Fold 2] Preparing data\n",
      "    [Trial 2 - Fold 2] Applying StandardScaler\n",
      "    [Trial 2 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 2 - Fold 2] Evaluating on validation set\n",
      "    [Trial 2 - Fold 2] F1-Score: 0.1811\n",
      "    [Trial 2 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.35      0.12      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 2] - Fold 3/5\n",
      "    [Trial 2 - Fold 3] Preparing data\n",
      "    [Trial 2 - Fold 3] Applying StandardScaler\n",
      "    [Trial 2 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 2 - Fold 3] Evaluating on validation set\n",
      "    [Trial 2 - Fold 3] F1-Score: 0.1784\n",
      "    [Trial 2 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 2] - Fold 4/5\n",
      "    [Trial 2 - Fold 4] Preparing data\n",
      "    [Trial 2 - Fold 4] Applying StandardScaler\n",
      "    [Trial 2 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 2 - Fold 4] Evaluating on validation set\n",
      "    [Trial 2 - Fold 4] F1-Score: 0.1836\n",
      "    [Trial 2 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.68      0.55      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 2] - Fold 5/5\n",
      "    [Trial 2 - Fold 5] Preparing data\n",
      "    [Trial 2 - Fold 5] Applying StandardScaler\n",
      "    [Trial 2 - Fold 5] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 12:27:10,980] Trial 2 finished with value: 0.18992875867577014 and parameters: {'n_features': 101}. Best is trial 2 with value: 0.18992875867577014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 2 - Fold 5] Evaluating on validation set\n",
      "    [Trial 2 - Fold 5] F1-Score: 0.2091\n",
      "    [Trial 2 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.14      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.56      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 2] Mean F1-Score Across 5 Folds: 0.1899\n",
      "[Trial 2] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_106', 'region_107', 'region_199', 'region_206', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_308', 'region_309', 'region_310', 'region_311', 'region_312', 'region_313', 'region_371', 'region_372', 'region_379', 'region_399', 'district_62', 'district_63', 'district_69', 'client_catg_11', 'client_catg_12', 'client_catg_51', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_std', 'consumption_level_2_min', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_min', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'consumption_level_4_median', 'consumption_level_4_sum', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_std', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_mean', 'total_consumption_std', 'total_consumption_min', 'total_consumption_max', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'months_number_median', 'meter_number_count', 'meter_code_count', 'no_of_invoices', 'time_since_last_invoice_mean', 'time_since_last_invoice_std', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'meter_status_2.0', 'meter_status_3.0', 'meter_status_4.0', 'meter_coefficient_0', 'meter_coefficient_2', 'meter_coefficient_3', 'meter_coefficient_4', 'meter_coefficient_10', 'meter_coefficient_11', 'meter_coefficient_20', 'meter_coefficient_30', 'meter_coefficient_33', 'meter_coefficient_40', 'meter_coefficient_50', 'reading_remark_6', 'reading_remark_7', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_False', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 5] Evaluating Top 51 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 5] Evaluating RFE with 51 features using 5-fold CV...\n",
      "  [Trial 5] - Fold 1/5\n",
      "    [Trial 5 - Fold 1] Preparing data\n",
      "    [Trial 5 - Fold 1] Applying StandardScaler\n",
      "    [Trial 5 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 1 - Fold 1] Evaluating on validation set\n",
      "    [Trial 1 - Fold 1] F1-Score: 0.1818\n",
      "    [Trial 1 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.36      0.12      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.66      0.55      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 1] - Fold 2/5\n",
      "    [Trial 1 - Fold 2] Preparing data\n",
      "    [Trial 1 - Fold 2] Applying StandardScaler\n",
      "    [Trial 1 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 4 - Fold 1] Evaluating on validation set\n",
      "    [Trial 4 - Fold 1] F1-Score: 0.2017\n",
      "    [Trial 4 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.37      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.66      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 4] - Fold 2/5\n",
      "    [Trial 4 - Fold 2] Preparing data\n",
      "    [Trial 4 - Fold 2] Applying StandardScaler\n",
      "    [Trial 4 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 0 - Fold 1] Evaluating on validation set\n",
      "    [Trial 0 - Fold 1] F1-Score: 0.1872\n",
      "    [Trial 0 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.33      0.13      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 0] - Fold 2/5\n",
      "    [Trial 0 - Fold 2] Preparing data\n",
      "    [Trial 0 - Fold 2] Applying StandardScaler\n",
      "    [Trial 0 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 5 - Fold 1] Evaluating on validation set\n",
      "    [Trial 5 - Fold 1] F1-Score: 0.2026\n",
      "    [Trial 5 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.35      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.59     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 5] - Fold 2/5\n",
      "    [Trial 5 - Fold 2] Preparing data\n",
      "    [Trial 5 - Fold 2] Applying StandardScaler\n",
      "    [Trial 5 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 1 - Fold 2] Evaluating on validation set\n",
      "    [Trial 1 - Fold 2] F1-Score: 0.1867\n",
      "    [Trial 1 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.37      0.12      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.66      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 1] - Fold 3/5\n",
      "    [Trial 1 - Fold 3] Preparing data\n",
      "    [Trial 1 - Fold 3] Applying StandardScaler\n",
      "    [Trial 1 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 3 - Fold 1] Evaluating on validation set\n",
      "    [Trial 3 - Fold 1] F1-Score: 0.0610\n",
      "    [Trial 3 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.24      0.04      0.06      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.59      0.51      0.52     21679\n",
      "weighted avg       0.91      0.94      0.92     21679\n",
      "\n",
      "  [Trial 3] - Fold 2/5\n",
      "    [Trial 3 - Fold 2] Preparing data\n",
      "    [Trial 3 - Fold 2] Applying StandardScaler\n",
      "    [Trial 3 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 4 - Fold 2] Evaluating on validation set\n",
      "    [Trial 4 - Fold 2] F1-Score: 0.1769\n",
      "    [Trial 4 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.34      0.12      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 4] - Fold 3/5\n",
      "    [Trial 4 - Fold 3] Preparing data\n",
      "    [Trial 4 - Fold 3] Applying StandardScaler\n",
      "    [Trial 4 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 1 - Fold 3] Evaluating on validation set\n",
      "    [Trial 1 - Fold 3] F1-Score: 0.1857\n",
      "    [Trial 1 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.37      0.12      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.66      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 1] - Fold 4/5\n",
      "    [Trial 1 - Fold 4] Preparing data\n",
      "    [Trial 1 - Fold 4] Applying StandardScaler\n",
      "    [Trial 1 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 5 - Fold 2] Evaluating on validation set\n",
      "    [Trial 5 - Fold 2] F1-Score: 0.1846\n",
      "    [Trial 5 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.32      0.13      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 5] - Fold 3/5\n",
      "    [Trial 5 - Fold 3] Preparing data\n",
      "    [Trial 5 - Fold 3] Applying StandardScaler\n",
      "    [Trial 5 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 0 - Fold 2] Evaluating on validation set\n",
      "    [Trial 0 - Fold 2] F1-Score: 0.1816\n",
      "    [Trial 0 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.32      0.13      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.56      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 0] - Fold 3/5\n",
      "    [Trial 0 - Fold 3] Preparing data\n",
      "    [Trial 0 - Fold 3] Applying StandardScaler\n",
      "    [Trial 0 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 4 - Fold 3] Evaluating on validation set\n",
      "    [Trial 4 - Fold 3] F1-Score: 0.1981\n",
      "    [Trial 4 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.14      0.20      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 4] - Fold 4/5\n",
      "    [Trial 4 - Fold 4] Preparing data\n",
      "    [Trial 4 - Fold 4] Applying StandardScaler\n",
      "    [Trial 4 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 1 - Fold 4] Evaluating on validation set\n",
      "    [Trial 1 - Fold 4] F1-Score: 0.1921\n",
      "    [Trial 1 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.38      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 1] - Fold 5/5\n",
      "    [Trial 1 - Fold 5] Preparing data\n",
      "    [Trial 1 - Fold 5] Applying StandardScaler\n",
      "    [Trial 1 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 5 - Fold 3] Evaluating on validation set\n",
      "    [Trial 5 - Fold 3] F1-Score: 0.1900\n",
      "    [Trial 5 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 5] - Fold 4/5\n",
      "    [Trial 5 - Fold 4] Preparing data\n",
      "    [Trial 5 - Fold 4] Applying StandardScaler\n",
      "    [Trial 5 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 3 - Fold 2] Evaluating on validation set\n",
      "    [Trial 3 - Fold 2] F1-Score: 0.0620\n",
      "    [Trial 3 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.23      0.04      0.06      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.59      0.51      0.52     21679\n",
      "weighted avg       0.91      0.94      0.92     21679\n",
      "\n",
      "  [Trial 3] - Fold 3/5\n",
      "    [Trial 3 - Fold 3] Preparing data\n",
      "    [Trial 3 - Fold 3] Applying StandardScaler\n",
      "    [Trial 3 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 0 - Fold 3] Evaluating on validation set\n",
      "    [Trial 0 - Fold 3] F1-Score: 0.1848\n",
      "    [Trial 0 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.34      0.13      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 0] - Fold 4/5\n",
      "    [Trial 0 - Fold 4] Preparing data\n",
      "    [Trial 0 - Fold 4] Applying StandardScaler\n",
      "    [Trial 0 - Fold 4] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:26:00,633] Trial 1 finished with value: 0.19106049140147982 and parameters: {'n_features': 66}. Best is trial 1 with value: 0.19106049140147982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 1 - Fold 5] Evaluating on validation set\n",
      "    [Trial 1 - Fold 5] F1-Score: 0.2090\n",
      "    [Trial 1 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.39      0.14      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.67      0.56      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 1] Mean F1-Score Across 5 Folds: 0.1911\n",
      "[Trial 1] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_107', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_309', 'region_310', 'region_311', 'region_371', 'district_62', 'district_63', 'district_69', 'client_catg_11', 'client_catg_12', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'consumption_level_4_sum', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_std', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_mean', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'months_number_median', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 6] Evaluating Top 71 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 6] Evaluating RFE with 71 features using 5-fold CV...\n",
      "  [Trial 6] - Fold 1/5\n",
      "    [Trial 6 - Fold 1] Preparing data\n",
      "    [Trial 6 - Fold 1] Applying StandardScaler\n",
      "    [Trial 6 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 4 - Fold 4] Evaluating on validation set\n",
      "    [Trial 4 - Fold 4] F1-Score: 0.1872\n",
      "    [Trial 4 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.39      0.12      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 4] - Fold 5/5\n",
      "    [Trial 4 - Fold 5] Preparing data\n",
      "    [Trial 4 - Fold 5] Applying StandardScaler\n",
      "    [Trial 4 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 6 - Fold 1] Evaluating on validation set\n",
      "    [Trial 6 - Fold 1] F1-Score: 0.1882\n",
      "    [Trial 6 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.36      0.13      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 6] - Fold 2/5\n",
      "    [Trial 6 - Fold 2] Preparing data\n",
      "    [Trial 6 - Fold 2] Applying StandardScaler\n",
      "    [Trial 6 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 5 - Fold 4] Evaluating on validation set\n",
      "    [Trial 5 - Fold 4] F1-Score: 0.2028\n",
      "    [Trial 5 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.38      0.14      0.20      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.59     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 5] - Fold 5/5\n",
      "    [Trial 5 - Fold 5] Preparing data\n",
      "    [Trial 5 - Fold 5] Applying StandardScaler\n",
      "    [Trial 5 - Fold 5] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:28:22,780] Trial 4 finished with value: 0.19706173969486834 and parameters: {'n_features': 56}. Best is trial 4 with value: 0.19706173969486834.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 4 - Fold 5] Evaluating on validation set\n",
      "    [Trial 4 - Fold 5] F1-Score: 0.2214\n",
      "    [Trial 4 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.41      0.15      0.22      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.57      0.60     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 4] Mean F1-Score Across 5 Folds: 0.1971\n",
      "[Trial 4] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_107', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_309', 'region_310', 'region_311', 'district_62', 'district_63', 'district_69', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 7] Evaluating Top 91 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 7] Evaluating RFE with 91 features using 5-fold CV...\n",
      "  [Trial 7] - Fold 1/5\n",
      "    [Trial 7 - Fold 1] Preparing data\n",
      "    [Trial 7 - Fold 1] Applying StandardScaler\n",
      "    [Trial 7 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 7 - Fold 1] Evaluating on validation set\n",
      "    [Trial 7 - Fold 1] F1-Score: 0.1974\n",
      "    [Trial 7 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.39      0.13      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 7] - Fold 2/5\n",
      "    [Trial 7 - Fold 2] Preparing data\n",
      "    [Trial 7 - Fold 2] Applying StandardScaler\n",
      "    [Trial 7 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 0 - Fold 4] Evaluating on validation set\n",
      "    [Trial 0 - Fold 4] F1-Score: 0.2040\n",
      "    [Trial 0 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.38      0.14      0.20      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.66      0.56      0.59     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 0] - Fold 5/5\n",
      "    [Trial 0 - Fold 5] Preparing data\n",
      "    [Trial 0 - Fold 5] Applying StandardScaler\n",
      "    [Trial 0 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 6 - Fold 2] Evaluating on validation set\n",
      "    [Trial 6 - Fold 2] F1-Score: 0.1717\n",
      "    [Trial 6 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.32      0.12      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 6] - Fold 3/5\n",
      "    [Trial 6 - Fold 3] Preparing data\n",
      "    [Trial 6 - Fold 3] Applying StandardScaler\n",
      "    [Trial 6 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 7 - Fold 2] Evaluating on validation set\n",
      "    [Trial 7 - Fold 2] F1-Score: 0.1811\n",
      "    [Trial 7 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.35      0.12      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 7] - Fold 3/5\n",
      "    [Trial 7 - Fold 3] Preparing data\n",
      "    [Trial 7 - Fold 3] Applying StandardScaler\n",
      "    [Trial 7 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 7 - Fold 3] Evaluating on validation set\n",
      "    [Trial 7 - Fold 3] F1-Score: 0.1784\n",
      "    [Trial 7 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 7] - Fold 4/5\n",
      "    [Trial 7 - Fold 4] Preparing data\n",
      "    [Trial 7 - Fold 4] Applying StandardScaler\n",
      "    [Trial 7 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 3 - Fold 3] Evaluating on validation set\n",
      "    [Trial 3 - Fold 3] F1-Score: 0.0401\n",
      "    [Trial 3 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.18      0.02      0.04      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.56      0.51      0.50     21679\n",
      "weighted avg       0.90      0.94      0.92     21679\n",
      "\n",
      "  [Trial 3] - Fold 4/5\n",
      "    [Trial 3 - Fold 4] Preparing data\n",
      "    [Trial 3 - Fold 4] Applying StandardScaler\n",
      "    [Trial 3 - Fold 4] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:31:16,425] Trial 5 finished with value: 0.1981695604557031 and parameters: {'n_features': 51}. Best is trial 5 with value: 0.1981695604557031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 5 - Fold 5] Evaluating on validation set\n",
      "    [Trial 5 - Fold 5] F1-Score: 0.2108\n",
      "    [Trial 5 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.37      0.15      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.66      0.57      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 5] Mean F1-Score Across 5 Folds: 0.1982\n",
      "[Trial 5] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_107', 'region_301', 'region_302', 'region_303', 'region_304', 'region_306', 'region_309', 'district_62', 'district_63', 'district_69', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_4_mean', 'consumption_level_4_max', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 8] Evaluating Top 31 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 8] Evaluating RFE with 31 features using 5-fold CV...\n",
      "  [Trial 8] - Fold 1/5\n",
      "    [Trial 8 - Fold 1] Preparing data\n",
      "    [Trial 8 - Fold 1] Applying StandardScaler\n",
      "    [Trial 8 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 6 - Fold 3] Evaluating on validation set\n",
      "    [Trial 6 - Fold 3] F1-Score: 0.1807\n",
      "    [Trial 6 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.36      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 6] - Fold 4/5\n",
      "    [Trial 6 - Fold 4] Preparing data\n",
      "    [Trial 6 - Fold 4] Applying StandardScaler\n",
      "    [Trial 6 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 7 - Fold 4] Evaluating on validation set\n",
      "    [Trial 7 - Fold 4] F1-Score: 0.1836\n",
      "    [Trial 7 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.68      0.55      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 7] - Fold 5/5\n",
      "    [Trial 7 - Fold 5] Preparing data\n",
      "    [Trial 7 - Fold 5] Applying StandardScaler\n",
      "    [Trial 7 - Fold 5] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:32:40,642] Trial 7 finished with value: 0.18992875867577014 and parameters: {'n_features': 91}. Best is trial 5 with value: 0.1981695604557031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 7 - Fold 5] Evaluating on validation set\n",
      "    [Trial 7 - Fold 5] F1-Score: 0.2091\n",
      "    [Trial 7 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.14      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.56      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 7] Mean F1-Score Across 5 Folds: 0.1899\n",
      "[Trial 7] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_106', 'region_107', 'region_199', 'region_206', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_308', 'region_309', 'region_310', 'region_311', 'region_312', 'region_313', 'region_371', 'region_372', 'region_379', 'region_399', 'district_62', 'district_63', 'district_69', 'client_catg_11', 'client_catg_12', 'client_catg_51', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_std', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'consumption_level_4_median', 'consumption_level_4_sum', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_std', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_mean', 'total_consumption_std', 'total_consumption_min', 'total_consumption_max', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'months_number_median', 'meter_number_count', 'meter_code_count', 'no_of_invoices', 'time_since_last_invoice_mean', 'time_since_last_invoice_std', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'meter_status_4.0', 'meter_coefficient_2', 'meter_coefficient_30', 'meter_coefficient_33', 'meter_coefficient_40', 'meter_coefficient_50', 'reading_remark_6', 'reading_remark_7', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_False', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 9] Evaluating Top 96 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 9] Evaluating RFE with 96 features using 5-fold CV...\n",
      "  [Trial 9] - Fold 1/5\n",
      "    [Trial 9 - Fold 1] Preparing data\n",
      "    [Trial 9 - Fold 1] Applying StandardScaler\n",
      "    [Trial 9 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 9 - Fold 1] Evaluating on validation set\n",
      "    [Trial 9 - Fold 1] F1-Score: 0.1974\n",
      "    [Trial 9 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.39      0.13      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 9] - Fold 2/5\n",
      "    [Trial 9 - Fold 2] Preparing data\n",
      "    [Trial 9 - Fold 2] Applying StandardScaler\n",
      "    [Trial 9 - Fold 2] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:33:10,913] Trial 0 finished with value: 0.19576238914022115 and parameters: {'n_features': 41}. Best is trial 5 with value: 0.1981695604557031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 0 - Fold 5] Evaluating on validation set\n",
      "    [Trial 0 - Fold 5] F1-Score: 0.2212\n",
      "    [Trial 0 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.37      0.16      0.22      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.66      0.57      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 0] Mean F1-Score Across 5 Folds: 0.1958\n",
      "[Trial 0] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_104', 'region_107', 'region_301', 'district_62', 'district_63', 'district_69', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_4_mean', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_1', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 10] Evaluating Top 21 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 10] Evaluating RFE with 21 features using 5-fold CV...\n",
      "  [Trial 10] - Fold 1/5\n",
      "    [Trial 10 - Fold 1] Preparing data\n",
      "    [Trial 10 - Fold 1] Applying StandardScaler\n",
      "    [Trial 10 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 9 - Fold 2] Evaluating on validation set\n",
      "    [Trial 9 - Fold 2] F1-Score: 0.1811\n",
      "    [Trial 9 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.35      0.12      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 9] - Fold 3/5\n",
      "    [Trial 9 - Fold 3] Preparing data\n",
      "    [Trial 9 - Fold 3] Applying StandardScaler\n",
      "    [Trial 9 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 6 - Fold 4] Evaluating on validation set\n",
      "    [Trial 6 - Fold 4] F1-Score: 0.1737\n",
      "    [Trial 6 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.38      0.11      0.17      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 6] - Fold 5/5\n",
      "    [Trial 6 - Fold 5] Preparing data\n",
      "    [Trial 6 - Fold 5] Applying StandardScaler\n",
      "    [Trial 6 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 9 - Fold 3] Evaluating on validation set\n",
      "    [Trial 9 - Fold 3] F1-Score: 0.1784\n",
      "    [Trial 9 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 9] - Fold 4/5\n",
      "    [Trial 9 - Fold 4] Preparing data\n",
      "    [Trial 9 - Fold 4] Applying StandardScaler\n",
      "    [Trial 9 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 9 - Fold 4] Evaluating on validation set\n",
      "    [Trial 9 - Fold 4] F1-Score: 0.1836\n",
      "    [Trial 9 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.68      0.55      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 9] - Fold 5/5\n",
      "    [Trial 9 - Fold 5] Preparing data\n",
      "    [Trial 9 - Fold 5] Applying StandardScaler\n",
      "    [Trial 9 - Fold 5] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:34:46,965] Trial 9 finished with value: 0.18992875867577014 and parameters: {'n_features': 96}. Best is trial 5 with value: 0.1981695604557031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 9 - Fold 5] Evaluating on validation set\n",
      "    [Trial 9 - Fold 5] F1-Score: 0.2091\n",
      "    [Trial 9 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.14      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.56      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 9] Mean F1-Score Across 5 Folds: 0.1899\n",
      "[Trial 9] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_106', 'region_107', 'region_199', 'region_206', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_308', 'region_309', 'region_310', 'region_311', 'region_312', 'region_313', 'region_371', 'region_372', 'region_379', 'region_399', 'district_62', 'district_63', 'district_69', 'client_catg_11', 'client_catg_12', 'client_catg_51', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_std', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'consumption_level_4_median', 'consumption_level_4_sum', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_std', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_mean', 'total_consumption_std', 'total_consumption_min', 'total_consumption_max', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'months_number_median', 'meter_number_count', 'meter_code_count', 'no_of_invoices', 'time_since_last_invoice_mean', 'time_since_last_invoice_std', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'meter_status_4.0', 'meter_coefficient_0', 'meter_coefficient_2', 'meter_coefficient_3', 'meter_coefficient_4', 'meter_coefficient_11', 'meter_coefficient_20', 'meter_coefficient_30', 'meter_coefficient_33', 'meter_coefficient_40', 'meter_coefficient_50', 'reading_remark_6', 'reading_remark_7', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_False', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 11] Evaluating Top 11 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 11] Evaluating RFE with 11 features using 5-fold CV...\n",
      "  [Trial 11] - Fold 1/5\n",
      "    [Trial 11 - Fold 1] Preparing data\n",
      "    [Trial 11 - Fold 1] Applying StandardScaler\n",
      "    [Trial 11 - Fold 1] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:35:12,399] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 8 - Fold 1] Evaluating on validation set\n",
      "    [Trial 8 - Fold 1] F1-Score: 0.1945\n",
      "    [Trial 8 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.31      0.14      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.63      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "    [Trial 8] Pruned after Fold 1\n",
      "\n",
      "[Trial 12] Evaluating Top 26 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 12] Evaluating RFE with 26 features using 5-fold CV...\n",
      "  [Trial 12] - Fold 1/5\n",
      "    [Trial 12 - Fold 1] Preparing data\n",
      "    [Trial 12 - Fold 1] Applying StandardScaler\n",
      "    [Trial 12 - Fold 1] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:35:27,834] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 6 - Fold 5] Evaluating on validation set\n",
      "    [Trial 6 - Fold 5] F1-Score: 0.2145\n",
      "    [Trial 6 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.15      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.57      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "    [Trial 6] Pruned after Fold 5\n",
      "\n",
      "[Trial 13] Evaluating Top 81 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 13] Evaluating RFE with 81 features using 5-fold CV...\n",
      "  [Trial 13] - Fold 1/5\n",
      "    [Trial 13 - Fold 1] Preparing data\n",
      "    [Trial 13 - Fold 1] Applying StandardScaler\n",
      "    [Trial 13 - Fold 1] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:36:25,279] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 3 - Fold 4] Evaluating on validation set\n",
      "    [Trial 3 - Fold 4] F1-Score: 0.0183\n",
      "    [Trial 3 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97     20478\n",
      "         1.0       0.11      0.01      0.02      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.53      0.50      0.49     21679\n",
      "weighted avg       0.90      0.94      0.92     21679\n",
      "\n",
      "    [Trial 3] Pruned after Fold 4\n",
      "\n",
      "[Trial 14] Evaluating Top 46 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 14] Evaluating RFE with 46 features using 5-fold CV...\n",
      "  [Trial 14] - Fold 1/5\n",
      "    [Trial 14 - Fold 1] Preparing data\n",
      "    [Trial 14 - Fold 1] Applying StandardScaler\n",
      "    [Trial 14 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 13 - Fold 1] Evaluating on validation set\n",
      "    [Trial 13 - Fold 1] F1-Score: 0.1974\n",
      "    [Trial 13 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.39      0.13      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 13] - Fold 2/5\n",
      "    [Trial 13 - Fold 2] Preparing data\n",
      "    [Trial 13 - Fold 2] Applying StandardScaler\n",
      "    [Trial 13 - Fold 2] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:37:36,217] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 10 - Fold 1] Evaluating on validation set\n",
      "    [Trial 10 - Fold 1] F1-Score: 0.1882\n",
      "    [Trial 10 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.37      0.13      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.66      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "    [Trial 10] Pruned after Fold 1\n",
      "\n",
      "[Trial 15] Evaluating Top 36 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 15] Evaluating RFE with 36 features using 5-fold CV...\n",
      "  [Trial 15] - Fold 1/5\n",
      "    [Trial 15 - Fold 1] Preparing data\n",
      "    [Trial 15 - Fold 1] Applying StandardScaler\n",
      "    [Trial 15 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 13 - Fold 2] Evaluating on validation set\n",
      "    [Trial 13 - Fold 2] F1-Score: 0.1811\n",
      "    [Trial 13 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.35      0.12      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 13] - Fold 3/5\n",
      "    [Trial 13 - Fold 3] Preparing data\n",
      "    [Trial 13 - Fold 3] Applying StandardScaler\n",
      "    [Trial 13 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 13 - Fold 3] Evaluating on validation set\n",
      "    [Trial 13 - Fold 3] F1-Score: 0.1784\n",
      "    [Trial 13 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 13] - Fold 4/5\n",
      "    [Trial 13 - Fold 4] Preparing data\n",
      "    [Trial 13 - Fold 4] Applying StandardScaler\n",
      "    [Trial 13 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 14 - Fold 1] Evaluating on validation set\n",
      "    [Trial 14 - Fold 1] F1-Score: 0.2014\n",
      "    [Trial 14 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.35      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 14] - Fold 2/5\n",
      "    [Trial 14 - Fold 2] Preparing data\n",
      "    [Trial 14 - Fold 2] Applying StandardScaler\n",
      "    [Trial 14 - Fold 2] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:39:13,941] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 12 - Fold 1] Evaluating on validation set\n",
      "    [Trial 12 - Fold 1] F1-Score: 0.1968\n",
      "    [Trial 12 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.35      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "    [Trial 12] Pruned after Fold 1\n",
      "\n",
      "[Trial 16] Evaluating Top 86 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 16] Evaluating RFE with 86 features using 5-fold CV...\n",
      "  [Trial 16] - Fold 1/5\n",
      "    [Trial 16 - Fold 1] Preparing data\n",
      "    [Trial 16 - Fold 1] Applying StandardScaler\n",
      "    [Trial 16 - Fold 1] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:39:20,951] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 11 - Fold 1] Evaluating on validation set\n",
      "    [Trial 11 - Fold 1] F1-Score: 0.1457\n",
      "    [Trial 11 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.31      0.10      0.15      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.63      0.54      0.56     21679\n",
      "weighted avg       0.91      0.94      0.92     21679\n",
      "\n",
      "    [Trial 11] Pruned after Fold 1\n",
      "\n",
      "[Trial 17] Evaluating Top 16 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 17] Evaluating RFE with 16 features using 5-fold CV...\n",
      "  [Trial 17] - Fold 1/5\n",
      "    [Trial 17 - Fold 1] Preparing data\n",
      "    [Trial 17 - Fold 1] Applying StandardScaler\n",
      "    [Trial 17 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 13 - Fold 4] Evaluating on validation set\n",
      "    [Trial 13 - Fold 4] F1-Score: 0.1836\n",
      "    [Trial 13 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.68      0.55      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 13] - Fold 5/5\n",
      "    [Trial 13 - Fold 5] Preparing data\n",
      "    [Trial 13 - Fold 5] Applying StandardScaler\n",
      "    [Trial 13 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 16 - Fold 1] Evaluating on validation set\n",
      "    [Trial 16 - Fold 1] F1-Score: 0.1974\n",
      "    [Trial 16 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.39      0.13      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 16] - Fold 2/5\n",
      "    [Trial 16 - Fold 2] Preparing data\n",
      "    [Trial 16 - Fold 2] Applying StandardScaler\n",
      "    [Trial 16 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 15 - Fold 1] Evaluating on validation set\n",
      "    [Trial 15 - Fold 1] F1-Score: 0.2093\n",
      "    [Trial 15 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.33      0.15      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.57      0.59     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 15] - Fold 2/5\n",
      "    [Trial 15 - Fold 2] Preparing data\n",
      "    [Trial 15 - Fold 2] Applying StandardScaler\n",
      "    [Trial 15 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 16 - Fold 2] Evaluating on validation set\n",
      "    [Trial 16 - Fold 2] F1-Score: 0.1811\n",
      "    [Trial 16 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.35      0.12      0.18      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 16] - Fold 3/5\n",
      "    [Trial 16 - Fold 3] Preparing data\n",
      "    [Trial 16 - Fold 3] Applying StandardScaler\n",
      "    [Trial 16 - Fold 3] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:41:19,180] Trial 13 finished with value: 0.18992875867577014 and parameters: {'n_features': 81}. Best is trial 5 with value: 0.1981695604557031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 13 - Fold 5] Evaluating on validation set\n",
      "    [Trial 13 - Fold 5] F1-Score: 0.2091\n",
      "    [Trial 13 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.14      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.56      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 13] Mean F1-Score Across 5 Folds: 0.1899\n",
      "[Trial 13] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_106', 'region_107', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_308', 'region_309', 'region_310', 'region_311', 'region_312', 'region_313', 'region_371', 'region_372', 'district_62', 'district_63', 'district_69', 'client_catg_11', 'client_catg_12', 'client_catg_51', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_std', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'consumption_level_4_median', 'consumption_level_4_sum', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_std', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_mean', 'total_consumption_std', 'total_consumption_min', 'total_consumption_max', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'months_number_median', 'meter_number_count', 'meter_code_count', 'no_of_invoices', 'time_since_last_invoice_mean', 'time_since_last_invoice_std', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'meter_coefficient_33', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_False', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 18] Evaluating Top 1 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 18] Evaluating RFE with 1 features using 5-fold CV...\n",
      "  [Trial 18] - Fold 1/5\n",
      "    [Trial 18 - Fold 1] Preparing data\n",
      "    [Trial 18 - Fold 1] Applying StandardScaler\n",
      "    [Trial 18 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 16 - Fold 3] Evaluating on validation set\n",
      "    [Trial 16 - Fold 3] F1-Score: 0.1784\n",
      "    [Trial 16 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 16] - Fold 4/5\n",
      "    [Trial 16 - Fold 4] Preparing data\n",
      "    [Trial 16 - Fold 4] Applying StandardScaler\n",
      "    [Trial 16 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 14 - Fold 2] Evaluating on validation set\n",
      "    [Trial 14 - Fold 2] F1-Score: 0.1939\n",
      "    [Trial 14 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.33      0.14      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 14] - Fold 3/5\n",
      "    [Trial 14 - Fold 3] Preparing data\n",
      "    [Trial 14 - Fold 3] Applying StandardScaler\n",
      "    [Trial 14 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 16 - Fold 4] Evaluating on validation set\n",
      "    [Trial 16 - Fold 4] F1-Score: 0.1836\n",
      "    [Trial 16 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.68      0.55      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 16] - Fold 5/5\n",
      "    [Trial 16 - Fold 5] Preparing data\n",
      "    [Trial 16 - Fold 5] Applying StandardScaler\n",
      "    [Trial 16 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 17 - Fold 1] Evaluating on validation set\n",
      "    [Trial 17 - Fold 1] F1-Score: 0.2236\n",
      "    [Trial 17 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.35      0.17      0.22      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.57      0.60     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 17] - Fold 2/5\n",
      "    [Trial 17 - Fold 2] Preparing data\n",
      "    [Trial 17 - Fold 2] Applying StandardScaler\n",
      "    [Trial 17 - Fold 2] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:43:48,646] Trial 16 finished with value: 0.18992875867577014 and parameters: {'n_features': 86}. Best is trial 5 with value: 0.1981695604557031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 16 - Fold 5] Evaluating on validation set\n",
      "    [Trial 16 - Fold 5] F1-Score: 0.2091\n",
      "    [Trial 16 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.14      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.56      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 16] Mean F1-Score Across 5 Folds: 0.1899\n",
      "[Trial 16] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_106', 'region_107', 'region_199', 'region_206', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_308', 'region_309', 'region_310', 'region_311', 'region_312', 'region_313', 'region_371', 'region_372', 'district_62', 'district_63', 'district_69', 'client_catg_11', 'client_catg_12', 'client_catg_51', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_std', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'consumption_level_4_median', 'consumption_level_4_sum', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_std', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_mean', 'total_consumption_std', 'total_consumption_min', 'total_consumption_max', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'months_number_median', 'meter_number_count', 'meter_code_count', 'no_of_invoices', 'time_since_last_invoice_mean', 'time_since_last_invoice_std', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'meter_coefficient_30', 'meter_coefficient_33', 'meter_coefficient_40', 'meter_coefficient_50', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_False', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 19] Evaluating Top 76 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 19] Evaluating RFE with 76 features using 5-fold CV...\n",
      "  [Trial 19] - Fold 1/5\n",
      "    [Trial 19 - Fold 1] Preparing data\n",
      "    [Trial 19 - Fold 1] Applying StandardScaler\n",
      "    [Trial 19 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 15 - Fold 2] Evaluating on validation set\n",
      "    [Trial 15 - Fold 2] F1-Score: 0.2014\n",
      "    [Trial 15 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.34      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 15] - Fold 3/5\n",
      "    [Trial 15 - Fold 3] Preparing data\n",
      "    [Trial 15 - Fold 3] Applying StandardScaler\n",
      "    [Trial 15 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 14 - Fold 3] Evaluating on validation set\n",
      "    [Trial 14 - Fold 3] F1-Score: 0.1896\n",
      "    [Trial 14 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.34      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 14] - Fold 4/5\n",
      "    [Trial 14 - Fold 4] Preparing data\n",
      "    [Trial 14 - Fold 4] Applying StandardScaler\n",
      "    [Trial 14 - Fold 4] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:45:13,086] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 19 - Fold 1] Evaluating on validation set\n",
      "    [Trial 19 - Fold 1] F1-Score: 0.1872\n",
      "    [Trial 19 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.36      0.13      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "    [Trial 19] Pruned after Fold 1\n",
      "\n",
      "[Trial 20] Evaluating Top 61 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 20] Evaluating RFE with 61 features using 5-fold CV...\n",
      "  [Trial 20] - Fold 1/5\n",
      "    [Trial 20 - Fold 1] Preparing data\n",
      "    [Trial 20 - Fold 1] Applying StandardScaler\n",
      "    [Trial 20 - Fold 1] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:46:05,257] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 18 - Fold 1] Evaluating on validation set\n",
      "    [Trial 18 - Fold 1] F1-Score: 0.0710\n",
      "    [Trial 18 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     20479\n",
      "         1.0       0.10      0.05      0.07      1200\n",
      "\n",
      "    accuracy                           0.92     21679\n",
      "   macro avg       0.52      0.51      0.52     21679\n",
      "weighted avg       0.90      0.92      0.91     21679\n",
      "\n",
      "    [Trial 18] Pruned after Fold 1\n",
      "\n",
      "[Trial 21] Evaluating Top 46 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 21] Evaluating RFE with 46 features using 5-fold CV...\n",
      "  [Trial 21] - Fold 1/5\n",
      "    [Trial 21 - Fold 1] Preparing data\n",
      "    [Trial 21 - Fold 1] Applying StandardScaler\n",
      "    [Trial 21 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 20 - Fold 1] Evaluating on validation set\n",
      "    [Trial 20 - Fold 1] F1-Score: 0.1994\n",
      "    [Trial 20 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.36      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 20] - Fold 2/5\n",
      "    [Trial 20 - Fold 2] Preparing data\n",
      "    [Trial 20 - Fold 2] Applying StandardScaler\n",
      "    [Trial 20 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 15 - Fold 3] Evaluating on validation set\n",
      "    [Trial 15 - Fold 3] F1-Score: 0.1861\n",
      "    [Trial 15 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 15] - Fold 4/5\n",
      "    [Trial 15 - Fold 4] Preparing data\n",
      "    [Trial 15 - Fold 4] Applying StandardScaler\n",
      "    [Trial 15 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 14 - Fold 4] Evaluating on validation set\n",
      "    [Trial 14 - Fold 4] F1-Score: 0.2030\n",
      "    [Trial 14 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.39      0.14      0.20      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.59     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 14] - Fold 5/5\n",
      "    [Trial 14 - Fold 5] Preparing data\n",
      "    [Trial 14 - Fold 5] Applying StandardScaler\n",
      "    [Trial 14 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 17 - Fold 2] Evaluating on validation set\n",
      "    [Trial 17 - Fold 2] F1-Score: 0.1885\n",
      "    [Trial 17 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.30      0.14      0.19      1200\n",
      "\n",
      "    accuracy                           0.93     21679\n",
      "   macro avg       0.63      0.56      0.58     21679\n",
      "weighted avg       0.92      0.93      0.92     21679\n",
      "\n",
      "  [Trial 17] - Fold 3/5\n",
      "    [Trial 17 - Fold 3] Preparing data\n",
      "    [Trial 17 - Fold 3] Applying StandardScaler\n",
      "    [Trial 17 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 21 - Fold 1] Evaluating on validation set\n",
      "    [Trial 21 - Fold 1] F1-Score: 0.2014\n",
      "    [Trial 21 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.35      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 21] - Fold 2/5\n",
      "    [Trial 21 - Fold 2] Preparing data\n",
      "    [Trial 21 - Fold 2] Applying StandardScaler\n",
      "    [Trial 21 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 20 - Fold 2] Evaluating on validation set\n",
      "    [Trial 20 - Fold 2] F1-Score: 0.1701\n",
      "    [Trial 20 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.34      0.11      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 20] - Fold 3/5\n",
      "    [Trial 20 - Fold 3] Preparing data\n",
      "    [Trial 20 - Fold 3] Applying StandardScaler\n",
      "    [Trial 20 - Fold 3] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:51:10,986] Trial 14 finished with value: 0.20326761109026775 and parameters: {'n_features': 46}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 14 - Fold 5] Evaluating on validation set\n",
      "    [Trial 14 - Fold 5] F1-Score: 0.2285\n",
      "    [Trial 14 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.39      0.16      0.23      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.67      0.57      0.60     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 14] Mean F1-Score Across 5 Folds: 0.2033\n",
      "[Trial 14] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_107', 'region_301', 'region_304', 'region_306', 'region_309', 'district_62', 'district_63', 'district_69', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_4_mean', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_1', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 22] Evaluating Top 36 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 22] Evaluating RFE with 36 features using 5-fold CV...\n",
      "  [Trial 22] - Fold 1/5\n",
      "    [Trial 22 - Fold 1] Preparing data\n",
      "    [Trial 22 - Fold 1] Applying StandardScaler\n",
      "    [Trial 22 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 15 - Fold 4] Evaluating on validation set\n",
      "    [Trial 15 - Fold 4] F1-Score: 0.1894\n",
      "    [Trial 15 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.37      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.66      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 15] - Fold 5/5\n",
      "    [Trial 15 - Fold 5] Preparing data\n",
      "    [Trial 15 - Fold 5] Applying StandardScaler\n",
      "    [Trial 15 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 20 - Fold 3] Evaluating on validation set\n",
      "    [Trial 20 - Fold 3] F1-Score: 0.1814\n",
      "    [Trial 20 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 20] - Fold 4/5\n",
      "    [Trial 20 - Fold 4] Preparing data\n",
      "    [Trial 20 - Fold 4] Applying StandardScaler\n",
      "    [Trial 20 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 21 - Fold 2] Evaluating on validation set\n",
      "    [Trial 21 - Fold 2] F1-Score: 0.1939\n",
      "    [Trial 21 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.33      0.14      0.19      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 21] - Fold 3/5\n",
      "    [Trial 21 - Fold 3] Preparing data\n",
      "    [Trial 21 - Fold 3] Applying StandardScaler\n",
      "    [Trial 21 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 17 - Fold 3] Evaluating on validation set\n",
      "    [Trial 17 - Fold 3] F1-Score: 0.2118\n",
      "    [Trial 17 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.96     20478\n",
      "         1.0       0.29      0.17      0.21      1201\n",
      "\n",
      "    accuracy                           0.93     21679\n",
      "   macro avg       0.62      0.57      0.59     21679\n",
      "weighted avg       0.92      0.93      0.92     21679\n",
      "\n",
      "  [Trial 17] - Fold 4/5\n",
      "    [Trial 17 - Fold 4] Preparing data\n",
      "    [Trial 17 - Fold 4] Applying StandardScaler\n",
      "    [Trial 17 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 20 - Fold 4] Evaluating on validation set\n",
      "    [Trial 20 - Fold 4] F1-Score: 0.1940\n",
      "    [Trial 20 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.38      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 20] - Fold 5/5\n",
      "    [Trial 20 - Fold 5] Preparing data\n",
      "    [Trial 20 - Fold 5] Applying StandardScaler\n",
      "    [Trial 20 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 22 - Fold 1] Evaluating on validation set\n",
      "    [Trial 22 - Fold 1] F1-Score: 0.2093\n",
      "    [Trial 22 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.33      0.15      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.57      0.59     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 22] - Fold 2/5\n",
      "    [Trial 22 - Fold 2] Preparing data\n",
      "    [Trial 22 - Fold 2] Applying StandardScaler\n",
      "    [Trial 22 - Fold 2] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:53:57,181] Trial 15 finished with value: 0.19927312412348858 and parameters: {'n_features': 36}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 15 - Fold 5] Evaluating on validation set\n",
      "    [Trial 15 - Fold 5] F1-Score: 0.2102\n",
      "    [Trial 15 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.38      0.15      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.66      0.57      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 15] Mean F1-Score Across 5 Folds: 0.1993\n",
      "[Trial 15] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_104', 'region_301', 'district_62', 'district_63', 'district_69', 'consumption_level_1_mean', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_4_mean', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 23] Evaluating Top 61 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 23] Evaluating RFE with 61 features using 5-fold CV...\n",
      "  [Trial 23] - Fold 1/5\n",
      "    [Trial 23 - Fold 1] Preparing data\n",
      "    [Trial 23 - Fold 1] Applying StandardScaler\n",
      "    [Trial 23 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 21 - Fold 3] Evaluating on validation set\n",
      "    [Trial 21 - Fold 3] F1-Score: 0.1896\n",
      "    [Trial 21 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.34      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.64      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 21] - Fold 4/5\n",
      "    [Trial 21 - Fold 4] Preparing data\n",
      "    [Trial 21 - Fold 4] Applying StandardScaler\n",
      "    [Trial 21 - Fold 4] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:55:01,652] Trial 20 finished with value: 0.1933986405244162 and parameters: {'n_features': 61}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 20 - Fold 5] Evaluating on validation set\n",
      "    [Trial 20 - Fold 5] F1-Score: 0.2221\n",
      "    [Trial 20 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.15      0.22      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.57      0.60     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 20] Mean F1-Score Across 5 Folds: 0.1934\n",
      "[Trial 20] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_107', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_309', 'region_310', 'region_311', 'region_371', 'district_62', 'district_63', 'district_69', 'client_catg_11', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 24] Evaluating Top 16 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 24] Evaluating RFE with 16 features using 5-fold CV...\n",
      "  [Trial 24] - Fold 1/5\n",
      "    [Trial 24 - Fold 1] Preparing data\n",
      "    [Trial 24 - Fold 1] Applying StandardScaler\n",
      "    [Trial 24 - Fold 1] Training LGBM with RFE\n",
      "    [Trial 23 - Fold 1] Evaluating on validation set\n",
      "    [Trial 23 - Fold 1] F1-Score: 0.1994\n",
      "    [Trial 23 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.36      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 23] - Fold 2/5\n",
      "    [Trial 23 - Fold 2] Preparing data\n",
      "    [Trial 23 - Fold 2] Applying StandardScaler\n",
      "    [Trial 23 - Fold 2] Training LGBM with RFE\n",
      "    [Trial 17 - Fold 4] Evaluating on validation set\n",
      "    [Trial 17 - Fold 4] F1-Score: 0.1666\n",
      "    [Trial 17 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.29      0.12      0.17      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.62      0.55      0.57     21679\n",
      "weighted avg       0.91      0.94      0.92     21679\n",
      "\n",
      "  [Trial 17] - Fold 5/5\n",
      "    [Trial 17 - Fold 5] Preparing data\n",
      "    [Trial 17 - Fold 5] Applying StandardScaler\n",
      "    [Trial 17 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 22 - Fold 2] Evaluating on validation set\n",
      "    [Trial 22 - Fold 2] F1-Score: 0.2014\n",
      "    [Trial 22 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.34      0.14      0.20      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 22] - Fold 3/5\n",
      "    [Trial 22 - Fold 3] Preparing data\n",
      "    [Trial 22 - Fold 3] Applying StandardScaler\n",
      "    [Trial 22 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 21 - Fold 4] Evaluating on validation set\n",
      "    [Trial 21 - Fold 4] F1-Score: 0.2030\n",
      "    [Trial 21 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.39      0.14      0.20      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.59     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 21] - Fold 5/5\n",
      "    [Trial 21 - Fold 5] Preparing data\n",
      "    [Trial 21 - Fold 5] Applying StandardScaler\n",
      "    [Trial 21 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 23 - Fold 2] Evaluating on validation set\n",
      "    [Trial 23 - Fold 2] F1-Score: 0.1701\n",
      "    [Trial 23 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20479\n",
      "         1.0       0.34      0.11      0.17      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 23] - Fold 3/5\n",
      "    [Trial 23 - Fold 3] Preparing data\n",
      "    [Trial 23 - Fold 3] Applying StandardScaler\n",
      "    [Trial 23 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 24 - Fold 1] Evaluating on validation set\n",
      "    [Trial 24 - Fold 1] F1-Score: 0.2236\n",
      "    [Trial 24 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.35      0.17      0.22      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.57      0.60     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 24] - Fold 2/5\n",
      "    [Trial 24 - Fold 2] Preparing data\n",
      "    [Trial 24 - Fold 2] Applying StandardScaler\n",
      "    [Trial 24 - Fold 2] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:58:01,405] Trial 21 finished with value: 0.20326761109026775 and parameters: {'n_features': 46}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 21 - Fold 5] Evaluating on validation set\n",
      "    [Trial 21 - Fold 5] F1-Score: 0.2285\n",
      "    [Trial 21 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.39      0.16      0.23      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.67      0.57      0.60     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 21] Mean F1-Score Across 5 Folds: 0.2033\n",
      "[Trial 21] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_107', 'region_301', 'region_304', 'region_306', 'region_309', 'district_62', 'district_63', 'district_69', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_4_mean', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_1', 'is_index_discrepancy_True']\n",
      "\n",
      "[Trial 25] Evaluating Top 16 Features with RFE and 5-Fold CV...\n",
      "\n",
      "[Trial 25] Evaluating RFE with 16 features using 5-fold CV...\n",
      "  [Trial 25] - Fold 1/5\n",
      "    [Trial 25 - Fold 1] Preparing data\n",
      "    [Trial 25 - Fold 1] Applying StandardScaler\n",
      "    [Trial 25 - Fold 1] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 15:58:12,306] Trial 17 finished with value: 0.20120533021376358 and parameters: {'n_features': 16}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 17 - Fold 5] Evaluating on validation set\n",
      "    [Trial 17 - Fold 5] F1-Score: 0.2155\n",
      "    [Trial 17 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.31      0.16      0.22      1200\n",
      "\n",
      "    accuracy                           0.93     21678\n",
      "   macro avg       0.63      0.57      0.59     21678\n",
      "weighted avg       0.92      0.93      0.92     21678\n",
      "\n",
      "[Trial 17] Mean F1-Score Across 5 Folds: 0.2012\n",
      "[Trial 17] Selected Features: ['creation_year', 'region_101', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_max', 'consumption_level_3_mean', 'old_index_mean', 'old_index_median', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_min', 'meter_status_1.0', 'reading_remark_8', 'reading_remark_9']\n",
      "    [Trial 23 - Fold 3] Evaluating on validation set\n",
      "    [Trial 23 - Fold 3] F1-Score: 0.1814\n",
      "    [Trial 23 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.12      0.18      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.55      0.57     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 23] - Fold 4/5\n",
      "    [Trial 23 - Fold 4] Preparing data\n",
      "    [Trial 23 - Fold 4] Applying StandardScaler\n",
      "    [Trial 23 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 22 - Fold 3] Evaluating on validation set\n",
      "    [Trial 22 - Fold 3] F1-Score: 0.1861\n",
      "    [Trial 22 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.35      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.92     21679\n",
      "\n",
      "  [Trial 22] - Fold 4/5\n",
      "    [Trial 22 - Fold 4] Preparing data\n",
      "    [Trial 22 - Fold 4] Applying StandardScaler\n",
      "    [Trial 22 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 23 - Fold 4] Evaluating on validation set\n",
      "    [Trial 23 - Fold 4] F1-Score: 0.1940\n",
      "    [Trial 23 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.38      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.67      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 23] - Fold 5/5\n",
      "    [Trial 23 - Fold 5] Preparing data\n",
      "    [Trial 23 - Fold 5] Applying StandardScaler\n",
      "    [Trial 23 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 22 - Fold 4] Evaluating on validation set\n",
      "    [Trial 22 - Fold 4] F1-Score: 0.1894\n",
      "    [Trial 22 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.37      0.13      0.19      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.66      0.56      0.58     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 22] - Fold 5/5\n",
      "    [Trial 22 - Fold 5] Preparing data\n",
      "    [Trial 22 - Fold 5] Applying StandardScaler\n",
      "    [Trial 22 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 24 - Fold 2] Evaluating on validation set\n",
      "    [Trial 24 - Fold 2] F1-Score: 0.1885\n",
      "    [Trial 24 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.30      0.14      0.19      1200\n",
      "\n",
      "    accuracy                           0.93     21679\n",
      "   macro avg       0.63      0.56      0.58     21679\n",
      "weighted avg       0.92      0.93      0.92     21679\n",
      "\n",
      "  [Trial 24] - Fold 3/5\n",
      "    [Trial 24 - Fold 3] Preparing data\n",
      "    [Trial 24 - Fold 3] Applying StandardScaler\n",
      "    [Trial 24 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 25 - Fold 1] Evaluating on validation set\n",
      "    [Trial 25 - Fold 1] F1-Score: 0.2236\n",
      "    [Trial 25 - Fold 1] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.35      0.17      0.22      1200\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.65      0.57      0.60     21679\n",
      "weighted avg       0.92      0.94      0.93     21679\n",
      "\n",
      "  [Trial 25] - Fold 2/5\n",
      "    [Trial 25 - Fold 2] Preparing data\n",
      "    [Trial 25 - Fold 2] Applying StandardScaler\n",
      "    [Trial 25 - Fold 2] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 16:00:50,347] Trial 23 finished with value: 0.1933986405244162 and parameters: {'n_features': 61}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 23 - Fold 5] Evaluating on validation set\n",
      "    [Trial 23 - Fold 5] F1-Score: 0.2221\n",
      "    [Trial 23 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.40      0.15      0.22      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.68      0.57      0.60     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 23] Mean F1-Score Across 5 Folds: 0.1934\n",
      "[Trial 23] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_105', 'region_107', 'region_301', 'region_302', 'region_303', 'region_304', 'region_305', 'region_306', 'region_307', 'region_309', 'region_310', 'region_311', 'region_371', 'district_62', 'district_63', 'district_69', 'client_catg_11', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_min', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_2_median', 'consumption_level_2_sum', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_3_sum', 'consumption_level_4_mean', 'consumption_level_4_max', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_0', 'meter_type_1', 'is_index_discrepancy_True']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 16:01:55,306] Trial 22 finished with value: 0.19927312412348858 and parameters: {'n_features': 36}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 22 - Fold 5] Evaluating on validation set\n",
      "    [Trial 22 - Fold 5] F1-Score: 0.2102\n",
      "    [Trial 22 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     20478\n",
      "         1.0       0.38      0.15      0.21      1200\n",
      "\n",
      "    accuracy                           0.94     21678\n",
      "   macro avg       0.66      0.57      0.59     21678\n",
      "weighted avg       0.92      0.94      0.93     21678\n",
      "\n",
      "[Trial 22] Mean F1-Score Across 5 Folds: 0.1993\n",
      "[Trial 22] Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_104', 'region_301', 'district_62', 'district_63', 'district_69', 'consumption_level_1_mean', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_4_mean', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'is_index_discrepancy_True']\n",
      "    [Trial 24 - Fold 3] Evaluating on validation set\n",
      "    [Trial 24 - Fold 3] F1-Score: 0.2118\n",
      "    [Trial 24 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.96     20478\n",
      "         1.0       0.29      0.17      0.21      1201\n",
      "\n",
      "    accuracy                           0.93     21679\n",
      "   macro avg       0.62      0.57      0.59     21679\n",
      "weighted avg       0.92      0.93      0.92     21679\n",
      "\n",
      "  [Trial 24] - Fold 4/5\n",
      "    [Trial 24 - Fold 4] Preparing data\n",
      "    [Trial 24 - Fold 4] Applying StandardScaler\n",
      "    [Trial 24 - Fold 4] Training LGBM with RFE\n",
      "    [Trial 25 - Fold 2] Evaluating on validation set\n",
      "    [Trial 25 - Fold 2] F1-Score: 0.1885\n",
      "    [Trial 25 - Fold 2] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20479\n",
      "         1.0       0.30      0.14      0.19      1200\n",
      "\n",
      "    accuracy                           0.93     21679\n",
      "   macro avg       0.63      0.56      0.58     21679\n",
      "weighted avg       0.92      0.93      0.92     21679\n",
      "\n",
      "  [Trial 25] - Fold 3/5\n",
      "    [Trial 25 - Fold 3] Preparing data\n",
      "    [Trial 25 - Fold 3] Applying StandardScaler\n",
      "    [Trial 25 - Fold 3] Training LGBM with RFE\n",
      "    [Trial 24 - Fold 4] Evaluating on validation set\n",
      "    [Trial 24 - Fold 4] F1-Score: 0.1666\n",
      "    [Trial 24 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.29      0.12      0.17      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.62      0.55      0.57     21679\n",
      "weighted avg       0.91      0.94      0.92     21679\n",
      "\n",
      "  [Trial 24] - Fold 5/5\n",
      "    [Trial 24 - Fold 5] Preparing data\n",
      "    [Trial 24 - Fold 5] Applying StandardScaler\n",
      "    [Trial 24 - Fold 5] Training LGBM with RFE\n",
      "    [Trial 25 - Fold 3] Evaluating on validation set\n",
      "    [Trial 25 - Fold 3] F1-Score: 0.2118\n",
      "    [Trial 25 - Fold 3] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.96     20478\n",
      "         1.0       0.29      0.17      0.21      1201\n",
      "\n",
      "    accuracy                           0.93     21679\n",
      "   macro avg       0.62      0.57      0.59     21679\n",
      "weighted avg       0.92      0.93      0.92     21679\n",
      "\n",
      "  [Trial 25] - Fold 4/5\n",
      "    [Trial 25 - Fold 4] Preparing data\n",
      "    [Trial 25 - Fold 4] Applying StandardScaler\n",
      "    [Trial 25 - Fold 4] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 16:04:30,291] Trial 24 finished with value: 0.20120533021376358 and parameters: {'n_features': 16}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 24 - Fold 5] Evaluating on validation set\n",
      "    [Trial 24 - Fold 5] F1-Score: 0.2155\n",
      "    [Trial 24 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.31      0.16      0.22      1200\n",
      "\n",
      "    accuracy                           0.93     21678\n",
      "   macro avg       0.63      0.57      0.59     21678\n",
      "weighted avg       0.92      0.93      0.92     21678\n",
      "\n",
      "[Trial 24] Mean F1-Score Across 5 Folds: 0.2012\n",
      "[Trial 24] Selected Features: ['creation_year', 'region_101', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_max', 'consumption_level_3_mean', 'old_index_mean', 'old_index_median', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_min', 'meter_status_1.0', 'reading_remark_8', 'reading_remark_9']\n",
      "    [Trial 25 - Fold 4] Evaluating on validation set\n",
      "    [Trial 25 - Fold 4] F1-Score: 0.1666\n",
      "    [Trial 25 - Fold 4] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.29      0.12      0.17      1201\n",
      "\n",
      "    accuracy                           0.94     21679\n",
      "   macro avg       0.62      0.55      0.57     21679\n",
      "weighted avg       0.91      0.94      0.92     21679\n",
      "\n",
      "  [Trial 25] - Fold 5/5\n",
      "    [Trial 25 - Fold 5] Preparing data\n",
      "    [Trial 25 - Fold 5] Applying StandardScaler\n",
      "    [Trial 25 - Fold 5] Training LGBM with RFE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 16:05:10,106] Trial 25 finished with value: 0.20120533021376358 and parameters: {'n_features': 16}. Best is trial 14 with value: 0.20326761109026775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 25 - Fold 5] Evaluating on validation set\n",
      "    [Trial 25 - Fold 5] F1-Score: 0.2155\n",
      "    [Trial 25 - Fold 5] Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     20478\n",
      "         1.0       0.31      0.16      0.22      1200\n",
      "\n",
      "    accuracy                           0.93     21678\n",
      "   macro avg       0.63      0.57      0.59     21678\n",
      "weighted avg       0.92      0.93      0.92     21678\n",
      "\n",
      "[Trial 25] Mean F1-Score Across 5 Folds: 0.2012\n",
      "[Trial 25] Selected Features: ['creation_year', 'region_101', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_max', 'consumption_level_3_mean', 'old_index_mean', 'old_index_median', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_min', 'meter_status_1.0', 'reading_remark_8', 'reading_remark_9']\n",
      "\n",
      "Best result:\n",
      "Optimal number of features: 46\n",
      "Best F1-Score: 0.2033\n",
      "Selected Features: ['creation_year', 'creation_month', 'creation_day', 'region_101', 'region_103', 'region_104', 'region_107', 'region_301', 'region_304', 'region_306', 'region_309', 'district_62', 'district_63', 'district_69', 'consumption_level_1_mean', 'consumption_level_1_std', 'consumption_level_1_max', 'consumption_level_1_sum', 'consumption_level_2_mean', 'consumption_level_2_max', 'consumption_level_3_mean', 'consumption_level_3_max', 'consumption_level_4_mean', 'old_index_mean', 'old_index_min', 'old_index_max', 'old_index_median', 'diff_in_index_mean', 'diff_in_index_min', 'diff_in_index_max', 'diff_in_index_sum', 'total_consumption_sum', 'months_number_min', 'months_number_max', 'meter_number_count', 'meter_code_count', 'time_since_last_invoice_mean', 'time_since_last_invoice_min', 'time_since_last_invoice_max', 'time_since_last_invoice_median', 'meter_status_1.0', 'reading_remark_6', 'reading_remark_8', 'reading_remark_9', 'meter_type_1', 'is_index_discrepancy_True']\n"
     ]
    }
   ],
   "source": [
    "# Run the study with pruning enabled\n",
    "study.optimize(objective, n_jobs=5, catch=(TrialPruned,))\n",
    "\n",
    "# Print the best result\n",
    "print(\"\\nBest result:\")\n",
    "print(f\"Optimal number of features: {study.best_params['n_features']}\")\n",
    "print(f\"Best F1-Score: {study.best_value:.4f}\")\n",
    "print(f\"Selected Features: {study.best_trial.user_attrs['selected_features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the selected 46 features, the model achieved a best F1-score of 0.2033. This represents an improvement compared to earlier stages of feature selection with fewer features, indicating that the inclusion of these additional features enhances the model's ability to balance precision and recall. However, f1-score is still rather low. Nevertheless, we move on to hyperparameter tuning with these selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = study.best_trial.user_attrs['selected_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM hyperparameter tuning with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we explored a few differen hyperparameters for the SVM model. This included the following hyperparameters:\n",
    "\n",
    "1. kernel options: (linear, rbf, poly, sigmoid) and parameters that control the model's complexity and generalization.\n",
    "2. Regularization parameter C: balances margin maximization and misclassificaiton penalities.\n",
    "3. Gamma: defines the influence of data points in non-linear kernels.\n",
    "4. Shrinking: effect on optimization speed and accuracy.\n",
    "5. Tolerance: stopping tolerance, to balance precision and computational efficiency.\n",
    "\n",
    "Specific kernels such as poly and sigmoid had additional parameters like coef0 to control higher-order term influence, and poly included degree to specify the polynomial degree.\n",
    "\n",
    "Similarly, we utilised Optuna's trial-based optimization approach to explore a unique combination of hyperparameters. 5-fold cross-validation ensures robustness with different training and validation sets each time. Likewise, we used mean F1-score across folds as the optimization metric to determine the best set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "    C = trial.suggest_float('C', 0.1, 100, log=True)\n",
    "    gamma = trial.suggest_float('gamma', 0.01, 10, log=True)\n",
    "    class_weight = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
    "    shrinking = trial.suggest_categorical(\"shrinking\", [True, False])\n",
    "    tol = trial.suggest_float(\"tol\", 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Additional hyperparameters for specific kernels\n",
    "    if kernel in [\"poly\", \"sigmoid\"]:\n",
    "        coef0 = trial.suggest_float(\"coef0\", 0.0, 10.0)\n",
    "    if kernel == \"poly\":\n",
    "        degree = trial.suggest_int(\"degree\", 2, 5)\n",
    "\n",
    "    print(f\"\\n[Trial {trial.number}] Starting with parameters: kernel={kernel}, C={C:.4f}, gamma={gamma:.4f}, tol={tol:.6f}, class_weight={class_weight}, shrinking={shrinking}\")\n",
    "\n",
    "    # Cross-validation loop\n",
    "    cv_f1_scores = []\n",
    "    for i in range(5):\n",
    "        print(f\"\\n  [Trial {trial.number} - Fold {i + 1}/5] Preparing data...\")\n",
    "\n",
    "        # Select training and validation folds\n",
    "        train_folds = [smote_folds[j] for j in range(5) if j != i]\n",
    "        val_fold = folds[i]\n",
    "        train_data = pd.concat(train_folds, axis=0)\n",
    "        val_data = val_fold\n",
    "\n",
    "        # Sample 10% of the train data\n",
    "        print(f\"    [Trial {trial.number} - Fold {i + 1}] Sampling 10% of training data...\")\n",
    "        train_data, _ = train_test_split(train_data, test_size=0.9, stratify=train_data['fraud_status'], random_state=42)\n",
    "\n",
    "        # Separate features and target\n",
    "        print(f\"    [Trial {trial.number} - Fold {i + 1}] Splitting features and target...\")\n",
    "        X_train = train_data[selected_features].values\n",
    "        y_train = train_data['fraud_status'].values\n",
    "        X_val = val_data[selected_features].values\n",
    "        y_val = val_data['fraud_status'].values\n",
    "\n",
    "        # Standard scaling\n",
    "        print(f\"    [Trial {trial.number} - Fold {i + 1}] Scaling data with StandardScaler...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        # Train SVM\n",
    "        print(f\"    [Trial {trial.number} - Fold {i + 1}] Training SVM model...\")\n",
    "        svm_params = {\n",
    "            'kernel': kernel,\n",
    "            'C': C,\n",
    "            'gamma': gamma,\n",
    "            'class_weight': class_weight,\n",
    "            'shrinking': shrinking,\n",
    "            'tol': tol,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        if kernel in [\"poly\", \"sigmoid\"]:\n",
    "            svm_params['coef0'] = coef0\n",
    "        if kernel == \"poly\":\n",
    "            svm_params['degree'] = degree\n",
    "\n",
    "        svm_model = SVC(**svm_params)\n",
    "        svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        print(f\"    [Trial {trial.number} - Fold {i + 1}] Evaluating on validation data...\")\n",
    "        val_predictions = svm_model.predict(X_val_scaled)\n",
    "        f1 = f1_score(y_val, val_predictions, pos_label=1.0)\n",
    "        print(f\"    [Trial {trial.number} - Fold {i + 1}] F1-Score: {f1:.4f}\")\n",
    "        cv_f1_scores.append(f1)\n",
    "\n",
    "        # Print Classification Report\n",
    "        print(f\"    [Trial {trial.number} - Fold {i + 1}] Classification Report:\")\n",
    "        print(classification_report(y_val, val_predictions))\n",
    "\n",
    "        # Report intermediate score for pruning\n",
    "        trial.report(np.mean(cv_f1_scores), step=i)\n",
    "        if trial.should_prune():\n",
    "            print(f\"    [Trial {trial.number}] Trial pruned after Fold {i + 1}\")\n",
    "            raise TrialPruned()\n",
    "\n",
    "    # Calculate mean F1-Score across folds\n",
    "    mean_f1 = np.mean(cv_f1_scores)\n",
    "    print(f\"\\n[Trial {trial.number}] Mean F1-Score across all folds: {mean_f1:.4f}\")\n",
    "\n",
    "    return mean_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 16:51:38,017] A new study created in memory with name: no-name-8faa70d4-9464-46d2-9c4c-2b58ad1d5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 2] Starting with parameters: kernel=sigmoid, C=25.6738, gamma=0.7110, tol=0.000188, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 2 - Fold 1/5] Preparing data...\n",
      "\n",
      "[Trial 1] Starting with parameters: kernel=poly, C=3.5435, gamma=1.0750, tol=0.001377, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 1 - Fold 1/5] Preparing data...\n",
      "\n",
      "[Trial 0] Starting with parameters: kernel=poly, C=2.4061, gamma=1.5912, tol=0.000842, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 0 - Fold 1/5] Preparing data...\n",
      "\n",
      "[Trial 3] Starting with parameters: kernel=linear, C=1.9031, gamma=0.5777, tol=0.000041, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 3 - Fold 1/5] Preparing data...\n",
      "\n",
      "[Trial 4] Starting with parameters: kernel=linear, C=9.4736, gamma=0.4437, tol=0.000510, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 4 - Fold 1/5] Preparing data...\n",
      "    [Trial 3 - Fold 1] Sampling 10% of training data...    [Trial 2 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 0 - Fold 1] Sampling 10% of training data...\n",
      "\n",
      "    [Trial 1 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 4 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 3 - Fold 1] Splitting features and target...\n",
      "    [Trial 1 - Fold 1] Splitting features and target...\n",
      "    [Trial 2 - Fold 1] Splitting features and target...\n",
      "    [Trial 4 - Fold 1] Splitting features and target...\n",
      "    [Trial 0 - Fold 1] Splitting features and target...\n",
      "    [Trial 2 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 1 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 3 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 4 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 0 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 4 - Fold 1] Training SVM model...\n",
      "    [Trial 3 - Fold 1] Training SVM model...\n",
      "    [Trial 2 - Fold 1] Training SVM model...\n",
      "    [Trial 0 - Fold 1] Training SVM model...\n",
      "    [Trial 1 - Fold 1] Training SVM model...\n",
      "    [Trial 1 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 1 - Fold 1] F1-Score: 0.2198\n",
      "    [Trial 1 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20479\n",
      "         1.0       0.15      0.39      0.22      1200\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.63      0.57     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 1 - Fold 2/5] Preparing data...\n",
      "    [Trial 1 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 3 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 1 - Fold 2] Splitting features and target...\n",
      "    [Trial 1 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 1 - Fold 2] Training SVM model...\n",
      "    [Trial 2 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 3 - Fold 1] F1-Score: 0.2330\n",
      "    [Trial 3 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.18      0.32      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.59     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 3 - Fold 2/5] Preparing data...\n",
      "    [Trial 3 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 3 - Fold 2] Splitting features and target...\n",
      "    [Trial 3 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 3 - Fold 2] Training SVM model...\n",
      "    [Trial 1 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 2 - Fold 1] F1-Score: 0.0975\n",
      "    [Trial 2 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.58     20479\n",
      "         1.0       0.05      0.56      0.10      1200\n",
      "\n",
      "    accuracy                           0.42     21679\n",
      "   macro avg       0.50      0.49      0.34     21679\n",
      "weighted avg       0.89      0.42      0.55     21679\n",
      "\n",
      "\n",
      "  [Trial 2 - Fold 2/5] Preparing data...\n",
      "    [Trial 2 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 2 - Fold 2] Splitting features and target...\n",
      "    [Trial 2 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 2 - Fold 2] Training SVM model...\n",
      "    [Trial 1 - Fold 2] F1-Score: 0.2314\n",
      "    [Trial 1 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20479\n",
      "         1.0       0.16      0.40      0.23      1200\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.64      0.58     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 1 - Fold 3/5] Preparing data...\n",
      "    [Trial 1 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 1 - Fold 3] Splitting features and target...\n",
      "    [Trial 1 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 1 - Fold 3] Training SVM model...\n",
      "    [Trial 3 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 3 - Fold 2] F1-Score: 0.2785\n",
      "    [Trial 3 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 3 - Fold 3/5] Preparing data...\n",
      "    [Trial 3 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 3 - Fold 3] Splitting features and target...\n",
      "    [Trial 3 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 3 - Fold 3] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 16:58:45,937] Trial 1 finished with value: 0.22641379940233267 and parameters: {'kernel': 'poly', 'C': 3.5435433542606636, 'gamma': 1.0749802092805794, 'class_weight': None, 'shrinking': True, 'tol': 0.0013773891133094984, 'coef0': 8.042703227220581, 'degree': 5}. Best is trial 1 with value: 0.22641379940233267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 1 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 0 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 1 - Fold 3] F1-Score: 0.2263\n",
      "    [Trial 1 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20478\n",
      "         1.0       0.16      0.39      0.23      1201\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.63      0.57     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 1 - Fold 4/5] Preparing data...\n",
      "    [Trial 1 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 1 - Fold 4] Splitting features and target...\n",
      "    [Trial 1 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 1 - Fold 4] Training SVM model...\n",
      "    [Trial 0 - Fold 1] F1-Score: 0.2131\n",
      "    [Trial 0 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     20479\n",
      "         1.0       0.15      0.40      0.21      1200\n",
      "\n",
      "    accuracy                           0.84     21679\n",
      "   macro avg       0.55      0.63      0.56     21679\n",
      "weighted avg       0.92      0.84      0.87     21679\n",
      "\n",
      "\n",
      "  [Trial 0 - Fold 2/5] Preparing data...\n",
      "    [Trial 0 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 0 - Fold 2] Splitting features and target...\n",
      "    [Trial 0 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 2 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 0 - Fold 2] Training SVM model...\n",
      "    [Trial 3 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 2 - Fold 2] F1-Score: 0.0916\n",
      "    [Trial 2 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57     20479\n",
      "         1.0       0.05      0.54      0.09      1200\n",
      "\n",
      "    accuracy                           0.41     21679\n",
      "   macro avg       0.49      0.47      0.33     21679\n",
      "weighted avg       0.89      0.41      0.54     21679\n",
      "\n",
      "\n",
      "  [Trial 2 - Fold 3/5] Preparing data...\n",
      "    [Trial 2 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 2 - Fold 3] Splitting features and target...\n",
      "    [Trial 2 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 2 - Fold 3] Training SVM model...\n",
      "    [Trial 3 - Fold 3] F1-Score: 0.2335\n",
      "    [Trial 3 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.20      0.28      0.23      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.59     21679\n",
      "weighted avg       0.91      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 3 - Fold 4/5] Preparing data...\n",
      "    [Trial 3 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 3 - Fold 4] Splitting features and target...\n",
      "    [Trial 3 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 3 - Fold 4] Training SVM model...\n",
      "    [Trial 1 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 1 - Fold 4] F1-Score: 0.2299\n",
      "    [Trial 1 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20478\n",
      "         1.0       0.16      0.40      0.23      1201\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.64      0.57     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 1 - Fold 5/5] Preparing data...\n",
      "    [Trial 1 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 1 - Fold 5] Splitting features and target...\n",
      "    [Trial 1 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 1 - Fold 5] Training SVM model...\n",
      "    [Trial 2 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 3 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 1 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 3 - Fold 4] F1-Score: 0.2625\n",
      "    [Trial 3 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.21      0.34      0.26      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.63      0.60     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 3 - Fold 5/5] Preparing data...\n",
      "    [Trial 3 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 3 - Fold 5] Splitting features and target...\n",
      "    [Trial 3 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 3 - Fold 5] Training SVM model...\n",
      "    [Trial 1 - Fold 5] F1-Score: 0.2246\n",
      "    [Trial 1 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     20478\n",
      "         1.0       0.15      0.42      0.22      1200\n",
      "\n",
      "    accuracy                           0.84     21678\n",
      "   macro avg       0.56      0.64      0.57     21678\n",
      "weighted avg       0.92      0.84      0.87     21678\n",
      "\n",
      "\n",
      "[Trial 1] Mean F1-Score across all folds: 0.2264\n",
      "\n",
      "[Trial 5] Starting with parameters: kernel=poly, C=1.5557, gamma=1.4030, tol=0.000019, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 5 - Fold 1/5] Preparing data...\n",
      "    [Trial 5 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 5 - Fold 1] Splitting features and target...\n",
      "    [Trial 5 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 5 - Fold 1] Training SVM model...\n",
      "    [Trial 2 - Fold 3] F1-Score: 0.1001\n",
      "    [Trial 2 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57     20478\n",
      "         1.0       0.05      0.58      0.10      1201\n",
      "\n",
      "    accuracy                           0.42     21679\n",
      "   macro avg       0.50      0.50      0.33     21679\n",
      "weighted avg       0.89      0.42      0.54     21679\n",
      "\n",
      "\n",
      "  [Trial 2 - Fold 4/5] Preparing data...\n",
      "    [Trial 2 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 2 - Fold 4] Splitting features and target...\n",
      "    [Trial 2 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 2 - Fold 4] Training SVM model...\n",
      "    [Trial 0 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 0 - Fold 2] F1-Score: 0.2352\n",
      "    [Trial 0 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.92     20479\n",
      "         1.0       0.16      0.42      0.24      1200\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.65      0.58     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 0 - Fold 3/5] Preparing data...\n",
      "    [Trial 0 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 0 - Fold 3] Splitting features and target...\n",
      "    [Trial 0 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 0 - Fold 3] Training SVM model...\n",
      "    [Trial 3 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 17:00:03,595] Trial 3 finished with value: 0.2533351052917944 and parameters: {'kernel': 'linear', 'C': 1.9031247087210839, 'gamma': 0.577661743534889, 'class_weight': 'balanced', 'shrinking': True, 'tol': 4.110423925467957e-05}. Best is trial 3 with value: 0.2533351052917944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 3 - Fold 5] F1-Score: 0.2591\n",
      "    [Trial 3 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20478\n",
      "         1.0       0.20      0.37      0.26      1200\n",
      "\n",
      "    accuracy                           0.88     21678\n",
      "   macro avg       0.58      0.64      0.60     21678\n",
      "weighted avg       0.92      0.88      0.90     21678\n",
      "\n",
      "\n",
      "[Trial 3] Mean F1-Score across all folds: 0.2533\n",
      "\n",
      "[Trial 6] Starting with parameters: kernel=poly, C=2.9337, gamma=0.3059, tol=0.000041, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 6 - Fold 1/5] Preparing data...\n",
      "    [Trial 6 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 6 - Fold 1] Splitting features and target...\n",
      "    [Trial 6 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 6 - Fold 1] Training SVM model...\n",
      "    [Trial 2 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 2 - Fold 4] F1-Score: 0.0939\n",
      "    [Trial 2 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57     20478\n",
      "         1.0       0.05      0.55      0.09      1201\n",
      "\n",
      "    accuracy                           0.42     21679\n",
      "   macro avg       0.50      0.48      0.33     21679\n",
      "weighted avg       0.89      0.42      0.54     21679\n",
      "\n",
      "\n",
      "  [Trial 2 - Fold 5/5] Preparing data...\n",
      "    [Trial 2 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 2 - Fold 5] Splitting features and target...\n",
      "    [Trial 2 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 2 - Fold 5] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 17:02:32,999] Trial 2 finished with value: 0.09595539606332129 and parameters: {'kernel': 'sigmoid', 'C': 25.673838214804586, 'gamma': 0.7110478788621873, 'class_weight': None, 'shrinking': True, 'tol': 0.00018797012490864078, 'coef0': 8.116630004646524}. Best is trial 3 with value: 0.2533351052917944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 2 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 6 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 6 - Fold 1] F1-Score: 0.2274\n",
      "    [Trial 6 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20479\n",
      "         1.0       0.16      0.39      0.23      1200\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.64      0.57     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 6 - Fold 2/5] Preparing data...\n",
      "    [Trial 6 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 6 - Fold 2] Splitting features and target...\n",
      "    [Trial 6 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 6 - Fold 2] Training SVM model...\n",
      "    [Trial 2 - Fold 5] F1-Score: 0.0966\n",
      "    [Trial 2 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.40      0.56     20478\n",
      "         1.0       0.05      0.57      0.10      1200\n",
      "\n",
      "    accuracy                           0.41     21678\n",
      "   macro avg       0.50      0.49      0.33     21678\n",
      "weighted avg       0.89      0.41      0.54     21678\n",
      "\n",
      "\n",
      "[Trial 2] Mean F1-Score across all folds: 0.0960\n",
      "\n",
      "[Trial 7] Starting with parameters: kernel=rbf, C=6.5718, gamma=0.3157, tol=0.000058, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 7 - Fold 1/5] Preparing data...\n",
      "    [Trial 7 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 7 - Fold 1] Splitting features and target...\n",
      "    [Trial 7 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 7 - Fold 1] Training SVM model...\n",
      "    [Trial 0 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 0 - Fold 3] F1-Score: 0.2222\n",
      "    [Trial 0 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.91     20478\n",
      "         1.0       0.15      0.41      0.22      1201\n",
      "\n",
      "    accuracy                           0.84     21679\n",
      "   macro avg       0.56      0.64      0.57     21679\n",
      "weighted avg       0.92      0.84      0.87     21679\n",
      "\n",
      "\n",
      "  [Trial 0 - Fold 4/5] Preparing data...\n",
      "    [Trial 0 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 0 - Fold 4] Splitting features and target...\n",
      "    [Trial 0 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 0 - Fold 4] Training SVM model...\n",
      "    [Trial 6 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 6 - Fold 2] F1-Score: 0.2323\n",
      "    [Trial 6 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20479\n",
      "         1.0       0.17      0.39      0.23      1200\n",
      "\n",
      "    accuracy                           0.86     21679\n",
      "   macro avg       0.56      0.64      0.58     21679\n",
      "weighted avg       0.92      0.86      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 6 - Fold 3/5] Preparing data...\n",
      "    [Trial 6 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 6 - Fold 3] Splitting features and target...\n",
      "    [Trial 6 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 6 - Fold 3] Training SVM model...\n",
      "    [Trial 7 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 7 - Fold 1] F1-Score: 0.1922\n",
      "    [Trial 7 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95     20479\n",
      "         1.0       0.20      0.19      0.19      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.57      0.57      0.57     21679\n",
      "weighted avg       0.91      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 7 - Fold 2/5] Preparing data...\n",
      "    [Trial 7 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 7 - Fold 2] Splitting features and target...\n",
      "    [Trial 7 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 7 - Fold 2] Training SVM model...\n",
      "    [Trial 5 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 5 - Fold 1] F1-Score: 0.2097\n",
      "    [Trial 5 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.85      0.90     20479\n",
      "         1.0       0.14      0.41      0.21      1200\n",
      "\n",
      "    accuracy                           0.83     21679\n",
      "   macro avg       0.55      0.63      0.56     21679\n",
      "weighted avg       0.92      0.83      0.87     21679\n",
      "\n",
      "\n",
      "  [Trial 5 - Fold 2/5] Preparing data...\n",
      "    [Trial 5 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 5 - Fold 2] Splitting features and target...\n",
      "    [Trial 5 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 5 - Fold 2] Training SVM model...\n",
      "    [Trial 0 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 0 - Fold 4] F1-Score: 0.2216\n",
      "    [Trial 0 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     20478\n",
      "         1.0       0.15      0.42      0.22      1201\n",
      "\n",
      "    accuracy                           0.84     21679\n",
      "   macro avg       0.56      0.64      0.57     21679\n",
      "weighted avg       0.92      0.84      0.87     21679\n",
      "\n",
      "\n",
      "  [Trial 0 - Fold 5/5] Preparing data...\n",
      "    [Trial 0 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 0 - Fold 5] Splitting features and target...\n",
      "    [Trial 0 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 0 - Fold 5] Training SVM model...\n",
      "    [Trial 6 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 6 - Fold 3] F1-Score: 0.2258\n",
      "    [Trial 6 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.89      0.92     20478\n",
      "         1.0       0.16      0.37      0.23      1201\n",
      "\n",
      "    accuracy                           0.86     21679\n",
      "   macro avg       0.56      0.63      0.57     21679\n",
      "weighted avg       0.92      0.86      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 6 - Fold 4/5] Preparing data...\n",
      "    [Trial 6 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 6 - Fold 4] Splitting features and target...\n",
      "    [Trial 6 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 6 - Fold 4] Training SVM model...\n",
      "    [Trial 7 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 7 - Fold 2] F1-Score: 0.2253\n",
      "    [Trial 7 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95     20479\n",
      "         1.0       0.22      0.23      0.23      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.59      0.59      0.59     21679\n",
      "weighted avg       0.91      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 7 - Fold 3/5] Preparing data...\n",
      "    [Trial 7 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 7 - Fold 3] Splitting features and target...\n",
      "    [Trial 7 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 7 - Fold 3] Training SVM model...\n",
      "    [Trial 6 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 6 - Fold 4] F1-Score: 0.2303\n",
      "    [Trial 6 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20478\n",
      "         1.0       0.16      0.40      0.23      1201\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.64      0.57     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 6 - Fold 5/5] Preparing data...\n",
      "    [Trial 6 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 6 - Fold 5] Splitting features and target...\n",
      "    [Trial 6 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 6 - Fold 5] Training SVM model...\n",
      "    [Trial 0 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:14:36,618] Trial 0 finished with value: 0.22324544778392372 and parameters: {'kernel': 'poly', 'C': 2.406128341747675, 'gamma': 1.5912239851961458, 'class_weight': None, 'shrinking': True, 'tol': 0.0008424693538662836, 'coef0': 2.1973162409290534, 'degree': 3}. Best is trial 3 with value: 0.2533351052917944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 0 - Fold 5] F1-Score: 0.2242\n",
      "    [Trial 0 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     20478\n",
      "         1.0       0.15      0.43      0.22      1200\n",
      "\n",
      "    accuracy                           0.84     21678\n",
      "   macro avg       0.56      0.64      0.57     21678\n",
      "weighted avg       0.92      0.84      0.87     21678\n",
      "\n",
      "\n",
      "[Trial 0] Mean F1-Score across all folds: 0.2232\n",
      "\n",
      "[Trial 8] Starting with parameters: kernel=sigmoid, C=52.2457, gamma=0.5700, tol=0.000162, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 8 - Fold 1/5] Preparing data...\n",
      "    [Trial 8 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 8 - Fold 1] Splitting features and target...\n",
      "    [Trial 8 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 8 - Fold 1] Training SVM model...\n",
      "    [Trial 8 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 7 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 8 - Fold 1] F1-Score: 0.1012\n",
      "    [Trial 8 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.59      0.72     20479\n",
      "         1.0       0.06      0.43      0.10      1200\n",
      "\n",
      "    accuracy                           0.58     21679\n",
      "   macro avg       0.50      0.51      0.41     21679\n",
      "weighted avg       0.90      0.58      0.69     21679\n",
      "\n",
      "\n",
      "  [Trial 8 - Fold 2/5] Preparing data...\n",
      "    [Trial 8 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 8 - Fold 2] Splitting features and target...\n",
      "    [Trial 8 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 8 - Fold 2] Training SVM model...\n",
      "    [Trial 8 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 8 - Fold 2] F1-Score: 0.1269\n",
      "    [Trial 8 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.60      0.73     20479\n",
      "         1.0       0.07      0.53      0.13      1200\n",
      "\n",
      "    accuracy                           0.59     21679\n",
      "   macro avg       0.51      0.57      0.43     21679\n",
      "weighted avg       0.91      0.59      0.70     21679\n",
      "\n",
      "\n",
      "  [Trial 8 - Fold 3/5] Preparing data...\n",
      "    [Trial 8 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 8 - Fold 3] Splitting features and target...\n",
      "    [Trial 8 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 8 - Fold 3] Training SVM model...\n",
      "    [Trial 4 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 7 - Fold 3] F1-Score: 0.2053\n",
      "    [Trial 7 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95     20478\n",
      "         1.0       0.21      0.20      0.21      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.58      0.58      0.58     21679\n",
      "weighted avg       0.91      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 7 - Fold 4/5] Preparing data...\n",
      "    [Trial 7 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 7 - Fold 4] Splitting features and target...\n",
      "    [Trial 7 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 7 - Fold 4] Training SVM model...\n",
      "    [Trial 4 - Fold 1] F1-Score: 0.2344\n",
      "    [Trial 4 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.19      0.32      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.59     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 4 - Fold 2/5] Preparing data...\n",
      "    [Trial 4 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 4 - Fold 2] Splitting features and target...\n",
      "    [Trial 4 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 4 - Fold 2] Training SVM model...\n",
      "    [Trial 8 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 5 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 5 - Fold 2] F1-Score: 0.2355\n",
      "    [Trial 5 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.91     20479\n",
      "         1.0       0.16      0.43      0.24      1200\n",
      "\n",
      "    accuracy                           0.84     21679\n",
      "   macro avg       0.56      0.65      0.57     21679\n",
      "weighted avg       0.92      0.84      0.88     21679\n",
      "\n",
      "\n",
      "  [Trial 5 - Fold 3/5] Preparing data...\n",
      "    [Trial 5 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 5 - Fold 3] Splitting features and target...\n",
      "    [Trial 5 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 5 - Fold 3] Training SVM model...\n",
      "    [Trial 8 - Fold 3] F1-Score: 0.1314\n",
      "    [Trial 8 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.60      0.74     20478\n",
      "         1.0       0.07      0.55      0.13      1201\n",
      "\n",
      "    accuracy                           0.60     21679\n",
      "   macro avg       0.52      0.58      0.43     21679\n",
      "weighted avg       0.91      0.60      0.70     21679\n",
      "\n",
      "\n",
      "  [Trial 8 - Fold 4/5] Preparing data...\n",
      "    [Trial 8 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 8 - Fold 4] Splitting features and target...\n",
      "    [Trial 8 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 8 - Fold 4] Training SVM model...\n",
      "    [Trial 8 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 6 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:16:38,938] Trial 6 finished with value: 0.22966893421961448 and parameters: {'kernel': 'poly', 'C': 2.9337330413896003, 'gamma': 0.3058871105951881, 'class_weight': 'balanced', 'shrinking': False, 'tol': 4.07518391584521e-05, 'coef0': 9.094229112702095, 'degree': 5}. Best is trial 3 with value: 0.2533351052917944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 6 - Fold 5] F1-Score: 0.2326\n",
      "    [Trial 6 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.91     20478\n",
      "         1.0       0.16      0.43      0.23      1200\n",
      "\n",
      "    accuracy                           0.84     21678\n",
      "   macro avg       0.56      0.65      0.57     21678\n",
      "weighted avg       0.92      0.84      0.88     21678\n",
      "\n",
      "\n",
      "[Trial 6] Mean F1-Score across all folds: 0.2297\n",
      "\n",
      "[Trial 9] Starting with parameters: kernel=sigmoid, C=2.4071, gamma=1.6598, tol=0.002549, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 9 - Fold 1/5] Preparing data...\n",
      "    [Trial 9 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 9 - Fold 1] Splitting features and target...\n",
      "    [Trial 9 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 9 - Fold 1] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:16:47,744] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 8 - Fold 4] F1-Score: 0.1262\n",
      "    [Trial 8 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.60      0.74     20478\n",
      "         1.0       0.07      0.53      0.13      1201\n",
      "\n",
      "    accuracy                           0.59     21679\n",
      "   macro avg       0.51      0.56      0.43     21679\n",
      "weighted avg       0.91      0.59      0.70     21679\n",
      "\n",
      "    [Trial 8] Trial pruned after Fold 4\n",
      "\n",
      "[Trial 10] Starting with parameters: kernel=poly, C=20.6824, gamma=8.2533, tol=0.003781, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 10 - Fold 1/5] Preparing data...\n",
      "    [Trial 10 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 10 - Fold 1] Splitting features and target...\n",
      "    [Trial 10 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 10 - Fold 1] Training SVM model...\n",
      "    [Trial 9 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:17:05,250] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 9 - Fold 1] F1-Score: 0.1231\n",
      "    [Trial 9 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.61      0.74     20479\n",
      "         1.0       0.07      0.51      0.12      1200\n",
      "\n",
      "    accuracy                           0.60     21679\n",
      "   macro avg       0.51      0.56      0.43     21679\n",
      "weighted avg       0.91      0.60      0.71     21679\n",
      "\n",
      "    [Trial 9] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 11] Starting with parameters: kernel=poly, C=0.8207, gamma=0.0371, tol=0.002352, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 11 - Fold 1/5] Preparing data...\n",
      "    [Trial 11 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 11 - Fold 1] Splitting features and target...\n",
      "    [Trial 11 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 11 - Fold 1] Training SVM model...\n",
      "    [Trial 7 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 11 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 11 - Fold 1] F1-Score: 0.2749\n",
      "    [Trial 11 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20479\n",
      "         1.0       0.21      0.40      0.27      1200\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 11 - Fold 2/5] Preparing data...\n",
      "    [Trial 11 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 11 - Fold 2] Splitting features and target...\n",
      "    [Trial 11 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 11 - Fold 2] Training SVM model...\n",
      "    [Trial 11 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 11 - Fold 2] F1-Score: 0.3144\n",
      "    [Trial 11 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20479\n",
      "         1.0       0.24      0.45      0.31      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.60      0.68      0.63     21679\n",
      "weighted avg       0.93      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 11 - Fold 3/5] Preparing data...\n",
      "    [Trial 11 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 11 - Fold 3] Splitting features and target...\n",
      "    [Trial 11 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 11 - Fold 3] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:17:53,575] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 7 - Fold 4] F1-Score: 0.2308\n",
      "    [Trial 7 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     20478\n",
      "         1.0       0.22      0.24      0.23      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.59      0.60      0.59     21679\n",
      "weighted avg       0.91      0.91      0.91     21679\n",
      "\n",
      "    [Trial 7] Trial pruned after Fold 4\n",
      "\n",
      "[Trial 12] Starting with parameters: kernel=rbf, C=47.7871, gamma=0.2991, tol=0.000949, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 12 - Fold 1/5] Preparing data...\n",
      "    [Trial 12 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 12 - Fold 1] Splitting features and target...\n",
      "    [Trial 12 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 12 - Fold 1] Training SVM model...\n",
      "    [Trial 11 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 10 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:17:59,854] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 10 - Fold 1] F1-Score: 0.2127\n",
      "    [Trial 10 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     20479\n",
      "         1.0       0.14      0.40      0.21      1200\n",
      "\n",
      "    accuracy                           0.84     21679\n",
      "   macro avg       0.55      0.63      0.56     21679\n",
      "weighted avg       0.92      0.84      0.87     21679\n",
      "\n",
      "    [Trial 10] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 13] Starting with parameters: kernel=linear, C=0.2857, gamma=0.0836, tol=0.002244, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 13 - Fold 1/5] Preparing data...\n",
      "    [Trial 13 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 13 - Fold 1] Splitting features and target...\n",
      "    [Trial 13 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 13 - Fold 1] Training SVM model...\n",
      "    [Trial 11 - Fold 3] F1-Score: 0.2888\n",
      "    [Trial 11 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.22      0.41      0.29      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.66      0.61     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 11 - Fold 4/5] Preparing data...\n",
      "    [Trial 11 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 11 - Fold 4] Splitting features and target...\n",
      "    [Trial 11 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 11 - Fold 4] Training SVM model...\n",
      "    [Trial 13 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 11 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 13 - Fold 1] F1-Score: 0.2310\n",
      "    [Trial 13 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.18      0.31      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.58     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 13 - Fold 2/5] Preparing data...\n",
      "    [Trial 13 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 13 - Fold 2] Splitting features and target...\n",
      "    [Trial 13 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 13 - Fold 2] Training SVM model...\n",
      "    [Trial 11 - Fold 4] F1-Score: 0.3075\n",
      "    [Trial 11 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.24      0.44      0.31      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.60      0.68      0.62     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 11 - Fold 5/5] Preparing data...\n",
      "    [Trial 11 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 11 - Fold 5] Splitting features and target...\n",
      "    [Trial 11 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 11 - Fold 5] Training SVM model...\n",
      "    [Trial 13 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 13 - Fold 2] F1-Score: 0.2777\n",
      "    [Trial 13 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 13 - Fold 3/5] Preparing data...\n",
      "    [Trial 13 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 13 - Fold 3] Splitting features and target...\n",
      "    [Trial 13 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 13 - Fold 3] Training SVM model...\n",
      "    [Trial 11 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:18:43,415] Trial 11 finished with value: 0.29695729680672045 and parameters: {'kernel': 'poly', 'C': 0.8206602148941851, 'gamma': 0.037129923519189, 'class_weight': None, 'shrinking': False, 'tol': 0.002351739040260563, 'coef0': 0.5572297028187234, 'degree': 4}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 11 - Fold 5] F1-Score: 0.2993\n",
      "    [Trial 11 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.91      0.94     20478\n",
      "         1.0       0.23      0.44      0.30      1200\n",
      "\n",
      "    accuracy                           0.89     21678\n",
      "   macro avg       0.60      0.68      0.62     21678\n",
      "weighted avg       0.92      0.89      0.90     21678\n",
      "\n",
      "\n",
      "[Trial 11] Mean F1-Score across all folds: 0.2970\n",
      "\n",
      "[Trial 14] Starting with parameters: kernel=rbf, C=0.1973, gamma=0.0142, tol=0.007921, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 14 - Fold 1/5] Preparing data...\n",
      "    [Trial 14 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 14 - Fold 1] Splitting features and target...\n",
      "    [Trial 14 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 14 - Fold 1] Training SVM model...\n",
      "    [Trial 13 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 12 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 14 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 13 - Fold 3] F1-Score: 0.2301\n",
      "    [Trial 13 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.20      0.27      0.23      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.60      0.59     21679\n",
      "weighted avg       0.91      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 13 - Fold 4/5] Preparing data...\n",
      "    [Trial 13 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 13 - Fold 4] Splitting features and target...\n",
      "    [Trial 13 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 13 - Fold 4] Training SVM model...\n",
      "    [Trial 13 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 13 - Fold 4] F1-Score: 0.2540\n",
      "    [Trial 13 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.21      0.32      0.25      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.58      0.63      0.60     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 13 - Fold 5/5] Preparing data...\n",
      "    [Trial 13 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 13 - Fold 5] Splitting features and target...\n",
      "    [Trial 13 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 13 - Fold 5] Training SVM model...\n",
      "    [Trial 14 - Fold 1] F1-Score: 0.2505\n",
      "    [Trial 14 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.22      0.30      0.25      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.59      0.62      0.60     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 14 - Fold 2/5] Preparing data...\n",
      "    [Trial 14 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 14 - Fold 2] Splitting features and target...\n",
      "    [Trial 14 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 14 - Fold 2] Training SVM model...\n",
      "    [Trial 13 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 14 - Fold 2] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:19:26,208] Trial 13 finished with value: 0.2496838692623114 and parameters: {'kernel': 'linear', 'C': 0.2857203410994943, 'gamma': 0.0836078304094812, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.002243837694631225}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 13 - Fold 5] F1-Score: 0.2556\n",
      "    [Trial 13 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20478\n",
      "         1.0       0.20      0.36      0.26      1200\n",
      "\n",
      "    accuracy                           0.88     21678\n",
      "   macro avg       0.58      0.64      0.60     21678\n",
      "weighted avg       0.92      0.88      0.90     21678\n",
      "\n",
      "\n",
      "[Trial 13] Mean F1-Score across all folds: 0.2497\n",
      "\n",
      "[Trial 15] Starting with parameters: kernel=linear, C=0.3941, gamma=0.0144, tol=0.000010, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 15 - Fold 1/5] Preparing data...\n",
      "    [Trial 15 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 15 - Fold 1] Splitting features and target...\n",
      "    [Trial 15 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 15 - Fold 1] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:19:33,231] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 12 - Fold 1] F1-Score: 0.1954\n",
      "    [Trial 12 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95     20479\n",
      "         1.0       0.20      0.19      0.20      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.57      0.57      0.57     21679\n",
      "weighted avg       0.91      0.91      0.91     21679\n",
      "\n",
      "    [Trial 12] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 16] Starting with parameters: kernel=linear, C=0.4360, gamma=0.0131, tol=0.000010, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 16 - Fold 1/5] Preparing data...\n",
      "    [Trial 16 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 16 - Fold 1] Splitting features and target...\n",
      "    [Trial 16 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 16 - Fold 1] Training SVM model...\n",
      "    [Trial 14 - Fold 2] F1-Score: 0.2831\n",
      "    [Trial 14 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.25      0.33      0.28      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.64      0.62     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 14 - Fold 3/5] Preparing data...\n",
      "    [Trial 14 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 14 - Fold 3] Splitting features and target...\n",
      "    [Trial 14 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 14 - Fold 3] Training SVM model...\n",
      "    [Trial 14 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 14 - Fold 3] F1-Score: 0.2495\n",
      "    [Trial 14 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     20478\n",
      "         1.0       0.23      0.28      0.25      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.59      0.61      0.60     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 14 - Fold 4/5] Preparing data...\n",
      "    [Trial 14 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 14 - Fold 4] Splitting features and target...\n",
      "    [Trial 14 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 14 - Fold 4] Training SVM model...\n",
      "    [Trial 14 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 5 - Fold 3] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:20:45,692] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 5 - Fold 3] F1-Score: 0.2206\n",
      "    [Trial 5 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     20478\n",
      "         1.0       0.15      0.43      0.22      1201\n",
      "\n",
      "    accuracy                           0.83     21679\n",
      "   macro avg       0.56      0.64      0.56     21679\n",
      "weighted avg       0.92      0.83      0.87     21679\n",
      "\n",
      "    [Trial 5] Trial pruned after Fold 3\n",
      "\n",
      "[Trial 17] Starting with parameters: kernel=linear, C=0.4426, gamma=0.0164, tol=0.000011, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 17 - Fold 1/5] Preparing data...\n",
      "    [Trial 17 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 17 - Fold 1] Splitting features and target...\n",
      "    [Trial 17 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 17 - Fold 1] Training SVM model...\n",
      "    [Trial 14 - Fold 4] F1-Score: 0.2703\n",
      "    [Trial 14 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.24      0.31      0.27      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.63      0.61     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 14 - Fold 5/5] Preparing data...\n",
      "    [Trial 14 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 14 - Fold 5] Splitting features and target...\n",
      "    [Trial 14 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 14 - Fold 5] Training SVM model...\n",
      "    [Trial 14 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 15 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 15 - Fold 1] F1-Score: 0.2303\n",
      "    [Trial 15 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.18      0.31      0.23      1200\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.57      0.61      0.58     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 15 - Fold 2/5] Preparing data...\n",
      "    [Trial 15 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 15 - Fold 2] Splitting features and target...\n",
      "    [Trial 15 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 15 - Fold 2] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:21:21,486] Trial 14 finished with value: 0.26438714629430515 and parameters: {'kernel': 'rbf', 'C': 0.19728839864675946, 'gamma': 0.014154011415044089, 'class_weight': 'balanced', 'shrinking': False, 'tol': 0.007920654900987666}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 14 - Fold 5] F1-Score: 0.2685\n",
      "    [Trial 14 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.23      0.33      0.27      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.59      0.63      0.61     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 14] Mean F1-Score across all folds: 0.2644\n",
      "\n",
      "[Trial 18] Starting with parameters: kernel=rbf, C=0.1682, gamma=0.0141, tol=0.009786, class_weight=balanced, shrinking=False\n",
      "\n",
      "  [Trial 18 - Fold 1/5] Preparing data...\n",
      "    [Trial 18 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 18 - Fold 1] Splitting features and target...\n",
      "    [Trial 18 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 18 - Fold 1] Training SVM model...\n",
      "    [Trial 18 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 16 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 16 - Fold 1] F1-Score: 0.2312\n",
      "    [Trial 16 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.18      0.31      0.23      1200\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.57      0.62      0.58     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 16 - Fold 2/5] Preparing data...\n",
      "    [Trial 16 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 16 - Fold 2] Splitting features and target...\n",
      "    [Trial 16 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 16 - Fold 2] Training SVM model...\n",
      "    [Trial 18 - Fold 1] F1-Score: 0.2455\n",
      "    [Trial 18 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.21      0.29      0.25      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.60     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 18 - Fold 2/5] Preparing data...\n",
      "    [Trial 18 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 18 - Fold 2] Splitting features and target...\n",
      "    [Trial 18 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 18 - Fold 2] Training SVM model...\n",
      "    [Trial 18 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 17 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 17 - Fold 1] F1-Score: 0.2313\n",
      "    [Trial 17 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.18      0.31      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.58     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 17 - Fold 2/5] Preparing data...\n",
      "    [Trial 17 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 17 - Fold 2] Splitting features and target...\n",
      "    [Trial 17 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 17 - Fold 2] Training SVM model...\n",
      "    [Trial 18 - Fold 2] F1-Score: 0.2755\n",
      "    [Trial 18 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.24      0.32      0.28      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.63      0.61     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 18 - Fold 3/5] Preparing data...\n",
      "    [Trial 18 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 18 - Fold 3] Splitting features and target...\n",
      "    [Trial 18 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 18 - Fold 3] Training SVM model...\n",
      "    [Trial 18 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 15 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 15 - Fold 2] F1-Score: 0.2785\n",
      "    [Trial 15 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 15 - Fold 3/5] Preparing data...\n",
      "    [Trial 15 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 15 - Fold 3] Splitting features and target...\n",
      "    [Trial 15 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 15 - Fold 3] Training SVM model...\n",
      "    [Trial 18 - Fold 3] F1-Score: 0.2370\n",
      "    [Trial 18 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     20478\n",
      "         1.0       0.22      0.25      0.24      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.59      0.60      0.59     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 18 - Fold 4/5] Preparing data...\n",
      "    [Trial 18 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 18 - Fold 4] Splitting features and target...\n",
      "    [Trial 18 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 18 - Fold 4] Training SVM model...\n",
      "    [Trial 18 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 17 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 17 - Fold 2] F1-Score: 0.2791\n",
      "    [Trial 17 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 17 - Fold 3/5] Preparing data...\n",
      "    [Trial 17 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 17 - Fold 3] Splitting features and target...\n",
      "    [Trial 17 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 17 - Fold 3] Training SVM model...\n",
      "    [Trial 18 - Fold 4] F1-Score: 0.2666\n",
      "    [Trial 18 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.24      0.30      0.27      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.62      0.61     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 18 - Fold 5/5] Preparing data...\n",
      "    [Trial 18 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 18 - Fold 5] Splitting features and target...\n",
      "    [Trial 18 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 18 - Fold 5] Training SVM model...\n",
      "    [Trial 18 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 16 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 16 - Fold 2] F1-Score: 0.2792\n",
      "    [Trial 16 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 16 - Fold 3/5] Preparing data...\n",
      "    [Trial 16 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 16 - Fold 3] Splitting features and target...\n",
      "    [Trial 16 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 16 - Fold 3] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:23:47,769] Trial 18 finished with value: 0.2580579104058828 and parameters: {'kernel': 'rbf', 'C': 0.1682068670434883, 'gamma': 0.01412158937822382, 'class_weight': 'balanced', 'shrinking': False, 'tol': 0.00978607543158554}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 18 - Fold 5] F1-Score: 0.2656\n",
      "    [Trial 18 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.23      0.32      0.27      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.59      0.63      0.61     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 18] Mean F1-Score across all folds: 0.2581\n",
      "\n",
      "[Trial 19] Starting with parameters: kernel=rbf, C=0.4627, gamma=0.0103, tol=0.008171, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 19 - Fold 1/5] Preparing data...\n",
      "    [Trial 19 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 19 - Fold 1] Splitting features and target...\n",
      "    [Trial 19 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 19 - Fold 1] Training SVM model...\n",
      "    [Trial 19 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 19 - Fold 1] F1-Score: 0.2618\n",
      "    [Trial 19 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.22      0.33      0.26      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.59      0.63      0.60     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 19 - Fold 2/5] Preparing data...\n",
      "    [Trial 19 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 19 - Fold 2] Splitting features and target...\n",
      "    [Trial 19 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 19 - Fold 2] Training SVM model...\n",
      "    [Trial 19 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 19 - Fold 2] F1-Score: 0.2886\n",
      "    [Trial 19 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.25      0.35      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.64      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 19 - Fold 3/5] Preparing data...\n",
      "    [Trial 19 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 19 - Fold 3] Splitting features and target...\n",
      "    [Trial 19 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 19 - Fold 3] Training SVM model...\n",
      "    [Trial 19 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 19 - Fold 3] F1-Score: 0.2628\n",
      "    [Trial 19 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.23      0.31      0.26      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.59      0.62      0.61     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 19 - Fold 4/5] Preparing data...\n",
      "    [Trial 19 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 19 - Fold 4] Splitting features and target...\n",
      "    [Trial 19 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 19 - Fold 4] Training SVM model...\n",
      "    [Trial 16 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 19 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 16 - Fold 3] F1-Score: 0.2320\n",
      "    [Trial 16 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.20      0.28      0.23      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.59     21679\n",
      "weighted avg       0.91      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 16 - Fold 4/5] Preparing data...\n",
      "    [Trial 16 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 16 - Fold 4] Splitting features and target...\n",
      "    [Trial 16 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 16 - Fold 4] Training SVM model...\n",
      "    [Trial 19 - Fold 4] F1-Score: 0.2860\n",
      "    [Trial 19 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.24      0.35      0.29      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.64      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 19 - Fold 5/5] Preparing data...\n",
      "    [Trial 19 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 19 - Fold 5] Splitting features and target...\n",
      "    [Trial 19 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 19 - Fold 5] Training SVM model...\n",
      "    [Trial 19 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 4 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 4 - Fold 2] F1-Score: 0.2786\n",
      "    [Trial 4 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 4 - Fold 3/5] Preparing data...\n",
      "    [Trial 4 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 4 - Fold 3] Splitting features and target...\n",
      "    [Trial 4 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 4 - Fold 3] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:25:55,700] Trial 19 finished with value: 0.27676439742304015 and parameters: {'kernel': 'rbf', 'C': 0.4626690870237939, 'gamma': 0.010255615622128657, 'class_weight': None, 'shrinking': False, 'tol': 0.008171494866648381}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 19 - Fold 5] F1-Score: 0.2846\n",
      "    [Trial 19 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.23      0.36      0.28      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.60      0.65      0.62     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 19] Mean F1-Score across all folds: 0.2768\n",
      "\n",
      "[Trial 20] Starting with parameters: kernel=rbf, C=0.6817, gamma=0.0415, tol=0.000435, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 20 - Fold 1/5] Preparing data...\n",
      "    [Trial 20 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 20 - Fold 1] Splitting features and target...\n",
      "    [Trial 20 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 20 - Fold 1] Training SVM model...\n",
      "    [Trial 20 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 15 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 15 - Fold 3] F1-Score: 0.2322\n",
      "    [Trial 15 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.20      0.28      0.23      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.59     21679\n",
      "weighted avg       0.91      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 15 - Fold 4/5] Preparing data...\n",
      "    [Trial 15 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 15 - Fold 4] Splitting features and target...\n",
      "    [Trial 15 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 15 - Fold 4] Training SVM model...\n",
      "    [Trial 20 - Fold 1] F1-Score: 0.2662\n",
      "    [Trial 20 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.23      0.31      0.27      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.62      0.61     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 20 - Fold 2/5] Preparing data...\n",
      "    [Trial 20 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 20 - Fold 2] Splitting features and target...\n",
      "    [Trial 20 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 20 - Fold 2] Training SVM model...\n",
      "    [Trial 20 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 16 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 20 - Fold 2] F1-Score: 0.3125\n",
      "    [Trial 20 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.27      0.37      0.31      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.62      0.66      0.63     21679\n",
      "weighted avg       0.92      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 20 - Fold 3/5] Preparing data...\n",
      "    [Trial 20 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 20 - Fold 3] Splitting features and target...\n",
      "    [Trial 20 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 20 - Fold 3] Training SVM model...\n",
      "    [Trial 16 - Fold 4] F1-Score: 0.2575\n",
      "    [Trial 16 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.21      0.33      0.26      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.63      0.60     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 16 - Fold 5/5] Preparing data...\n",
      "    [Trial 16 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 16 - Fold 5] Splitting features and target...\n",
      "    [Trial 16 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 16 - Fold 5] Training SVM model...\n",
      "    [Trial 20 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 15 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 15 - Fold 4] F1-Score: 0.2563\n",
      "    [Trial 15 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.21      0.33      0.26      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.58      0.63      0.60     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 15 - Fold 5/5] Preparing data...\n",
      "    [Trial 15 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 15 - Fold 5] Splitting features and target...\n",
      "    [Trial 15 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 15 - Fold 5] Training SVM model...\n",
      "    [Trial 20 - Fold 3] F1-Score: 0.2740\n",
      "    [Trial 20 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.24      0.31      0.27      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.63      0.61     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 20 - Fold 4/5] Preparing data...\n",
      "    [Trial 20 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 20 - Fold 4] Splitting features and target...\n",
      "    [Trial 20 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 20 - Fold 4] Training SVM model...\n",
      "    [Trial 20 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 20 - Fold 4] F1-Score: 0.3003\n",
      "    [Trial 20 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.26      0.36      0.30      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.61      0.65      0.63     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 20 - Fold 5/5] Preparing data...\n",
      "    [Trial 20 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 20 - Fold 5] Splitting features and target...\n",
      "    [Trial 20 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 20 - Fold 5] Training SVM model...\n",
      "    [Trial 20 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:28:12,780] Trial 20 finished with value: 0.2877734796890699 and parameters: {'kernel': 'rbf', 'C': 0.6816554726664313, 'gamma': 0.041464337677018015, 'class_weight': None, 'shrinking': False, 'tol': 0.00043465169474532305}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 20 - Fold 5] F1-Score: 0.2858\n",
      "    [Trial 20 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.34      0.29      1200\n",
      "\n",
      "    accuracy                           0.91     21678\n",
      "   macro avg       0.60      0.64      0.62     21678\n",
      "weighted avg       0.92      0.91      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 20] Mean F1-Score across all folds: 0.2878\n",
      "\n",
      "[Trial 21] Starting with parameters: kernel=linear, C=0.7108, gamma=0.0455, tol=0.000416, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 21 - Fold 1/5] Preparing data...\n",
      "    [Trial 21 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 21 - Fold 1] Splitting features and target...\n",
      "    [Trial 21 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 21 - Fold 1] Training SVM model...\n",
      "    [Trial 17 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 17 - Fold 3] F1-Score: 0.2319\n",
      "    [Trial 17 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.20      0.28      0.23      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.59     21679\n",
      "weighted avg       0.91      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 17 - Fold 4/5] Preparing data...\n",
      "    [Trial 17 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 17 - Fold 4] Splitting features and target...\n",
      "    [Trial 17 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 17 - Fold 4] Training SVM model...\n",
      "    [Trial 15 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:28:37,783] Trial 15 finished with value: 0.2506238593881304 and parameters: {'kernel': 'linear', 'C': 0.39412354325768917, 'gamma': 0.01439996630406429, 'class_weight': 'balanced', 'shrinking': False, 'tol': 1.0127165776356057e-05}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 15 - Fold 5] F1-Score: 0.2558\n",
      "    [Trial 15 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20478\n",
      "         1.0       0.20      0.36      0.26      1200\n",
      "\n",
      "    accuracy                           0.88     21678\n",
      "   macro avg       0.58      0.64      0.60     21678\n",
      "weighted avg       0.92      0.88      0.90     21678\n",
      "\n",
      "\n",
      "[Trial 15] Mean F1-Score across all folds: 0.2506\n",
      "\n",
      "[Trial 22] Starting with parameters: kernel=poly, C=0.7626, gamma=0.0459, tol=0.000416, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 22 - Fold 1/5] Preparing data...\n",
      "    [Trial 22 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 22 - Fold 1] Splitting features and target...\n",
      "    [Trial 22 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 22 - Fold 1] Training SVM model...\n",
      "    [Trial 21 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 21 - Fold 1] F1-Score: 0.2322\n",
      "    [Trial 21 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.18      0.31      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.59     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 21 - Fold 2/5] Preparing data...\n",
      "    [Trial 21 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 21 - Fold 2] Splitting features and target...\n",
      "    [Trial 21 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 21 - Fold 2] Training SVM model...\n",
      "    [Trial 16 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:29:40,728] Trial 16 finished with value: 0.25107727123024726 and parameters: {'kernel': 'linear', 'C': 0.4359587650633219, 'gamma': 0.01310801343119748, 'class_weight': 'balanced', 'shrinking': False, 'tol': 1.0025710873966212e-05}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 16 - Fold 5] F1-Score: 0.2555\n",
      "    [Trial 16 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20478\n",
      "         1.0       0.20      0.36      0.26      1200\n",
      "\n",
      "    accuracy                           0.88     21678\n",
      "   macro avg       0.58      0.64      0.60     21678\n",
      "weighted avg       0.92      0.88      0.90     21678\n",
      "\n",
      "\n",
      "[Trial 16] Mean F1-Score across all folds: 0.2511\n",
      "\n",
      "[Trial 23] Starting with parameters: kernel=poly, C=0.7194, gamma=0.0642, tol=0.000439, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 23 - Fold 1/5] Preparing data...\n",
      "    [Trial 23 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 23 - Fold 1] Splitting features and target...\n",
      "    [Trial 23 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 23 - Fold 1] Training SVM model...\n",
      "    [Trial 17 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 17 - Fold 4] F1-Score: 0.2580\n",
      "    [Trial 17 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.21      0.33      0.26      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.63      0.60     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 17 - Fold 5/5] Preparing data...\n",
      "    [Trial 17 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 17 - Fold 5] Splitting features and target...\n",
      "    [Trial 17 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 17 - Fold 5] Training SVM model...\n",
      "    [Trial 22 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 22 - Fold 1] F1-Score: 0.2605\n",
      "    [Trial 22 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20479\n",
      "         1.0       0.19      0.40      0.26      1200\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.58      0.65      0.60     21679\n",
      "weighted avg       0.92      0.88      0.89     21679\n",
      "\n",
      "\n",
      "  [Trial 22 - Fold 2/5] Preparing data...\n",
      "    [Trial 22 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 22 - Fold 2] Splitting features and target...\n",
      "    [Trial 22 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 22 - Fold 2] Training SVM model...\n",
      "    [Trial 21 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 21 - Fold 2] F1-Score: 0.2797\n",
      "    [Trial 21 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 21 - Fold 3/5] Preparing data...\n",
      "    [Trial 21 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 21 - Fold 3] Splitting features and target...\n",
      "    [Trial 21 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 21 - Fold 3] Training SVM model...\n",
      "    [Trial 23 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 23 - Fold 1] F1-Score: 0.2563\n",
      "    [Trial 23 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20479\n",
      "         1.0       0.19      0.41      0.26      1200\n",
      "\n",
      "    accuracy                           0.87     21679\n",
      "   macro avg       0.57      0.65      0.59     21679\n",
      "weighted avg       0.92      0.87      0.89     21679\n",
      "\n",
      "\n",
      "  [Trial 23 - Fold 2/5] Preparing data...\n",
      "    [Trial 23 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 23 - Fold 2] Splitting features and target...\n",
      "    [Trial 23 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 23 - Fold 2] Training SVM model...\n",
      "    [Trial 21 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 21 - Fold 3] F1-Score: 0.2335\n",
      "    [Trial 21 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.20      0.28      0.23      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.59     21679\n",
      "weighted avg       0.91      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 21 - Fold 4/5] Preparing data...\n",
      "    [Trial 21 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 21 - Fold 4] Splitting features and target...\n",
      "    [Trial 21 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 21 - Fold 4] Training SVM model...\n",
      "    [Trial 22 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 17 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 22 - Fold 2] F1-Score: 0.2696\n",
      "    [Trial 22 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.93     20479\n",
      "         1.0       0.20      0.40      0.27      1200\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.58      0.66      0.60     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 22 - Fold 3/5] Preparing data...\n",
      "    [Trial 22 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 22 - Fold 3] Splitting features and target...\n",
      "    [Trial 22 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 22 - Fold 3] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:40:21,952] Trial 17 finished with value: 0.25112279757743905 and parameters: {'kernel': 'linear', 'C': 0.4425902780724398, 'gamma': 0.016415455033486705, 'class_weight': 'balanced', 'shrinking': False, 'tol': 1.1200049864854187e-05}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 17 - Fold 5] F1-Score: 0.2554\n",
      "    [Trial 17 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20478\n",
      "         1.0       0.20      0.36      0.26      1200\n",
      "\n",
      "    accuracy                           0.88     21678\n",
      "   macro avg       0.58      0.64      0.60     21678\n",
      "weighted avg       0.92      0.88      0.90     21678\n",
      "\n",
      "\n",
      "[Trial 17] Mean F1-Score across all folds: 0.2511\n",
      "\n",
      "[Trial 24] Starting with parameters: kernel=poly, C=1.0680, gamma=0.0577, tol=0.000521, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 24 - Fold 1/5] Preparing data...\n",
      "    [Trial 24 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 24 - Fold 1] Splitting features and target...\n",
      "    [Trial 24 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 24 - Fold 1] Training SVM model...\n",
      "    [Trial 21 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 21 - Fold 4] F1-Score: 0.2587\n",
      "    [Trial 21 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.21      0.33      0.26      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.63      0.60     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 21 - Fold 5/5] Preparing data...\n",
      "    [Trial 21 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 21 - Fold 5] Splitting features and target...\n",
      "    [Trial 21 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 21 - Fold 5] Training SVM model...\n",
      "    [Trial 23 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 23 - Fold 2] F1-Score: 0.2543\n",
      "    [Trial 23 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20479\n",
      "         1.0       0.19      0.40      0.25      1200\n",
      "\n",
      "    accuracy                           0.87     21679\n",
      "   macro avg       0.57      0.65      0.59     21679\n",
      "weighted avg       0.92      0.87      0.89     21679\n",
      "\n",
      "\n",
      "  [Trial 23 - Fold 3/5] Preparing data...\n",
      "    [Trial 23 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 23 - Fold 3] Splitting features and target...\n",
      "    [Trial 23 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 23 - Fold 3] Training SVM model...\n",
      "    [Trial 21 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:42:13,851] Trial 21 finished with value: 0.2520294678586332 and parameters: {'kernel': 'linear', 'C': 0.7108438876663343, 'gamma': 0.04545697924330491, 'class_weight': None, 'shrinking': False, 'tol': 0.00041609980640295864}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 21 - Fold 5] F1-Score: 0.2560\n",
      "    [Trial 21 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20478\n",
      "         1.0       0.20      0.36      0.26      1200\n",
      "\n",
      "    accuracy                           0.88     21678\n",
      "   macro avg       0.58      0.64      0.60     21678\n",
      "weighted avg       0.92      0.88      0.90     21678\n",
      "\n",
      "\n",
      "[Trial 21] Mean F1-Score across all folds: 0.2520\n",
      "\n",
      "[Trial 25] Starting with parameters: kernel=rbf, C=1.1241, gamma=0.0420, tol=0.004966, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 25 - Fold 1/5] Preparing data...\n",
      "    [Trial 25 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 25 - Fold 1] Splitting features and target...\n",
      "    [Trial 25 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 25 - Fold 1] Training SVM model...\n",
      "    [Trial 24 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 25 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 24 - Fold 1] F1-Score: 0.2560\n",
      "    [Trial 24 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20479\n",
      "         1.0       0.19      0.41      0.26      1200\n",
      "\n",
      "    accuracy                           0.87     21679\n",
      "   macro avg       0.57      0.65      0.59     21679\n",
      "weighted avg       0.92      0.87      0.89     21679\n",
      "\n",
      "\n",
      "  [Trial 24 - Fold 2/5] Preparing data...\n",
      "    [Trial 24 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 24 - Fold 2] Splitting features and target...\n",
      "    [Trial 24 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 24 - Fold 2] Training SVM model...\n",
      "    [Trial 22 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 22 - Fold 3] F1-Score: 0.2749\n",
      "    [Trial 22 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20478\n",
      "         1.0       0.21      0.39      0.27      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 22 - Fold 4/5] Preparing data...\n",
      "    [Trial 22 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 22 - Fold 4] Splitting features and target...\n",
      "    [Trial 22 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 22 - Fold 4] Training SVM model...\n",
      "    [Trial 25 - Fold 1] F1-Score: 0.2676\n",
      "    [Trial 25 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.23      0.31      0.27      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.63      0.61     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 25 - Fold 2/5] Preparing data...\n",
      "    [Trial 25 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 25 - Fold 2] Splitting features and target...\n",
      "    [Trial 25 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 25 - Fold 2] Training SVM model...\n",
      "    [Trial 25 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 25 - Fold 2] F1-Score: 0.3218\n",
      "    [Trial 25 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.28      0.38      0.32      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.62      0.66      0.64     21679\n",
      "weighted avg       0.93      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 25 - Fold 3/5] Preparing data...\n",
      "    [Trial 25 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 25 - Fold 3] Splitting features and target...\n",
      "    [Trial 25 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 25 - Fold 3] Training SVM model...\n",
      "    [Trial 25 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 23 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 23 - Fold 3] F1-Score: 0.2592\n",
      "    [Trial 23 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.93     20478\n",
      "         1.0       0.20      0.38      0.26      1201\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.58      0.65      0.60     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 23 - Fold 4/5] Preparing data...\n",
      "    [Trial 23 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 23 - Fold 4] Splitting features and target...\n",
      "    [Trial 23 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 23 - Fold 4] Training SVM model...\n",
      "    [Trial 25 - Fold 3] F1-Score: 0.2788\n",
      "    [Trial 25 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.32      0.28      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.63      0.61     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 25 - Fold 4/5] Preparing data...\n",
      "    [Trial 25 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 25 - Fold 4] Splitting features and target...\n",
      "    [Trial 25 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 25 - Fold 4] Training SVM model...\n",
      "    [Trial 25 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 25 - Fold 4] F1-Score: 0.3077\n",
      "    [Trial 25 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.26      0.37      0.31      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.61      0.65      0.63     21679\n",
      "weighted avg       0.92      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 25 - Fold 5/5] Preparing data...\n",
      "    [Trial 25 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 25 - Fold 5] Splitting features and target...\n",
      "    [Trial 25 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 25 - Fold 5] Training SVM model...\n",
      "    [Trial 25 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 24 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 24 - Fold 2] F1-Score: 0.2555\n",
      "    [Trial 24 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20479\n",
      "         1.0       0.19      0.40      0.26      1200\n",
      "\n",
      "    accuracy                           0.87     21679\n",
      "   macro avg       0.58      0.65      0.59     21679\n",
      "weighted avg       0.92      0.87      0.89     21679\n",
      "\n",
      "\n",
      "  [Trial 24 - Fold 3/5] Preparing data...\n",
      "    [Trial 24 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 24 - Fold 3] Splitting features and target...\n",
      "    [Trial 24 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 24 - Fold 3] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:44:43,834] Trial 25 finished with value: 0.294253980031008 and parameters: {'kernel': 'rbf', 'C': 1.1241157201340788, 'gamma': 0.042034529800320644, 'class_weight': None, 'shrinking': False, 'tol': 0.0049658353228613636}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 25 - Fold 5] F1-Score: 0.2954\n",
      "    [Trial 25 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.36      0.30      1200\n",
      "\n",
      "    accuracy                           0.91     21678\n",
      "   macro avg       0.61      0.65      0.62     21678\n",
      "weighted avg       0.92      0.91      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 25] Mean F1-Score across all folds: 0.2943\n",
      "\n",
      "[Trial 26] Starting with parameters: kernel=rbf, C=0.9821, gamma=0.0454, tol=0.000452, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 26 - Fold 1/5] Preparing data...\n",
      "    [Trial 26 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 26 - Fold 1] Splitting features and target...\n",
      "    [Trial 26 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 26 - Fold 1] Training SVM model...\n",
      "    [Trial 26 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 26 - Fold 1] F1-Score: 0.2645\n",
      "    [Trial 26 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.23      0.31      0.26      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.62      0.61     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 26 - Fold 2/5] Preparing data...\n",
      "    [Trial 26 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 26 - Fold 2] Splitting features and target...\n",
      "    [Trial 26 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 26 - Fold 2] Training SVM model...\n",
      "    [Trial 26 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 22 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 22 - Fold 4] F1-Score: 0.2872\n",
      "    [Trial 22 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94     20478\n",
      "         1.0       0.22      0.42      0.29      1201\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.66      0.61     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 22 - Fold 5/5] Preparing data...\n",
      "    [Trial 22 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 22 - Fold 5] Splitting features and target...\n",
      "    [Trial 22 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 22 - Fold 5] Training SVM model...\n",
      "    [Trial 26 - Fold 2] F1-Score: 0.3221\n",
      "    [Trial 26 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.28      0.38      0.32      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.62      0.66      0.64     21679\n",
      "weighted avg       0.93      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 26 - Fold 3/5] Preparing data...\n",
      "    [Trial 26 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 26 - Fold 3] Splitting features and target...\n",
      "    [Trial 26 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 26 - Fold 3] Training SVM model...\n",
      "    [Trial 26 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 23 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 23 - Fold 4] F1-Score: 0.2690\n",
      "    [Trial 23 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20478\n",
      "         1.0       0.20      0.41      0.27      1201\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.58      0.66      0.60     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 23 - Fold 5/5] Preparing data...\n",
      "    [Trial 23 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 23 - Fold 5] Splitting features and target...\n",
      "    [Trial 23 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 23 - Fold 5] Training SVM model...\n",
      "    [Trial 26 - Fold 3] F1-Score: 0.2792\n",
      "    [Trial 26 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.32      0.28      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.63      0.62     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 26 - Fold 4/5] Preparing data...\n",
      "    [Trial 26 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 26 - Fold 4] Splitting features and target...\n",
      "    [Trial 26 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 26 - Fold 4] Training SVM model...\n",
      "    [Trial 26 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 26 - Fold 4] F1-Score: 0.3041\n",
      "    [Trial 26 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.26      0.36      0.30      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.61      0.65      0.63     21679\n",
      "weighted avg       0.92      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 26 - Fold 5/5] Preparing data...\n",
      "    [Trial 26 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 26 - Fold 5] Splitting features and target...\n",
      "    [Trial 26 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 26 - Fold 5] Training SVM model...\n",
      "    [Trial 24 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 24 - Fold 3] F1-Score: 0.2609\n",
      "    [Trial 24 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.93     20478\n",
      "         1.0       0.20      0.38      0.26      1201\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.58      0.65      0.60     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 24 - Fold 4/5] Preparing data...\n",
      "    [Trial 24 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 24 - Fold 4] Splitting features and target...\n",
      "    [Trial 24 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 24 - Fold 4] Training SVM model...\n",
      "    [Trial 26 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:47:15,900] Trial 26 finished with value: 0.29202137094071934 and parameters: {'kernel': 'rbf', 'C': 0.9821490938959996, 'gamma': 0.045402215561020455, 'class_weight': None, 'shrinking': False, 'tol': 0.000452478953784901}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 26 - Fold 5] F1-Score: 0.2903\n",
      "    [Trial 26 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.35      0.29      1200\n",
      "\n",
      "    accuracy                           0.91     21678\n",
      "   macro avg       0.60      0.64      0.62     21678\n",
      "weighted avg       0.92      0.91      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 26] Mean F1-Score across all folds: 0.2920\n",
      "\n",
      "[Trial 27] Starting with parameters: kernel=rbf, C=0.1032, gamma=0.1159, tol=0.003555, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 27 - Fold 1/5] Preparing data...\n",
      "    [Trial 27 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 27 - Fold 1] Splitting features and target...\n",
      "    [Trial 27 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 27 - Fold 1] Training SVM model...\n",
      "    [Trial 27 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:48:02,941] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 27 - Fold 1] F1-Score: 0.2005\n",
      "    [Trial 27 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     20479\n",
      "         1.0       0.22      0.18      0.20      1200\n",
      "\n",
      "    accuracy                           0.92     21679\n",
      "   macro avg       0.59      0.57      0.58     21679\n",
      "weighted avg       0.91      0.92      0.92     21679\n",
      "\n",
      "    [Trial 27] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 28] Starting with parameters: kernel=rbf, C=1.1365, gamma=0.0328, tol=0.004925, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 28 - Fold 1/5] Preparing data...\n",
      "    [Trial 28 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 28 - Fold 1] Splitting features and target...\n",
      "    [Trial 28 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 28 - Fold 1] Training SVM model...\n",
      "    [Trial 22 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:48:07,318] Trial 22 finished with value: 0.27184254481732334 and parameters: {'kernel': 'poly', 'C': 0.7625598411253082, 'gamma': 0.04589273169931054, 'class_weight': None, 'shrinking': False, 'tol': 0.0004163188142217492, 'coef0': 4.0137033661156485, 'degree': 4}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 22 - Fold 5] F1-Score: 0.2671\n",
      "    [Trial 22 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20478\n",
      "         1.0       0.20      0.41      0.27      1200\n",
      "\n",
      "    accuracy                           0.87     21678\n",
      "   macro avg       0.58      0.66      0.60     21678\n",
      "weighted avg       0.92      0.87      0.89     21678\n",
      "\n",
      "\n",
      "[Trial 22] Mean F1-Score across all folds: 0.2718\n",
      "\n",
      "[Trial 29] Starting with parameters: kernel=rbf, C=7.6344, gamma=0.1261, tol=0.004927, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 29 - Fold 1/5] Preparing data...\n",
      "    [Trial 29 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 29 - Fold 1] Splitting features and target...\n",
      "    [Trial 29 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 29 - Fold 1] Training SVM model...\n",
      "    [Trial 28 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 28 - Fold 1] F1-Score: 0.2717\n",
      "    [Trial 28 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.23      0.32      0.27      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.63      0.61     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 28 - Fold 2/5] Preparing data...\n",
      "    [Trial 28 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 28 - Fold 2] Splitting features and target...\n",
      "    [Trial 28 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 28 - Fold 2] Training SVM model...\n",
      "    [Trial 29 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 28 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 23 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:48:49,863] Trial 23 finished with value: 0.26031044448590573 and parameters: {'kernel': 'poly', 'C': 0.719425947261542, 'gamma': 0.06421896546153119, 'class_weight': None, 'shrinking': False, 'tol': 0.00043900488517356064, 'coef0': 3.94725910516546, 'degree': 4}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 23 - Fold 5] F1-Score: 0.2628\n",
      "    [Trial 23 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20478\n",
      "         1.0       0.19      0.42      0.26      1200\n",
      "\n",
      "    accuracy                           0.87     21678\n",
      "   macro avg       0.58      0.66      0.60     21678\n",
      "weighted avg       0.92      0.87      0.89     21678\n",
      "\n",
      "\n",
      "[Trial 23] Mean F1-Score across all folds: 0.2603\n",
      "\n",
      "[Trial 30] Starting with parameters: kernel=rbf, C=6.1654, gamma=0.1473, tol=0.001289, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 30 - Fold 1/5] Preparing data...\n",
      "    [Trial 30 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 30 - Fold 1] Splitting features and target...\n",
      "    [Trial 30 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 30 - Fold 1] Training SVM model...\n",
      "    [Trial 28 - Fold 2] F1-Score: 0.3203\n",
      "    [Trial 28 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.27      0.39      0.32      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.62      0.66      0.64     21679\n",
      "weighted avg       0.92      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 28 - Fold 3/5] Preparing data...\n",
      "    [Trial 28 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 28 - Fold 3] Splitting features and target...\n",
      "    [Trial 28 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 28 - Fold 3] Training SVM model...\n",
      "    [Trial 29 - Fold 1] F1-Score: 0.2364\n",
      "    [Trial 29 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.20      0.28      0.24      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.59     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 29 - Fold 2/5] Preparing data...\n",
      "    [Trial 29 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 29 - Fold 2] Splitting features and target...\n",
      "    [Trial 29 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 29 - Fold 2] Training SVM model...\n",
      "    [Trial 28 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 24 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 24 - Fold 4] F1-Score: 0.2696\n",
      "    [Trial 24 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20478\n",
      "         1.0       0.20      0.41      0.27      1201\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.58      0.66      0.60     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 24 - Fold 5/5] Preparing data...\n",
      "    [Trial 24 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 24 - Fold 5] Splitting features and target...\n",
      "    [Trial 24 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 24 - Fold 5] Training SVM model...\n",
      "    [Trial 30 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 28 - Fold 3] F1-Score: 0.2813\n",
      "    [Trial 28 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.33      0.28      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.64      0.62     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 28 - Fold 4/5] Preparing data...\n",
      "    [Trial 28 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 28 - Fold 4] Splitting features and target...\n",
      "    [Trial 28 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 28 - Fold 4] Training SVM model...\n",
      "    [Trial 29 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 28 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 30 - Fold 1] F1-Score: 0.2369\n",
      "    [Trial 30 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.21      0.28      0.24      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.59     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 30 - Fold 2/5] Preparing data...\n",
      "    [Trial 30 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 30 - Fold 2] Splitting features and target...\n",
      "    [Trial 30 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 30 - Fold 2] Training SVM model...\n",
      "    [Trial 28 - Fold 4] F1-Score: 0.3073\n",
      "    [Trial 28 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.26      0.38      0.31      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.61      0.66      0.63     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 28 - Fold 5/5] Preparing data...\n",
      "    [Trial 28 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 28 - Fold 5] Splitting features and target...\n",
      "    [Trial 28 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 28 - Fold 5] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:50:07,117] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 29 - Fold 2] F1-Score: 0.2606\n",
      "    [Trial 29 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.22      0.32      0.26      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.59      0.63      0.60     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 29] Trial pruned after Fold 2\n",
      "\n",
      "[Trial 31] Starting with parameters: kernel=rbf, C=1.1384, gamma=0.0279, tol=0.001385, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 31 - Fold 1/5] Preparing data...\n",
      "    [Trial 31 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 31 - Fold 1] Splitting features and target...\n",
      "    [Trial 31 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 31 - Fold 1] Training SVM model...\n",
      "    [Trial 28 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 31 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:50:33,683] Trial 28 finished with value: 0.2950424476340429 and parameters: {'kernel': 'rbf', 'C': 1.136535309254098, 'gamma': 0.03280181974335309, 'class_weight': None, 'shrinking': False, 'tol': 0.004924837246408743}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 28 - Fold 5] F1-Score: 0.2946\n",
      "    [Trial 28 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.36      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.65      0.62     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 28] Mean F1-Score across all folds: 0.2950\n",
      "\n",
      "[Trial 32] Starting with parameters: kernel=rbf, C=1.3184, gamma=0.0259, tol=0.001661, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 32 - Fold 1/5] Preparing data...\n",
      "    [Trial 32 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 32 - Fold 1] Splitting features and target...\n",
      "    [Trial 32 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 32 - Fold 1] Training SVM model...\n",
      "    [Trial 31 - Fold 1] F1-Score: 0.2755\n",
      "    [Trial 31 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.24      0.33      0.28      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.63      0.61     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 31 - Fold 2/5] Preparing data...\n",
      "    [Trial 31 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 31 - Fold 2] Splitting features and target...\n",
      "    [Trial 31 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 31 - Fold 2] Training SVM model...\n",
      "    [Trial 30 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 32 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 31 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 32 - Fold 1] F1-Score: 0.2775\n",
      "    [Trial 32 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.24      0.34      0.28      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.64      0.61     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 32 - Fold 2/5] Preparing data...\n",
      "    [Trial 32 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 32 - Fold 2] Splitting features and target...\n",
      "    [Trial 32 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 32 - Fold 2] Training SVM model...\n",
      "    [Trial 31 - Fold 2] F1-Score: 0.3168\n",
      "    [Trial 31 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.27      0.39      0.32      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.62      0.66      0.63     21679\n",
      "weighted avg       0.92      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 31 - Fold 3/5] Preparing data...\n",
      "    [Trial 31 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 31 - Fold 3] Splitting features and target...\n",
      "    [Trial 31 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 31 - Fold 3] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:51:08,946] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 30 - Fold 2] F1-Score: 0.2600\n",
      "    [Trial 30 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.23      0.31      0.26      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.59      0.62      0.60     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 30] Trial pruned after Fold 2\n",
      "\n",
      "[Trial 33] Starting with parameters: kernel=poly, C=1.1712, gamma=0.0250, tol=0.005816, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 33 - Fold 1/5] Preparing data...\n",
      "    [Trial 33 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 33 - Fold 1] Splitting features and target...\n",
      "    [Trial 33 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 33 - Fold 1] Training SVM model...\n",
      "    [Trial 32 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 31 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 33 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 33 - Fold 1] F1-Score: 0.2880\n",
      "    [Trial 33 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 33 - Fold 2/5] Preparing data...\n",
      "    [Trial 33 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 33 - Fold 2] Splitting features and target...\n",
      "    [Trial 33 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 33 - Fold 2] Training SVM model...\n",
      "    [Trial 32 - Fold 2] F1-Score: 0.3176\n",
      "    [Trial 32 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.27      0.39      0.32      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.62      0.66      0.63     21679\n",
      "weighted avg       0.92      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 32 - Fold 3/5] Preparing data...\n",
      "    [Trial 32 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 32 - Fold 3] Splitting features and target...\n",
      "    [Trial 32 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 32 - Fold 3] Training SVM model...\n",
      "    [Trial 33 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 31 - Fold 3] F1-Score: 0.2825\n",
      "    [Trial 31 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.24      0.33      0.28      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.64      0.62     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 31 - Fold 4/5] Preparing data...\n",
      "    [Trial 31 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 31 - Fold 4] Splitting features and target...\n",
      "    [Trial 31 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 31 - Fold 4] Training SVM model...\n",
      "    [Trial 33 - Fold 2] F1-Score: 0.3204\n",
      "    [Trial 33 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.41      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 33 - Fold 3/5] Preparing data...\n",
      "    [Trial 33 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 33 - Fold 3] Splitting features and target...\n",
      "    [Trial 33 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 33 - Fold 3] Training SVM model...\n",
      "    [Trial 32 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 31 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 33 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 33 - Fold 3] F1-Score: 0.2966\n",
      "    [Trial 33 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.24      0.38      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 33 - Fold 4/5] Preparing data...\n",
      "    [Trial 33 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 33 - Fold 4] Splitting features and target...\n",
      "    [Trial 33 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 33 - Fold 4] Training SVM model...\n",
      "    [Trial 24 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 33 - Fold 4] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:52:00,202] Trial 24 finished with value: 0.26097681807768136 and parameters: {'kernel': 'poly', 'C': 1.0679846342438042, 'gamma': 0.05766429433558389, 'class_weight': None, 'shrinking': False, 'tol': 0.0005206134897845126, 'coef0': 3.5778442452843553, 'degree': 4}. Best is trial 11 with value: 0.29695729680672045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 24 - Fold 5] F1-Score: 0.2629\n",
      "    [Trial 24 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20478\n",
      "         1.0       0.19      0.42      0.26      1200\n",
      "\n",
      "    accuracy                           0.87     21678\n",
      "   macro avg       0.58      0.66      0.60     21678\n",
      "weighted avg       0.92      0.87      0.89     21678\n",
      "\n",
      "\n",
      "[Trial 24] Mean F1-Score across all folds: 0.2610\n",
      "\n",
      "[Trial 34] Starting with parameters: kernel=sigmoid, C=1.4113, gamma=0.0242, tol=0.001958, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 34 - Fold 1/5] Preparing data...\n",
      "    [Trial 32 - Fold 3] F1-Score: 0.2822\n",
      "    [Trial 32 - Fold 3] Classification Report:\n",
      "    [Trial 34 - Fold 1] Sampling 10% of training data...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.24      0.33      0.28      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.64      0.62     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 32 - Fold 4/5] Preparing data...\n",
      "    [Trial 32 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 34 - Fold 1] Splitting features and target...\n",
      "    [Trial 34 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 34 - Fold 1] Training SVM model...\n",
      "    [Trial 32 - Fold 4] Splitting features and target...\n",
      "    [Trial 32 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 32 - Fold 4] Training SVM model...\n",
      "    [Trial 31 - Fold 4] F1-Score: 0.3109\n",
      "    [Trial 31 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.26      0.38      0.31      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.61      0.66      0.63     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 31 - Fold 5/5] Preparing data...\n",
      "    [Trial 31 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 31 - Fold 5] Splitting features and target...\n",
      "    [Trial 31 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 31 - Fold 5] Training SVM model...\n",
      "    [Trial 33 - Fold 4] F1-Score: 0.3160\n",
      "    [Trial 33 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.42      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 33 - Fold 5/5] Preparing data...\n",
      "    [Trial 33 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 33 - Fold 5] Splitting features and target...\n",
      "    [Trial 33 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 33 - Fold 5] Training SVM model...\n",
      "    [Trial 34 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 32 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 31 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 33 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:52:17,749] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 34 - Fold 1] F1-Score: 0.1601\n",
      "    [Trial 34 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.77      0.86     20479\n",
      "         1.0       0.10      0.42      0.16      1200\n",
      "\n",
      "    accuracy                           0.75     21679\n",
      "   macro avg       0.53      0.60      0.51     21679\n",
      "weighted avg       0.91      0.75      0.82     21679\n",
      "\n",
      "    [Trial 34] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 35] Starting with parameters: kernel=rbf, C=1.2090, gamma=0.0278, tol=0.005197, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 35 - Fold 1/5] Preparing data...\n",
      "    [Trial 35 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 35 - Fold 1] Splitting features and target...\n",
      "    [Trial 35 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 35 - Fold 1] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:52:21,352] Trial 33 finished with value: 0.30450330669016157 and parameters: {'kernel': 'poly', 'C': 1.1712199390161988, 'gamma': 0.02495730184269811, 'class_weight': None, 'shrinking': False, 'tol': 0.005816475420399203, 'coef0': 0.2869375069368356, 'degree': 2}. Best is trial 33 with value: 0.30450330669016157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 33 - Fold 5] F1-Score: 0.3016\n",
      "    [Trial 33 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.40      0.30      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.60      0.66      0.62     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 33] Mean F1-Score across all folds: 0.3045\n",
      "\n",
      "[Trial 36] Starting with parameters: kernel=poly, C=4.1539, gamma=0.0257, tol=0.005239, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 36 - Fold 1/5] Preparing data...\n",
      "    [Trial 36 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 36 - Fold 1] Splitting features and target...\n",
      "    [Trial 36 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 36 - Fold 1] Training SVM model...\n",
      "    [Trial 35 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 32 - Fold 4] F1-Score: 0.3133\n",
      "    [Trial 32 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.26      0.39      0.31      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.61      0.66      0.63     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 32 - Fold 5/5] Preparing data...\n",
      "    [Trial 32 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 32 - Fold 5] Splitting features and target...\n",
      "    [Trial 32 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 32 - Fold 5] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:52:33,998] Trial 31 finished with value: 0.2960027340945468 and parameters: {'kernel': 'rbf', 'C': 1.138409469741744, 'gamma': 0.027861760307559026, 'class_weight': None, 'shrinking': False, 'tol': 0.0013853148150481153}. Best is trial 33 with value: 0.30450330669016157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 31 - Fold 5] F1-Score: 0.2943\n",
      "    [Trial 31 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.36      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.60      0.65      0.62     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 31] Mean F1-Score across all folds: 0.2960\n",
      "\n",
      "[Trial 37] Starting with parameters: kernel=poly, C=3.2279, gamma=0.0232, tol=0.001354, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 37 - Fold 1/5] Preparing data...\n",
      "    [Trial 37 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 37 - Fold 1] Splitting features and target...\n",
      "    [Trial 37 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 37 - Fold 1] Training SVM model...\n",
      "    [Trial 32 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 36 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 35 - Fold 1] F1-Score: 0.2777\n",
      "    [Trial 35 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.24      0.33      0.28      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.64      0.61     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 35 - Fold 2/5] Preparing data...\n",
      "    [Trial 35 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 36 - Fold 1] F1-Score: 0.2881\n",
      "    [Trial 36 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 36 - Fold 2/5] Preparing data...\n",
      "    [Trial 36 - Fold 2] Sampling 10% of training data...    [Trial 35 - Fold 2] Splitting features and target...\n",
      "\n",
      "    [Trial 35 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 35 - Fold 2] Training SVM model...\n",
      "    [Trial 36 - Fold 2] Splitting features and target...\n",
      "    [Trial 36 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 36 - Fold 2] Training SVM model...\n",
      "    [Trial 35 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 37 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:52:58,380] Trial 32 finished with value: 0.2970371625075962 and parameters: {'kernel': 'rbf', 'C': 1.3184311605359005, 'gamma': 0.025868405202672518, 'class_weight': None, 'shrinking': False, 'tol': 0.0016607948426363543}. Best is trial 33 with value: 0.30450330669016157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 32 - Fold 5] F1-Score: 0.2946\n",
      "    [Trial 32 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.36      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.60      0.65      0.62     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 32] Mean F1-Score across all folds: 0.2970\n",
      "\n",
      "[Trial 38] Starting with parameters: kernel=poly, C=4.1406, gamma=0.0255, tol=0.000789, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 38 - Fold 1/5] Preparing data...\n",
      "    [Trial 38 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 38 - Fold 1] Splitting features and target...\n",
      "    [Trial 38 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 38 - Fold 1] Training SVM model...\n",
      "    [Trial 37 - Fold 1] F1-Score: 0.2900\n",
      "    [Trial 37 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 37 - Fold 2/5] Preparing data...\n",
      "    [Trial 37 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 37 - Fold 2] Splitting features and target...\n",
      "    [Trial 37 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 37 - Fold 2] Training SVM model...\n",
      "    [Trial 36 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 36 - Fold 2] F1-Score: 0.3135\n",
      "    [Trial 36 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 36 - Fold 3/5] Preparing data...\n",
      "    [Trial 36 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 36 - Fold 3] Splitting features and target...\n",
      "    [Trial 36 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 36 - Fold 3] Training SVM model...\n",
      "    [Trial 35 - Fold 2] F1-Score: 0.3176\n",
      "    [Trial 35 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20479\n",
      "         1.0       0.27      0.39      0.32      1200\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.62      0.66      0.63     21679\n",
      "weighted avg       0.92      0.91      0.92     21679\n",
      "\n",
      "\n",
      "  [Trial 35 - Fold 3/5] Preparing data...\n",
      "    [Trial 35 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 35 - Fold 3] Splitting features and target...\n",
      "    [Trial 35 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 35 - Fold 3] Training SVM model...\n",
      "    [Trial 4 - Fold 3] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:53:23,758] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 4 - Fold 3] F1-Score: 0.2328\n",
      "    [Trial 4 - Fold 3] Classification Report:\n",
      "    [Trial 35 - Fold 3] Evaluating on validation data...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.20      0.28      0.23      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.58      0.61      0.59     21679\n",
      "weighted avg       0.91      0.90      0.91     21679\n",
      "\n",
      "    [Trial 4] Trial pruned after Fold 3\n",
      "\n",
      "[Trial 39] Starting with parameters: kernel=poly, C=3.9648, gamma=0.0252, tol=0.001307, class_weight=None, shrinking=False\n",
      "\n",
      "  [Trial 39 - Fold 1/5] Preparing data...\n",
      "    [Trial 39 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 39 - Fold 1] Splitting features and target...\n",
      "    [Trial 39 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 39 - Fold 1] Training SVM model...\n",
      "    [Trial 37 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 38 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 37 - Fold 2] F1-Score: 0.3176\n",
      "    [Trial 37 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.42      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 37 - Fold 3/5] Preparing data...\n",
      "    [Trial 37 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 37 - Fold 3] Splitting features and target...\n",
      "    [Trial 37 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 37 - Fold 3] Training SVM model...\n",
      "    [Trial 38 - Fold 1] F1-Score: 0.2864\n",
      "    [Trial 38 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 38 - Fold 2/5] Preparing data...\n",
      "    [Trial 38 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 38 - Fold 2] Splitting features and target...\n",
      "    [Trial 38 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 38 - Fold 2] Training SVM model...\n",
      "    [Trial 36 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 36 - Fold 3] F1-Score: 0.3027\n",
      "    [Trial 36 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 36 - Fold 4/5] Preparing data...\n",
      "    [Trial 36 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 36 - Fold 4] Splitting features and target...\n",
      "    [Trial 36 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 36 - Fold 4] Training SVM model...\n",
      "    [Trial 35 - Fold 3] F1-Score: 0.2814\n",
      "    [Trial 35 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.24      0.33      0.28      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.60      0.64      0.62     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 35 - Fold 4/5] Preparing data...\n",
      "    [Trial 35 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 35 - Fold 4] Splitting features and target...\n",
      "    [Trial 35 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 35 - Fold 4] Training SVM model...\n",
      "    [Trial 39 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 37 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 35 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 39 - Fold 1] F1-Score: 0.2870\n",
      "    [Trial 39 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 39 - Fold 2/5] Preparing data...\n",
      "    [Trial 39 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 39 - Fold 2] Splitting features and target...\n",
      "    [Trial 39 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 39 - Fold 2] Training SVM model...\n",
      "    [Trial 37 - Fold 3] F1-Score: 0.3035\n",
      "    [Trial 37 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 37 - Fold 4/5] Preparing data...\n",
      "    [Trial 37 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 37 - Fold 4] Splitting features and target...\n",
      "    [Trial 37 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 37 - Fold 4] Training SVM model...\n",
      "    [Trial 36 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 38 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 36 - Fold 4] F1-Score: 0.3287\n",
      "    [Trial 36 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 36 - Fold 5/5] Preparing data...\n",
      "    [Trial 36 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 36 - Fold 5] Splitting features and target...\n",
      "    [Trial 36 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 36 - Fold 5] Training SVM model...\n",
      "    [Trial 38 - Fold 2] F1-Score: 0.3121\n",
      "    [Trial 38 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 38 - Fold 3/5] Preparing data...\n",
      "    [Trial 38 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 38 - Fold 3] Splitting features and target...\n",
      "    [Trial 38 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 38 - Fold 3] Training SVM model...\n",
      "    [Trial 35 - Fold 4] F1-Score: 0.3102\n",
      "    [Trial 35 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.26      0.38      0.31      1201\n",
      "\n",
      "    accuracy                           0.91     21679\n",
      "   macro avg       0.61      0.66      0.63     21679\n",
      "weighted avg       0.92      0.91      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 35 - Fold 5/5] Preparing data...\n",
      "    [Trial 35 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 35 - Fold 5] Splitting features and target...\n",
      "    [Trial 35 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 35 - Fold 5] Training SVM model...\n",
      "    [Trial 37 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 39 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 35 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 37 - Fold 4] F1-Score: 0.3214\n",
      "    [Trial 37 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 37 - Fold 5/5] Preparing data...\n",
      "    [Trial 37 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 37 - Fold 5] Splitting features and target...\n",
      "    [Trial 37 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 37 - Fold 5] Training SVM model...\n",
      "    [Trial 39 - Fold 2] F1-Score: 0.3151\n",
      "    [Trial 39 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 39 - Fold 3/5] Preparing data...\n",
      "    [Trial 39 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 39 - Fold 3] Splitting features and target...\n",
      "    [Trial 39 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 39 - Fold 3] Training SVM model...\n",
      "    [Trial 36 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:54:34,990] Trial 36 finished with value: 0.30996108825141405 and parameters: {'kernel': 'poly', 'C': 4.153868013257493, 'gamma': 0.025748992776436982, 'class_weight': None, 'shrinking': False, 'tol': 0.005238555936576485, 'coef0': 1.8520088104380528, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 36 - Fold 5] F1-Score: 0.3169\n",
      "    [Trial 36 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 36] Mean F1-Score across all folds: 0.3100\n",
      "\n",
      "[Trial 40] Starting with parameters: kernel=poly, C=4.1579, gamma=0.0219, tol=0.000828, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 40 - Fold 1/5] Preparing data...\n",
      "    [Trial 40 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 40 - Fold 1] Splitting features and target...\n",
      "    [Trial 40 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 40 - Fold 1] Training SVM model...\n",
      "    [Trial 38 - Fold 3] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:54:41,099] Trial 35 finished with value: 0.2960429691644973 and parameters: {'kernel': 'rbf', 'C': 1.2089714620630903, 'gamma': 0.027846237757106176, 'class_weight': None, 'shrinking': False, 'tol': 0.005197056451993528}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 35 - Fold 5] F1-Score: 0.2933\n",
      "    [Trial 35 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     20478\n",
      "         1.0       0.25      0.36      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.60      0.65      0.62     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 35] Mean F1-Score across all folds: 0.2960\n",
      "\n",
      "[Trial 41] Starting with parameters: kernel=poly, C=4.3915, gamma=0.0215, tol=0.002848, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 41 - Fold 1/5] Preparing data...\n",
      "    [Trial 41 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 41 - Fold 1] Splitting features and target...\n",
      "    [Trial 41 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 41 - Fold 1] Training SVM model...\n",
      "    [Trial 37 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 38 - Fold 3] F1-Score: 0.3025\n",
      "    [Trial 38 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 38 - Fold 4/5] Preparing data...\n",
      "    [Trial 38 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 38 - Fold 4] Splitting features and target...\n",
      "    [Trial 38 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 38 - Fold 4] Training SVM model...\n",
      "    [Trial 40 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:54:47,333] Trial 37 finished with value: 0.309247486953991 and parameters: {'kernel': 'poly', 'C': 3.2278896483168524, 'gamma': 0.0232218770629915, 'class_weight': None, 'shrinking': False, 'tol': 0.0013541673122315712, 'coef0': 1.7517672295060893, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 37 - Fold 5] F1-Score: 0.3138\n",
      "    [Trial 37 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 37] Mean F1-Score across all folds: 0.3092\n",
      "\n",
      "[Trial 42] Starting with parameters: kernel=poly, C=4.3752, gamma=0.0214, tol=0.000171, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 42 - Fold 1/5] Preparing data...\n",
      "    [Trial 42 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 42 - Fold 1] Splitting features and target...\n",
      "    [Trial 42 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 42 - Fold 1] Training SVM model...\n",
      "    [Trial 40 - Fold 1] F1-Score: 0.2887\n",
      "    [Trial 40 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 40 - Fold 2/5] Preparing data...\n",
      "    [Trial 40 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 40 - Fold 2] Splitting features and target...\n",
      "    [Trial 40 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 40 - Fold 2] Training SVM model...\n",
      "    [Trial 39 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 41 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 39 - Fold 3] F1-Score: 0.3032\n",
      "    [Trial 39 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 39 - Fold 4/5] Preparing data...\n",
      "    [Trial 39 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 39 - Fold 4] Splitting features and target...\n",
      "    [Trial 39 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 39 - Fold 4] Training SVM model...\n",
      "    [Trial 41 - Fold 1] F1-Score: 0.2899\n",
      "    [Trial 41 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 41 - Fold 2/5] Preparing data...\n",
      "    [Trial 41 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 41 - Fold 2] Splitting features and target...\n",
      "    [Trial 41 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 41 - Fold 2] Training SVM model...\n",
      "    [Trial 42 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 40 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 42 - Fold 1] F1-Score: 0.2889\n",
      "    [Trial 42 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 42 - Fold 2/5] Preparing data...\n",
      "    [Trial 42 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 42 - Fold 2] Splitting features and target...\n",
      "    [Trial 42 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 42 - Fold 2] Training SVM model...\n",
      "    [Trial 40 - Fold 2] F1-Score: 0.3149\n",
      "    [Trial 40 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 40 - Fold 3/5] Preparing data...\n",
      "    [Trial 40 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 40 - Fold 3] Splitting features and target...\n",
      "    [Trial 40 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 40 - Fold 3] Training SVM model...\n",
      "    [Trial 41 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 38 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 41 - Fold 2] F1-Score: 0.3142\n",
      "    [Trial 41 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 41 - Fold 3/5] Preparing data...\n",
      "    [Trial 41 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 41 - Fold 3] Splitting features and target...\n",
      "    [Trial 41 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 41 - Fold 3] Training SVM model...\n",
      "    [Trial 42 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 40 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 38 - Fold 4] F1-Score: 0.3297\n",
      "    [Trial 38 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 38 - Fold 5/5] Preparing data...\n",
      "    [Trial 38 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 39 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 38 - Fold 5] Splitting features and target...\n",
      "    [Trial 38 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 38 - Fold 5] Training SVM model...\n",
      "    [Trial 40 - Fold 3] F1-Score: 0.3054\n",
      "    [Trial 40 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.40      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 40 - Fold 4/5] Preparing data...\n",
      "    [Trial 40 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 40 - Fold 4] Splitting features and target...\n",
      "    [Trial 40 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 40 - Fold 4] Training SVM model...\n",
      "    [Trial 42 - Fold 2] F1-Score: 0.3144\n",
      "    [Trial 42 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 42 - Fold 3/5] Preparing data...\n",
      "    [Trial 42 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 42 - Fold 3] Splitting features and target...\n",
      "    [Trial 42 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 42 - Fold 3] Training SVM model...\n",
      "    [Trial 39 - Fold 4] F1-Score: 0.3268\n",
      "    [Trial 39 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 39 - Fold 5/5] Preparing data...\n",
      "    [Trial 39 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 39 - Fold 5] Splitting features and target...\n",
      "    [Trial 39 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 39 - Fold 5] Training SVM model...\n",
      "    [Trial 41 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 41 - Fold 3] F1-Score: 0.3060\n",
      "    [Trial 41 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 41 - Fold 4/5] Preparing data...\n",
      "    [Trial 41 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 41 - Fold 4] Splitting features and target...\n",
      "    [Trial 41 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 41 - Fold 4] Training SVM model...\n",
      "    [Trial 40 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 42 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 40 - Fold 4] F1-Score: 0.3240\n",
      "    [Trial 40 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 40 - Fold 5/5] Preparing data...\n",
      "    [Trial 40 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 40 - Fold 5] Splitting features and target...\n",
      "    [Trial 40 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 40 - Fold 5] Training SVM model...\n",
      "    [Trial 42 - Fold 3] F1-Score: 0.3063\n",
      "    [Trial 42 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 42 - Fold 4/5] Preparing data...\n",
      "    [Trial 42 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 42 - Fold 4] Splitting features and target...\n",
      "    [Trial 42 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 42 - Fold 4] Training SVM model...\n",
      "    [Trial 41 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 40 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 41 - Fold 4] F1-Score: 0.3243\n",
      "    [Trial 41 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 41 - Fold 5/5] Preparing data...\n",
      "    [Trial 41 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 41 - Fold 5] Splitting features and target...\n",
      "    [Trial 41 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 41 - Fold 5] Training SVM model...\n",
      "    [Trial 38 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 42 - Fold 4] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:55:59,748] Trial 40 finished with value: 0.3095506845277646 and parameters: {'kernel': 'poly', 'C': 4.157885061134158, 'gamma': 0.021856837012978, 'class_weight': None, 'shrinking': True, 'tol': 0.0008284764530773931, 'coef0': 1.6128909076739104, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 40 - Fold 5] F1-Score: 0.3147\n",
      "    [Trial 40 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 40] Mean F1-Score across all folds: 0.3096\n",
      "\n",
      "[Trial 43] Starting with parameters: kernel=poly, C=4.0245, gamma=0.0199, tol=0.000707, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 43 - Fold 1/5] Preparing data...\n",
      "    [Trial 43 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 43 - Fold 1] Splitting features and target...\n",
      "    [Trial 43 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 43 - Fold 1] Training SVM model...\n",
      "    [Trial 39 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 38 - Fold 5] F1-Score: 0.3167\n",
      "    [Trial 38 - Fold 5] Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:56:00,716] Trial 38 finished with value: 0.30948595042357024 and parameters: {'kernel': 'poly', 'C': 4.140597533710621, 'gamma': 0.025465583505749113, 'class_weight': None, 'shrinking': False, 'tol': 0.0007891738844586739, 'coef0': 1.7347634015557176, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 38] Mean F1-Score across all folds: 0.3095\n",
      "\n",
      "[Trial 44] Starting with parameters: kernel=poly, C=4.1905, gamma=0.1738, tol=0.000198, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 44 - Fold 1/5] Preparing data...\n",
      "    [Trial 44 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 44 - Fold 1] Splitting features and target...\n",
      "    [Trial 44 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 44 - Fold 1] Training SVM model...\n",
      "    [Trial 42 - Fold 4] F1-Score: 0.3247\n",
      "    [Trial 42 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 42 - Fold 5/5] Preparing data...\n",
      "    [Trial 42 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 42 - Fold 5] Splitting features and target...\n",
      "    [Trial 42 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 42 - Fold 5] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:56:05,122] Trial 39 finished with value: 0.3096580729052329 and parameters: {'kernel': 'poly', 'C': 3.9648059087249843, 'gamma': 0.025158956475732283, 'class_weight': None, 'shrinking': False, 'tol': 0.0013070810790451238, 'coef0': 1.9757687317148598, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 39 - Fold 5] F1-Score: 0.3163\n",
      "    [Trial 39 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 39] Mean F1-Score across all folds: 0.3097\n",
      "\n",
      "[Trial 45] Starting with parameters: kernel=poly, C=3.9638, gamma=0.0176, tol=0.000758, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 45 - Fold 1/5] Preparing data...\n",
      "    [Trial 45 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 45 - Fold 1] Splitting features and target...\n",
      "    [Trial 45 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 45 - Fold 1] Training SVM model...\n",
      "    [Trial 41 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:56:13,447] Trial 41 finished with value: 0.30967177072084645 and parameters: {'kernel': 'poly', 'C': 4.3914956256147475, 'gamma': 0.021487373063676103, 'class_weight': None, 'shrinking': True, 'tol': 0.0028477380306571017, 'coef0': 1.977884947564196, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 41 - Fold 5] F1-Score: 0.3140\n",
      "    [Trial 41 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 41] Mean F1-Score across all folds: 0.3097\n",
      "\n",
      "[Trial 46] Starting with parameters: kernel=poly, C=4.6495, gamma=0.0175, tol=0.000851, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 46 - Fold 1/5] Preparing data...\n",
      "    [Trial 46 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 46 - Fold 1] Splitting features and target...\n",
      "    [Trial 46 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 46 - Fold 1] Training SVM model...\n",
      "    [Trial 43 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 42 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 43 - Fold 1] F1-Score: 0.2911\n",
      "    [Trial 43 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 43 - Fold 2/5] Preparing data...\n",
      "    [Trial 45 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 43 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 43 - Fold 2] Splitting features and target...\n",
      "    [Trial 43 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 43 - Fold 2] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:56:21,983] Trial 42 finished with value: 0.3095337147875672 and parameters: {'kernel': 'poly', 'C': 4.375172926496406, 'gamma': 0.021363660076415898, 'class_weight': None, 'shrinking': True, 'tol': 0.00017053179569399387, 'coef0': 2.020719337055441, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 42 - Fold 5] F1-Score: 0.3135\n",
      "    [Trial 42 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 42] Mean F1-Score across all folds: 0.3095\n",
      "\n",
      "[Trial 47] Starting with parameters: kernel=poly, C=13.9901, gamma=0.0190, tol=0.000156, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 47 - Fold 1/5] Preparing data...\n",
      "    [Trial 47 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 47 - Fold 1] Splitting features and target...\n",
      "    [Trial 47 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 47 - Fold 1] Training SVM model...\n",
      "    [Trial 45 - Fold 1] F1-Score: 0.2895\n",
      "    [Trial 45 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 45 - Fold 2/5] Preparing data...\n",
      "    [Trial 45 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 45 - Fold 2] Splitting features and target...\n",
      "    [Trial 45 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 45 - Fold 2] Training SVM model...\n",
      "    [Trial 46 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 43 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 46 - Fold 1] F1-Score: 0.2918\n",
      "    [Trial 46 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 46 - Fold 2/5] Preparing data...\n",
      "    [Trial 46 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 46 - Fold 2] Splitting features and target...\n",
      "    [Trial 46 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 46 - Fold 2] Training SVM model...\n",
      "    [Trial 43 - Fold 2] F1-Score: 0.3193\n",
      "    [Trial 43 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.42      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 43 - Fold 3/5] Preparing data...\n",
      "    [Trial 43 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 43 - Fold 3] Splitting features and target...\n",
      "    [Trial 43 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 43 - Fold 3] Training SVM model...\n",
      "    [Trial 45 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 45 - Fold 2] F1-Score: 0.3191\n",
      "    [Trial 45 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.42      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 45 - Fold 3/5] Preparing data...\n",
      "    [Trial 45 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 45 - Fold 3] Splitting features and target...\n",
      "    [Trial 45 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 45 - Fold 3] Training SVM model...\n",
      "    [Trial 46 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 47 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 43 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 46 - Fold 2] F1-Score: 0.3171\n",
      "    [Trial 46 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.42      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 46 - Fold 3/5] Preparing data...\n",
      "    [Trial 46 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 46 - Fold 3] Splitting features and target...\n",
      "    [Trial 46 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 46 - Fold 3] Training SVM model...\n",
      "    [Trial 47 - Fold 1] F1-Score: 0.2854\n",
      "    [Trial 47 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.61     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 47 - Fold 2/5] Preparing data...\n",
      "    [Trial 47 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 47 - Fold 2] Splitting features and target...\n",
      "    [Trial 47 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 47 - Fold 2] Training SVM model...\n",
      "    [Trial 45 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 43 - Fold 3] F1-Score: 0.3014\n",
      "    [Trial 43 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 43 - Fold 4/5] Preparing data...\n",
      "    [Trial 43 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 43 - Fold 4] Splitting features and target...\n",
      "    [Trial 43 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 43 - Fold 4] Training SVM model...\n",
      "    [Trial 45 - Fold 3] F1-Score: 0.3002\n",
      "    [Trial 45 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.24      0.39      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 45 - Fold 4/5] Preparing data...\n",
      "    [Trial 45 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 45 - Fold 4] Splitting features and target...\n",
      "    [Trial 45 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 45 - Fold 4] Training SVM model...\n",
      "    [Trial 46 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 43 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 46 - Fold 3] F1-Score: 0.3021\n",
      "    [Trial 46 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 46 - Fold 4/5] Preparing data...\n",
      "    [Trial 46 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 46 - Fold 4] Splitting features and target...\n",
      "    [Trial 46 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 46 - Fold 4] Training SVM model...\n",
      "    [Trial 45 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 43 - Fold 4] F1-Score: 0.3233\n",
      "    [Trial 43 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 43 - Fold 5/5] Preparing data...\n",
      "    [Trial 43 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 43 - Fold 5] Splitting features and target...\n",
      "    [Trial 43 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 43 - Fold 5] Training SVM model...\n",
      "    [Trial 45 - Fold 4] F1-Score: 0.3228\n",
      "    [Trial 45 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 45 - Fold 5/5] Preparing data...\n",
      "    [Trial 45 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 45 - Fold 5] Splitting features and target...\n",
      "    [Trial 45 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 45 - Fold 5] Training SVM model...\n",
      "    [Trial 47 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 47 - Fold 2] F1-Score: 0.3097\n",
      "    [Trial 47 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.40      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 47 - Fold 3/5] Preparing data...\n",
      "    [Trial 47 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 47 - Fold 3] Splitting features and target...\n",
      "    [Trial 47 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 47 - Fold 3] Training SVM model...\n",
      "    [Trial 46 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 43 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 46 - Fold 4] F1-Score: 0.3244\n",
      "    [Trial 46 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 46 - Fold 5/5] Preparing data...\n",
      "    [Trial 46 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 46 - Fold 5] Splitting features and target...\n",
      "    [Trial 46 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 46 - Fold 5] Training SVM model...\n",
      "    [Trial 45 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:57:33,731] Trial 43 finished with value: 0.3092783534999243 and parameters: {'kernel': 'poly', 'C': 4.024456354234034, 'gamma': 0.01992527846560379, 'class_weight': None, 'shrinking': True, 'tol': 0.0007074202014490777, 'coef0': 2.0517081023646146, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 43 - Fold 5] F1-Score: 0.3113\n",
      "    [Trial 43 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 43] Mean F1-Score across all folds: 0.3093\n",
      "\n",
      "[Trial 48] Starting with parameters: kernel=poly, C=16.3094, gamma=0.0109, tol=0.000183, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 48 - Fold 1/5] Preparing data...\n",
      "    [Trial 45 - Fold 5] F1-Score: 0.3132\n",
      "    [Trial 45 - Fold 5] Classification Report:\n",
      "    [Trial 48 - Fold 1] Sampling 10% of training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:57:33,957] Trial 45 finished with value: 0.30895305661244044 and parameters: {'kernel': 'poly', 'C': 3.9637828194663847, 'gamma': 0.017645724066359593, 'class_weight': None, 'shrinking': True, 'tol': 0.0007576479806088027, 'coef0': 1.9904008503913415, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 45] Mean F1-Score across all folds: 0.3090\n",
      "\n",
      "[Trial 49] Starting with parameters: kernel=poly, C=13.9393, gamma=0.0110, tol=0.000214, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 49 - Fold 1/5] Preparing data...\n",
      "    [Trial 49 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 48 - Fold 1] Splitting features and target...\n",
      "    [Trial 48 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 48 - Fold 1] Training SVM model...\n",
      "    [Trial 49 - Fold 1] Splitting features and target...\n",
      "    [Trial 49 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 49 - Fold 1] Training SVM model...\n",
      "    [Trial 46 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 47 - Fold 3] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:57:47,117] Trial 46 finished with value: 0.30958517032999067 and parameters: {'kernel': 'poly', 'C': 4.649543986133771, 'gamma': 0.017471637947647962, 'class_weight': None, 'shrinking': True, 'tol': 0.0008507463415706488, 'coef0': 2.5288272480387546, 'degree': 2}. Best is trial 36 with value: 0.30996108825141405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 46 - Fold 5] F1-Score: 0.3125\n",
      "    [Trial 46 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 46] Mean F1-Score across all folds: 0.3096\n",
      "\n",
      "[Trial 50] Starting with parameters: kernel=poly, C=12.5494, gamma=0.0100, tol=0.001091, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 50 - Fold 1/5] Preparing data...\n",
      "    [Trial 50 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 50 - Fold 1] Splitting features and target...\n",
      "    [Trial 50 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 50 - Fold 1] Training SVM model...\n",
      "    [Trial 47 - Fold 3] F1-Score: 0.3059\n",
      "    [Trial 47 - Fold 3] Classification Report:\n",
      "    [Trial 49 - Fold 1] Evaluating on validation data...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 47 - Fold 4/5] Preparing data...\n",
      "    [Trial 47 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 47 - Fold 4] Splitting features and target...\n",
      "    [Trial 47 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 47 - Fold 4] Training SVM model...\n",
      "    [Trial 48 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 49 - Fold 1] F1-Score: 0.2897\n",
      "    [Trial 49 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 49 - Fold 2/5] Preparing data...\n",
      "    [Trial 49 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 49 - Fold 2] Splitting features and target...\n",
      "    [Trial 49 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 49 - Fold 2] Training SVM model...\n",
      "    [Trial 48 - Fold 1] F1-Score: 0.2873\n",
      "    [Trial 48 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 48 - Fold 2/5] Preparing data...\n",
      "    [Trial 48 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 48 - Fold 2] Splitting features and target...\n",
      "    [Trial 48 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 48 - Fold 2] Training SVM model...\n",
      "    [Trial 50 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 50 - Fold 1] F1-Score: 0.2960\n",
      "    [Trial 50 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.24      0.39      0.30      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 50 - Fold 2/5] Preparing data...\n",
      "    [Trial 50 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 50 - Fold 2] Splitting features and target...\n",
      "    [Trial 50 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 50 - Fold 2] Training SVM model...\n",
      "    [Trial 44 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 49 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 48 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 44 - Fold 1] F1-Score: 0.2742\n",
      "    [Trial 44 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.27      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 44 - Fold 2/5] Preparing data...\n",
      "    [Trial 44 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 44 - Fold 2] Splitting features and target...\n",
      "    [Trial 44 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 44 - Fold 2] Training SVM model...\n",
      "    [Trial 49 - Fold 2] F1-Score: 0.3157\n",
      "    [Trial 49 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.42      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 49 - Fold 3/5] Preparing data...\n",
      "    [Trial 49 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 47 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 49 - Fold 3] Splitting features and target...\n",
      "    [Trial 49 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 49 - Fold 3] Training SVM model...\n",
      "    [Trial 48 - Fold 2] F1-Score: 0.3147\n",
      "    [Trial 48 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 48 - Fold 3/5] Preparing data...\n",
      "    [Trial 48 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 48 - Fold 3] Splitting features and target...\n",
      "    [Trial 48 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 48 - Fold 3] Training SVM model...\n",
      "    [Trial 50 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 47 - Fold 4] F1-Score: 0.3308\n",
      "    [Trial 47 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 47 - Fold 5/5] Preparing data...\n",
      "    [Trial 47 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 47 - Fold 5] Splitting features and target...\n",
      "    [Trial 47 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 47 - Fold 5] Training SVM model...\n",
      "    [Trial 50 - Fold 2] F1-Score: 0.3174\n",
      "    [Trial 50 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.42      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 50 - Fold 3/5] Preparing data...\n",
      "    [Trial 50 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 50 - Fold 3] Splitting features and target...\n",
      "    [Trial 50 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 50 - Fold 3] Training SVM model...\n",
      "    [Trial 49 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 48 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 49 - Fold 3] F1-Score: 0.3039\n",
      "    [Trial 49 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 49 - Fold 4/5] Preparing data...\n",
      "    [Trial 49 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 49 - Fold 4] Splitting features and target...\n",
      "    [Trial 49 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 49 - Fold 4] Training SVM model...\n",
      "    [Trial 50 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 47 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 48 - Fold 3] F1-Score: 0.3067\n",
      "    [Trial 48 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 48 - Fold 4/5] Preparing data...\n",
      "    [Trial 48 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 48 - Fold 4] Splitting features and target...\n",
      "    [Trial 48 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 48 - Fold 4] Training SVM model...\n",
      "    [Trial 50 - Fold 3] F1-Score: 0.3005\n",
      "    [Trial 50 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.24      0.39      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 50 - Fold 4/5] Preparing data...\n",
      "    [Trial 50 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 50 - Fold 4] Splitting features and target...\n",
      "    [Trial 50 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 50 - Fold 4] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:58:54,429] Trial 47 finished with value: 0.31046898485006846 and parameters: {'kernel': 'poly', 'C': 13.990069270887533, 'gamma': 0.019015307741611292, 'class_weight': None, 'shrinking': True, 'tol': 0.00015578344223784636, 'coef0': 2.7872991224511, 'degree': 2}. Best is trial 47 with value: 0.31046898485006846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 47 - Fold 5] F1-Score: 0.3205\n",
      "    [Trial 47 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.44      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 47] Mean F1-Score across all folds: 0.3105\n",
      "\n",
      "[Trial 51] Starting with parameters: kernel=poly, C=12.9778, gamma=0.2009, tol=0.000266, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 51 - Fold 1/5] Preparing data...\n",
      "    [Trial 51 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 51 - Fold 1] Splitting features and target...\n",
      "    [Trial 51 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 51 - Fold 1] Training SVM model...\n",
      "    [Trial 49 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 49 - Fold 4] F1-Score: 0.3222\n",
      "    [Trial 49 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 49 - Fold 5/5] Preparing data...\n",
      "    [Trial 49 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 49 - Fold 5] Splitting features and target...    [Trial 48 - Fold 4] Evaluating on validation data...\n",
      "\n",
      "    [Trial 49 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 49 - Fold 5] Training SVM model...\n",
      "    [Trial 50 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 50 - Fold 4] F1-Score: 0.3249\n",
      "    [Trial 50 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 50 - Fold 5/5] Preparing data...\n",
      "    [Trial 50 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 50 - Fold 5] Splitting features and target...\n",
      "    [Trial 50 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 50 - Fold 5] Training SVM model...\n",
      "    [Trial 48 - Fold 4] F1-Score: 0.3241\n",
      "    [Trial 48 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 48 - Fold 5/5] Preparing data...\n",
      "    [Trial 48 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 48 - Fold 5] Splitting features and target...\n",
      "    [Trial 48 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 48 - Fold 5] Training SVM model...\n",
      "    [Trial 49 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 50 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:59:30,999] Trial 49 finished with value: 0.30872805489833366 and parameters: {'kernel': 'poly', 'C': 13.939305617012227, 'gamma': 0.010950465057022223, 'class_weight': None, 'shrinking': True, 'tol': 0.00021387731384290155, 'coef0': 2.9688514423387726, 'degree': 2}. Best is trial 47 with value: 0.31046898485006846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 49 - Fold 5] F1-Score: 0.3122\n",
      "    [Trial 49 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 49] Mean F1-Score across all folds: 0.3087\n",
      "\n",
      "[Trial 52] Starting with parameters: kernel=poly, C=2.0611, gamma=3.0673, tol=0.000098, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 52 - Fold 1/5] Preparing data...\n",
      "    [Trial 52 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 52 - Fold 1] Splitting features and target...\n",
      "    [Trial 52 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 52 - Fold 1] Training SVM model...\n",
      "    [Trial 48 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:59:35,962] Trial 50 finished with value: 0.3102708924797105 and parameters: {'kernel': 'poly', 'C': 12.549368848337386, 'gamma': 0.010001624749024954, 'class_weight': None, 'shrinking': True, 'tol': 0.0010907766125563846, 'coef0': 3.070977283219547, 'degree': 2}. Best is trial 47 with value: 0.31046898485006846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 50 - Fold 5] F1-Score: 0.3125\n",
      "    [Trial 50 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 50] Mean F1-Score across all folds: 0.3103\n",
      "\n",
      "[Trial 53] Starting with parameters: kernel=poly, C=28.9998, gamma=2.7264, tol=0.000087, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 53 - Fold 1/5] Preparing data...\n",
      "    [Trial 53 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 53 - Fold 1] Splitting features and target...\n",
      "    [Trial 53 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 53 - Fold 1] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 18:59:38,096] Trial 48 finished with value: 0.3094733552349082 and parameters: {'kernel': 'poly', 'C': 16.309357093912443, 'gamma': 0.010936926255844288, 'class_weight': None, 'shrinking': True, 'tol': 0.00018338224386875679, 'coef0': 2.7507084209941155, 'degree': 2}. Best is trial 47 with value: 0.31046898485006846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 48 - Fold 5] F1-Score: 0.3146\n",
      "    [Trial 48 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 48] Mean F1-Score across all folds: 0.3095\n",
      "\n",
      "[Trial 54] Starting with parameters: kernel=sigmoid, C=37.4596, gamma=2.5496, tol=0.000254, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 54 - Fold 1/5] Preparing data...\n",
      "    [Trial 54 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 54 - Fold 1] Splitting features and target...\n",
      "    [Trial 54 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 54 - Fold 1] Training SVM model...\n",
      "    [Trial 54 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:00:08,408] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 54 - Fold 1] F1-Score: 0.1164\n",
      "    [Trial 54 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.61      0.75     20479\n",
      "         1.0       0.07      0.47      0.12      1200\n",
      "\n",
      "    accuracy                           0.61     21679\n",
      "   macro avg       0.51      0.54      0.43     21679\n",
      "weighted avg       0.90      0.61      0.71     21679\n",
      "\n",
      "    [Trial 54] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 55] Starting with parameters: kernel=poly, C=2.1100, gamma=0.2125, tol=0.000117, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 55 - Fold 1/5] Preparing data...\n",
      "    [Trial 55 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 55 - Fold 1] Splitting features and target...\n",
      "    [Trial 55 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 55 - Fold 1] Training SVM model...\n",
      "    [Trial 44 - Fold 2] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:00:13,926] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 44 - Fold 2] F1-Score: 0.2967\n",
      "    [Trial 44 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.24      0.39      0.30      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 44] Trial pruned after Fold 2\n",
      "\n",
      "[Trial 56] Starting with parameters: kernel=poly, C=10.9533, gamma=0.0818, tol=0.000059, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 56 - Fold 1/5] Preparing data...\n",
      "    [Trial 56 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 56 - Fold 1] Splitting features and target...\n",
      "    [Trial 56 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 56 - Fold 1] Training SVM model...\n",
      "    [Trial 56 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 53 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:01:28,893] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 53 - Fold 1] F1-Score: 0.2138\n",
      "    [Trial 53 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     20479\n",
      "         1.0       0.15      0.40      0.21      1200\n",
      "\n",
      "    accuracy                           0.84     21679\n",
      "   macro avg       0.55      0.63      0.56     21679\n",
      "weighted avg       0.92      0.84      0.87     21679\n",
      "\n",
      "    [Trial 53] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 57] Starting with parameters: kernel=poly, C=2.0348, gamma=0.0768, tol=0.002862, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 57 - Fold 1/5] Preparing data...\n",
      "    [Trial 57 - Fold 1] Sampling 10% of training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:01:29,479] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 57 - Fold 1] Splitting features and target...\n",
      "    [Trial 57 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 57 - Fold 1] Training SVM model...\n",
      "    [Trial 56 - Fold 1] F1-Score: 0.2418\n",
      "    [Trial 56 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.89      0.92     20479\n",
      "         1.0       0.17      0.40      0.24      1200\n",
      "\n",
      "    accuracy                           0.86     21679\n",
      "   macro avg       0.57      0.64      0.58     21679\n",
      "weighted avg       0.92      0.86      0.89     21679\n",
      "\n",
      "    [Trial 56] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 58] Starting with parameters: kernel=poly, C=2.3258, gamma=0.0146, tol=0.003113, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 58 - Fold 1/5] Preparing data...\n",
      "    [Trial 58 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 58 - Fold 1] Splitting features and target...\n",
      "    [Trial 58 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 58 - Fold 1] Training SVM model...\n",
      "    [Trial 55 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 55 - Fold 1] F1-Score: 0.2766\n",
      "    [Trial 55 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "\n",
      "  [Trial 55 - Fold 2/5] Preparing data...\n",
      "    [Trial 55 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 55 - Fold 2] Splitting features and target...\n",
      "    [Trial 55 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 55 - Fold 2] Training SVM model...\n",
      "    [Trial 58 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 52 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 57 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 52 - Fold 1] F1-Score: 0.2117\n",
      "    [Trial 52 - Fold 1] Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:01:45,316] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     20479\n",
      "         1.0       0.14      0.40      0.21      1200\n",
      "\n",
      "    accuracy                           0.84     21679\n",
      "   macro avg       0.55      0.63      0.56     21679\n",
      "weighted avg       0.92      0.84      0.87     21679\n",
      "\n",
      "    [Trial 52] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 59] Starting with parameters: kernel=poly, C=5.8713, gamma=0.0169, tol=0.003092, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 59 - Fold 1/5] Preparing data...\n",
      "    [Trial 59 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 59 - Fold 1] Splitting features and target...\n",
      "    [Trial 59 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 59 - Fold 1] Training SVM model...\n",
      "    [Trial 58 - Fold 1] F1-Score: 0.2910\n",
      "    [Trial 58 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 58 - Fold 2/5] Preparing data...\n",
      "    [Trial 58 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 58 - Fold 2] Splitting features and target...\n",
      "    [Trial 58 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 58 - Fold 2] Training SVM model...\n",
      "    [Trial 57 - Fold 1] F1-Score: 0.2862\n",
      "    [Trial 57 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.60      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 57 - Fold 2/5] Preparing data...\n",
      "    [Trial 57 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 57 - Fold 2] Splitting features and target...\n",
      "    [Trial 57 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 57 - Fold 2] Training SVM model...\n",
      "    [Trial 58 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 59 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 58 - Fold 2] F1-Score: 0.3252\n",
      "    [Trial 58 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20479\n",
      "         1.0       0.26      0.43      0.33      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 58 - Fold 3/5] Preparing data...\n",
      "    [Trial 58 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 58 - Fold 3] Splitting features and target...\n",
      "    [Trial 58 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 58 - Fold 3] Training SVM model...\n",
      "    [Trial 59 - Fold 1] F1-Score: 0.2923\n",
      "    [Trial 59 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 59 - Fold 2/5] Preparing data...\n",
      "    [Trial 59 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 59 - Fold 2] Splitting features and target...\n",
      "    [Trial 59 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 59 - Fold 2] Training SVM model...\n",
      "    [Trial 57 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 57 - Fold 2] F1-Score: 0.3139\n",
      "    [Trial 57 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 57 - Fold 3/5] Preparing data...\n",
      "    [Trial 57 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 57 - Fold 3] Splitting features and target...\n",
      "    [Trial 57 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 57 - Fold 3] Training SVM model...\n",
      "    [Trial 58 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 58 - Fold 3] F1-Score: 0.2965\n",
      "    [Trial 58 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.24      0.38      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 58 - Fold 4/5] Preparing data...\n",
      "    [Trial 58 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 58 - Fold 4] Splitting features and target...\n",
      "    [Trial 58 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 58 - Fold 4] Training SVM model...\n",
      "    [Trial 59 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 59 - Fold 2] F1-Score: 0.3169\n",
      "    [Trial 59 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.42      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 59 - Fold 3/5] Preparing data...\n",
      "    [Trial 59 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 59 - Fold 3] Splitting features and target...\n",
      "    [Trial 59 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 59 - Fold 3] Training SVM model...\n",
      "    [Trial 57 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 58 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 57 - Fold 3] F1-Score: 0.3031\n",
      "    [Trial 57 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 57 - Fold 4/5] Preparing data...\n",
      "    [Trial 57 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 57 - Fold 4] Splitting features and target...\n",
      "    [Trial 57 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 57 - Fold 4] Training SVM model...\n",
      "    [Trial 58 - Fold 4] F1-Score: 0.3156\n",
      "    [Trial 58 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.42      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 58 - Fold 5/5] Preparing data...\n",
      "    [Trial 58 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 58 - Fold 5] Splitting features and target...\n",
      "    [Trial 58 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 58 - Fold 5] Training SVM model...\n",
      "    [Trial 59 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 59 - Fold 3] F1-Score: 0.3036\n",
      "    [Trial 59 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 59 - Fold 4/5] Preparing data...\n",
      "    [Trial 59 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 59 - Fold 4] Splitting features and target...\n",
      "    [Trial 59 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 59 - Fold 4] Training SVM model...\n",
      "    [Trial 58 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 55 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 57 - Fold 4] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:02:50,121] Trial 58 finished with value: 0.3064634237685674 and parameters: {'kernel': 'poly', 'C': 2.325794199279779, 'gamma': 0.014579706119558816, 'class_weight': None, 'shrinking': True, 'tol': 0.0031134747587266264, 'coef0': 2.6544014036876087, 'degree': 2}. Best is trial 47 with value: 0.31046898485006846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 58 - Fold 5] F1-Score: 0.3041\n",
      "    [Trial 58 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.41      0.30      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.60      0.67      0.62     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 58] Mean F1-Score across all folds: 0.3065\n",
      "\n",
      "[Trial 60] Starting with parameters: kernel=poly, C=5.8446, gamma=0.0334, tol=0.001082, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 60 - Fold 1/5] Preparing data...\n",
      "    [Trial 60 - Fold 1] Sampling 10% of training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:02:50,459] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 55 - Fold 2] F1-Score: 0.3006\n",
      "    [Trial 55 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.24      0.40      0.30      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 55] Trial pruned after Fold 2\n",
      "    [Trial 60 - Fold 1] Splitting features and target...\n",
      "\n",
      "[Trial 61] Starting with parameters: kernel=poly, C=8.5687, gamma=0.0169, tol=0.001125, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 61 - Fold 1/5] Preparing data...\n",
      "    [Trial 60 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 60 - Fold 1] Training SVM model...\n",
      "    [Trial 61 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 61 - Fold 1] Splitting features and target...\n",
      "    [Trial 61 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 61 - Fold 1] Training SVM model...\n",
      "    [Trial 57 - Fold 4] F1-Score: 0.3299\n",
      "    [Trial 57 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 57 - Fold 5/5] Preparing data...\n",
      "    [Trial 57 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 57 - Fold 5] Splitting features and target...\n",
      "    [Trial 57 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 57 - Fold 5] Training SVM model...\n",
      "    [Trial 59 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 59 - Fold 4] F1-Score: 0.3239\n",
      "    [Trial 59 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 59 - Fold 5/5] Preparing data...\n",
      "    [Trial 59 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 59 - Fold 5] Splitting features and target...\n",
      "    [Trial 59 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 59 - Fold 5] Training SVM model...\n",
      "    [Trial 60 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 57 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 60 - Fold 1] F1-Score: 0.2866\n",
      "    [Trial 60 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 60 - Fold 2/5] Preparing data...\n",
      "    [Trial 60 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 60 - Fold 2] Splitting features and target...\n",
      "    [Trial 60 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 60 - Fold 2] Training SVM model...\n",
      "    [Trial 61 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 59 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:03:15,019] Trial 57 finished with value: 0.30894601177102243 and parameters: {'kernel': 'poly', 'C': 2.03478534695966, 'gamma': 0.07678518912726913, 'class_weight': None, 'shrinking': True, 'tol': 0.002861788696465133, 'coef0': 1.1178229977626546, 'degree': 2}. Best is trial 47 with value: 0.31046898485006846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 57 - Fold 5] F1-Score: 0.3117\n",
      "    [Trial 57 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 57] Mean F1-Score across all folds: 0.3089\n",
      "\n",
      "[Trial 62] Starting with parameters: kernel=poly, C=6.0232, gamma=0.0350, tol=0.001036, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 62 - Fold 1/5] Preparing data...\n",
      "    [Trial 62 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 62 - Fold 1] Splitting features and target...\n",
      "    [Trial 62 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 62 - Fold 1] Training SVM model...\n",
      "    [Trial 61 - Fold 1] F1-Score: 0.2862\n",
      "    [Trial 61 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 61 - Fold 2/5] Preparing data...\n",
      "    [Trial 61 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 61 - Fold 2] Splitting features and target...\n",
      "    [Trial 61 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 61 - Fold 2] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:03:19,846] Trial 59 finished with value: 0.3096253888200648 and parameters: {'kernel': 'poly', 'C': 5.871292278116318, 'gamma': 0.016911155184144298, 'class_weight': None, 'shrinking': True, 'tol': 0.003091738411667091, 'coef0': 2.5895247752435577, 'degree': 2}. Best is trial 47 with value: 0.31046898485006846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 59 - Fold 5] F1-Score: 0.3113\n",
      "    [Trial 59 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 59] Mean F1-Score across all folds: 0.3096\n",
      "\n",
      "[Trial 63] Starting with parameters: kernel=poly, C=9.1541, gamma=0.0320, tol=0.001974, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 63 - Fold 1/5] Preparing data...\n",
      "    [Trial 63 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 63 - Fold 1] Splitting features and target...\n",
      "    [Trial 63 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 63 - Fold 1] Training SVM model...\n",
      "    [Trial 60 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 60 - Fold 2] F1-Score: 0.3141\n",
      "    [Trial 60 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 60 - Fold 3/5] Preparing data...\n",
      "    [Trial 60 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 60 - Fold 3] Splitting features and target...\n",
      "    [Trial 60 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 60 - Fold 3] Training SVM model...\n",
      "    [Trial 62 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 62 - Fold 1] F1-Score: 0.2897\n",
      "    [Trial 62 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 62 - Fold 2/5] Preparing data...\n",
      "    [Trial 62 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 62 - Fold 2] Splitting features and target...\n",
      "    [Trial 62 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 62 - Fold 2] Training SVM model...\n",
      "    [Trial 61 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 61 - Fold 2] F1-Score: 0.3124\n",
      "    [Trial 61 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 61 - Fold 3/5] Preparing data...\n",
      "    [Trial 61 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 61 - Fold 3] Splitting features and target...\n",
      "    [Trial 61 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 61 - Fold 3] Training SVM model...\n",
      "    [Trial 60 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 60 - Fold 3] F1-Score: 0.3064\n",
      "    [Trial 60 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 60 - Fold 4/5] Preparing data...\n",
      "    [Trial 60 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 60 - Fold 4] Splitting features and target...\n",
      "    [Trial 60 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 60 - Fold 4] Training SVM model...\n",
      "    [Trial 63 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 63 - Fold 1] F1-Score: 0.2906\n",
      "    [Trial 63 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 63 - Fold 2/5] Preparing data...\n",
      "    [Trial 63 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 63 - Fold 2] Splitting features and target...\n",
      "    [Trial 63 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 63 - Fold 2] Training SVM model...\n",
      "    [Trial 62 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 62 - Fold 2] F1-Score: 0.3140\n",
      "    [Trial 62 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 62 - Fold 3/5] Preparing data...\n",
      "    [Trial 62 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 62 - Fold 3] Splitting features and target...\n",
      "    [Trial 62 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 62 - Fold 3] Training SVM model...\n",
      "    [Trial 61 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 60 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 61 - Fold 3] F1-Score: 0.3033\n",
      "    [Trial 61 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 61 - Fold 4/5] Preparing data...\n",
      "    [Trial 61 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 61 - Fold 4] Splitting features and target...\n",
      "    [Trial 61 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 61 - Fold 4] Training SVM model...\n",
      "    [Trial 60 - Fold 4] F1-Score: 0.3320\n",
      "    [Trial 60 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.69      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 60 - Fold 5/5] Preparing data...\n",
      "    [Trial 60 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 60 - Fold 5] Splitting features and target...\n",
      "    [Trial 60 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 60 - Fold 5] Training SVM model...\n",
      "    [Trial 62 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 63 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 60 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 62 - Fold 3] F1-Score: 0.3040\n",
      "    [Trial 62 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 62 - Fold 4/5] Preparing data...\n",
      "    [Trial 62 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 62 - Fold 4] Splitting features and target...\n",
      "    [Trial 62 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 62 - Fold 4] Training SVM model...\n",
      "    [Trial 63 - Fold 2] F1-Score: 0.3111\n",
      "    [Trial 63 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.40      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 63 - Fold 3/5] Preparing data...\n",
      "    [Trial 63 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 63 - Fold 3] Splitting features and target...\n",
      "    [Trial 63 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 63 - Fold 3] Training SVM model...\n",
      "    [Trial 60 - Fold 5] F1-Score: 0.3185\n",
      "    [Trial 60 - Fold 5] Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:04:32,236] Trial 60 finished with value: 0.3115152805519068 and parameters: {'kernel': 'poly', 'C': 5.84460479286567, 'gamma': 0.033393759601115645, 'class_weight': None, 'shrinking': True, 'tol': 0.001081756235318734, 'coef0': 0.9970851684650713, 'degree': 2}. Best is trial 60 with value: 0.3115152805519068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.44      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 60] Mean F1-Score across all folds: 0.3115\n",
      "\n",
      "[Trial 64] Starting with parameters: kernel=sigmoid, C=85.6692, gamma=0.9242, tol=0.001125, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 64 - Fold 1/5] Preparing data...\n",
      "    [Trial 64 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 64 - Fold 1] Splitting features and target...\n",
      "    [Trial 64 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 64 - Fold 1] Training SVM model...\n",
      "    [Trial 61 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 61 - Fold 4] F1-Score: 0.3248\n",
      "    [Trial 61 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 61 - Fold 5/5] Preparing data...\n",
      "    [Trial 61 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 61 - Fold 5] Splitting features and target...\n",
      "    [Trial 61 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 61 - Fold 5] Training SVM model...\n",
      "    [Trial 62 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 62 - Fold 4] F1-Score: 0.3340\n",
      "    [Trial 62 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.69      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 62 - Fold 5/5] Preparing data...\n",
      "    [Trial 62 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 62 - Fold 5] Splitting features and target...\n",
      "    [Trial 62 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 62 - Fold 5] Training SVM model...\n",
      "    [Trial 64 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 63 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 61 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 63 - Fold 3] F1-Score: 0.3040\n",
      "    [Trial 63 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.41      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 63 - Fold 4/5] Preparing data...\n",
      "    [Trial 63 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 63 - Fold 4] Splitting features and target...\n",
      "    [Trial 63 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 63 - Fold 4] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:05:05,149] Trial 61 finished with value: 0.30841548097547433 and parameters: {'kernel': 'poly', 'C': 8.568705715549775, 'gamma': 0.016907169848557727, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.0011250020020746217, 'coef0': 4.96734487662374, 'degree': 2}. Best is trial 60 with value: 0.3115152805519068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 61 - Fold 5] F1-Score: 0.3155\n",
      "    [Trial 61 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 61] Mean F1-Score across all folds: 0.3084\n",
      "\n",
      "[Trial 65] Starting with parameters: kernel=poly, C=11.2758, gamma=0.0121, tol=0.001991, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 65 - Fold 1/5] Preparing data...\n",
      "    [Trial 65 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 65 - Fold 1] Splitting features and target...\n",
      "    [Trial 65 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 65 - Fold 1] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:05:09,475] Trial 64 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 64 - Fold 1] F1-Score: 0.1306\n",
      "    [Trial 64 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.62      0.75     20479\n",
      "         1.0       0.07      0.52      0.13      1200\n",
      "\n",
      "    accuracy                           0.61     21679\n",
      "   macro avg       0.52      0.57      0.44     21679\n",
      "weighted avg       0.91      0.61      0.72     21679\n",
      "\n",
      "    [Trial 64] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 66] Starting with parameters: kernel=poly, C=11.1834, gamma=0.0343, tol=0.002121, class_weight=None, shrinking=True\n",
      "\n",
      "  [Trial 66 - Fold 1/5] Preparing data...\n",
      "    [Trial 66 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 66 - Fold 1] Splitting features and target...\n",
      "    [Trial 66 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 66 - Fold 1] Training SVM model...\n",
      "    [Trial 62 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 65 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:05:18,583] Trial 62 finished with value: 0.31227989461307626 and parameters: {'kernel': 'poly', 'C': 6.023202349974428, 'gamma': 0.0349598138793687, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.001036150304536677, 'coef0': 2.4478960760505553, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 62 - Fold 5] F1-Score: 0.3198\n",
      "    [Trial 62 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.44      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 62] Mean F1-Score across all folds: 0.3123\n",
      "\n",
      "[Trial 67] Starting with parameters: kernel=poly, C=11.2803, gamma=0.0325, tol=0.001930, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 67 - Fold 1/5] Preparing data...\n",
      "    [Trial 67 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 67 - Fold 1] Splitting features and target...\n",
      "    [Trial 67 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 67 - Fold 1] Training SVM model...\n",
      "    [Trial 65 - Fold 1] F1-Score: 0.2908\n",
      "    [Trial 65 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 65 - Fold 2/5] Preparing data...\n",
      "    [Trial 65 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 65 - Fold 2] Splitting features and target...\n",
      "    [Trial 65 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 65 - Fold 2] Training SVM model...\n",
      "    [Trial 63 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 63 - Fold 4] F1-Score: 0.3332\n",
      "    [Trial 63 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 63 - Fold 5/5] Preparing data...\n",
      "    [Trial 63 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 63 - Fold 5] Splitting features and target...\n",
      "    [Trial 63 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 63 - Fold 5] Training SVM model...\n",
      "    [Trial 66 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 65 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 66 - Fold 1] F1-Score: 0.2921\n",
      "    [Trial 66 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 66 - Fold 2/5] Preparing data...\n",
      "    [Trial 66 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 66 - Fold 2] Splitting features and target...\n",
      "    [Trial 66 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 66 - Fold 2] Training SVM model...\n",
      "    [Trial 65 - Fold 2] F1-Score: 0.3178\n",
      "    [Trial 65 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.42      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 65 - Fold 3/5] Preparing data...\n",
      "    [Trial 65 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 65 - Fold 3] Splitting features and target...\n",
      "    [Trial 65 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 65 - Fold 3] Training SVM model...\n",
      "    [Trial 67 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 67 - Fold 1] F1-Score: 0.2924\n",
      "    [Trial 67 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 67 - Fold 2/5] Preparing data...\n",
      "    [Trial 67 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 67 - Fold 2] Splitting features and target...\n",
      "    [Trial 67 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 67 - Fold 2] Training SVM model...\n",
      "    [Trial 65 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 65 - Fold 3] F1-Score: 0.3035\n",
      "    [Trial 65 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 65 - Fold 4/5] Preparing data...\n",
      "    [Trial 65 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 65 - Fold 4] Splitting features and target...\n",
      "    [Trial 65 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 65 - Fold 4] Training SVM model...\n",
      "    [Trial 63 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 66 - Fold 2] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:06:05,883] Trial 63 finished with value: 0.31212298913857134 and parameters: {'kernel': 'poly', 'C': 9.154111135360546, 'gamma': 0.03197564312338547, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.001974215607374581, 'coef0': 4.2578887252756825, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 63 - Fold 5] F1-Score: 0.3217\n",
      "    [Trial 63 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.94     20478\n",
      "         1.0       0.25      0.44      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 63] Mean F1-Score across all folds: 0.3121\n",
      "\n",
      "[Trial 68] Starting with parameters: kernel=poly, C=10.2341, gamma=0.0324, tol=0.001877, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 68 - Fold 1/5] Preparing data...\n",
      "    [Trial 68 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 68 - Fold 1] Splitting features and target...\n",
      "    [Trial 68 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 68 - Fold 1] Training SVM model...\n",
      "    [Trial 65 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 66 - Fold 2] F1-Score: 0.3156\n",
      "    [Trial 66 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.41      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 66 - Fold 3/5] Preparing data...\n",
      "    [Trial 66 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 66 - Fold 3] Splitting features and target...\n",
      "    [Trial 66 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 66 - Fold 3] Training SVM model...\n",
      "    [Trial 65 - Fold 4] F1-Score: 0.3238\n",
      "    [Trial 65 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.26      0.43      0.32      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 65 - Fold 5/5] Preparing data...\n",
      "    [Trial 65 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 65 - Fold 5] Splitting features and target...\n",
      "    [Trial 65 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 65 - Fold 5] Training SVM model...\n",
      "    [Trial 67 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 65 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 67 - Fold 2] F1-Score: 0.3123\n",
      "    [Trial 67 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 67 - Fold 3/5] Preparing data...\n",
      "    [Trial 67 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 67 - Fold 3] Splitting features and target...\n",
      "    [Trial 67 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 67 - Fold 3] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:06:31,589] Trial 65 finished with value: 0.3095387559588248 and parameters: {'kernel': 'poly', 'C': 11.27581485545953, 'gamma': 0.0121255205262047, 'class_weight': None, 'shrinking': True, 'tol': 0.0019909111747977498, 'coef0': 1.219343862662461, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 65 - Fold 5] F1-Score: 0.3117\n",
      "    [Trial 65 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.42      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.67      0.63     21678\n",
      "weighted avg       0.92      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 65] Mean F1-Score across all folds: 0.3095\n",
      "\n",
      "[Trial 69] Starting with parameters: kernel=poly, C=21.2576, gamma=0.0357, tol=0.000595, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 69 - Fold 1/5] Preparing data...\n",
      "    [Trial 69 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 69 - Fold 1] Splitting features and target...\n",
      "    [Trial 69 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 69 - Fold 1] Training SVM model...\n",
      "    [Trial 66 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 68 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 66 - Fold 3] F1-Score: 0.3080\n",
      "    [Trial 66 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 66 - Fold 4/5] Preparing data...\n",
      "    [Trial 66 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 66 - Fold 4] Splitting features and target...\n",
      "    [Trial 66 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 66 - Fold 4] Training SVM model...\n",
      "    [Trial 68 - Fold 1] F1-Score: 0.2929\n",
      "    [Trial 68 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 68 - Fold 2/5] Preparing data...\n",
      "    [Trial 68 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 68 - Fold 2] Splitting features and target...\n",
      "    [Trial 68 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 68 - Fold 2] Training SVM model...\n",
      "    [Trial 51 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:06:48,415] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 51 - Fold 1] F1-Score: 0.2741\n",
      "    [Trial 51 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.22      0.36      0.27      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.64      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "    [Trial 51] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 70] Starting with parameters: kernel=linear, C=19.1874, gamma=0.0325, tol=0.001792, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 70 - Fold 1/5] Preparing data...\n",
      "    [Trial 70 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 70 - Fold 1] Splitting features and target...\n",
      "    [Trial 70 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 70 - Fold 1] Training SVM model...\n",
      "    [Trial 67 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 67 - Fold 3] F1-Score: 0.3066\n",
      "    [Trial 67 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 67 - Fold 4/5] Preparing data...\n",
      "    [Trial 66 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 67 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 67 - Fold 4] Splitting features and target...\n",
      "    [Trial 67 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 67 - Fold 4] Training SVM model...\n",
      "    [Trial 68 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 66 - Fold 4] F1-Score: 0.3281\n",
      "    [Trial 66 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 66 - Fold 5/5] Preparing data...\n",
      "    [Trial 66 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 66 - Fold 5] Splitting features and target...\n",
      "    [Trial 66 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 66 - Fold 5] Training SVM model...\n",
      "    [Trial 68 - Fold 2] F1-Score: 0.3107\n",
      "    [Trial 68 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.40      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 68 - Fold 3/5] Preparing data...\n",
      "    [Trial 68 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 68 - Fold 3] Splitting features and target...\n",
      "    [Trial 68 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 68 - Fold 3] Training SVM model...\n",
      "    [Trial 66 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 67 - Fold 4] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:07:44,897] Trial 66 finished with value: 0.312234055469286 and parameters: {'kernel': 'poly', 'C': 11.183363999282674, 'gamma': 0.03429481390167161, 'class_weight': None, 'shrinking': True, 'tol': 0.002121055426132039, 'coef0': 2.40630620495147, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 66 - Fold 5] F1-Score: 0.3174\n",
      "    [Trial 66 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 66] Mean F1-Score across all folds: 0.3122\n",
      "\n",
      "[Trial 71] Starting with parameters: kernel=linear, C=19.3121, gamma=0.0526, tol=0.002192, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 71 - Fold 1/5] Preparing data...\n",
      "    [Trial 71 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 71 - Fold 1] Splitting features and target...\n",
      "    [Trial 71 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 71 - Fold 1] Training SVM model...\n",
      "    [Trial 67 - Fold 4] F1-Score: 0.3289\n",
      "    [Trial 67 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 67 - Fold 5/5] Preparing data...\n",
      "    [Trial 67 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 67 - Fold 5] Splitting features and target...\n",
      "    [Trial 67 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 67 - Fold 5] Training SVM model...\n",
      "    [Trial 68 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 69 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 68 - Fold 3] F1-Score: 0.3060\n",
      "    [Trial 68 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 68 - Fold 4/5] Preparing data...\n",
      "    [Trial 68 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 68 - Fold 4] Splitting features and target...\n",
      "    [Trial 68 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 68 - Fold 4] Training SVM model...\n",
      "    [Trial 69 - Fold 1] F1-Score: 0.2836\n",
      "    [Trial 69 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.23      0.38      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 69 - Fold 2/5] Preparing data...\n",
      "    [Trial 69 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 69 - Fold 2] Splitting features and target...\n",
      "    [Trial 69 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 69 - Fold 2] Training SVM model...\n",
      "    [Trial 67 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:08:23,594] Trial 67 finished with value: 0.3112261255685412 and parameters: {'kernel': 'poly', 'C': 11.280293238199137, 'gamma': 0.0324977460025947, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.0019295118642498558, 'coef0': 4.249129816344289, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 67 - Fold 5] F1-Score: 0.3160\n",
      "    [Trial 67 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 67] Mean F1-Score across all folds: 0.3112\n",
      "\n",
      "[Trial 72] Starting with parameters: kernel=linear, C=19.0908, gamma=0.0534, tol=0.000554, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 72 - Fold 1/5] Preparing data...\n",
      "    [Trial 72 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 72 - Fold 1] Splitting features and target...\n",
      "    [Trial 72 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 72 - Fold 1] Training SVM model...\n",
      "    [Trial 68 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 68 - Fold 4] F1-Score: 0.3325\n",
      "    [Trial 68 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.44      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 68 - Fold 5/5] Preparing data...\n",
      "    [Trial 68 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 68 - Fold 5] Splitting features and target...\n",
      "    [Trial 68 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 68 - Fold 5] Training SVM model...\n",
      "    [Trial 68 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:09:01,795] Trial 68 finished with value: 0.31147986353556034 and parameters: {'kernel': 'poly', 'C': 10.234056942571375, 'gamma': 0.032444822908666536, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.0018774390173174728, 'coef0': 4.3456999680387085, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 68 - Fold 5] F1-Score: 0.3154\n",
      "    [Trial 68 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 68] Mean F1-Score across all folds: 0.3115\n",
      "\n",
      "[Trial 73] Starting with parameters: kernel=linear, C=19.7279, gamma=0.0554, tol=0.000557, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 73 - Fold 1/5] Preparing data...\n",
      "    [Trial 73 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 73 - Fold 1] Splitting features and target...\n",
      "    [Trial 73 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 73 - Fold 1] Training SVM model...\n",
      "    [Trial 69 - Fold 2] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:09:17,176] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 69 - Fold 2] F1-Score: 0.3108\n",
      "    [Trial 69 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 69] Trial pruned after Fold 2\n",
      "\n",
      "[Trial 74] Starting with parameters: kernel=linear, C=7.3720, gamma=0.0578, tol=0.001778, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 74 - Fold 1/5] Preparing data...\n",
      "    [Trial 74 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 74 - Fold 1] Splitting features and target...\n",
      "    [Trial 74 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 74 - Fold 1] Training SVM model...\n",
      "    [Trial 70 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:09:54,185] Trial 70 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 70 - Fold 1] F1-Score: 0.2346\n",
      "    [Trial 70 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.19      0.32      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.59     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "    [Trial 70] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 75] Starting with parameters: kernel=poly, C=7.2476, gamma=0.0612, tol=0.002289, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 75 - Fold 1/5] Preparing data...\n",
      "    [Trial 75 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 75 - Fold 1] Splitting features and target...\n",
      "    [Trial 75 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 75 - Fold 1] Training SVM model...\n",
      "    [Trial 74 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 71 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:10:41,312] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 74 - Fold 1] F1-Score: 0.2339\n",
      "    [Trial 74 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.19      0.32      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.59     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "    [Trial 74] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 76] Starting with parameters: kernel=poly, C=9.8158, gamma=0.0563, tol=0.002323, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 76 - Fold 1/5] Preparing data...\n",
      "    [Trial 76 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 76 - Fold 1] Splitting features and target...\n",
      "    [Trial 76 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 76 - Fold 1] Training SVM model...\n",
      "    [Trial 71 - Fold 1] F1-Score: 0.2345\n",
      "    [Trial 71 - Fold 1] Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:10:41,950] Trial 71 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.19      0.32      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.59     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "    [Trial 71] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 77] Starting with parameters: kernel=poly, C=9.7111, gamma=0.0360, tol=0.003802, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 77 - Fold 1/5] Preparing data...\n",
      "    [Trial 77 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 77 - Fold 1] Splitting features and target...\n",
      "    [Trial 77 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 77 - Fold 1] Training SVM model...\n",
      "    [Trial 75 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:11:29,479] Trial 75 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 75 - Fold 1] F1-Score: 0.2583\n",
      "    [Trial 75 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20479\n",
      "         1.0       0.19      0.40      0.26      1200\n",
      "\n",
      "    accuracy                           0.87     21679\n",
      "   macro avg       0.58      0.65      0.59     21679\n",
      "weighted avg       0.92      0.87      0.89     21679\n",
      "\n",
      "    [Trial 75] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 78] Starting with parameters: kernel=poly, C=9.6920, gamma=0.0381, tol=0.003976, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 78 - Fold 1/5] Preparing data...\n",
      "    [Trial 78 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 78 - Fold 1] Splitting features and target...\n",
      "    [Trial 78 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 78 - Fold 1] Training SVM model...\n",
      "    [Trial 72 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:11:37,896] Trial 72 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 72 - Fold 1] F1-Score: 0.2346\n",
      "    [Trial 72 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.19      0.32      0.23      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.59     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "    [Trial 72] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 79] Starting with parameters: kernel=poly, C=9.7886, gamma=0.0360, tol=0.003829, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 79 - Fold 1/5] Preparing data...\n",
      "    [Trial 79 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 79 - Fold 1] Splitting features and target...\n",
      "    [Trial 79 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 79 - Fold 1] Training SVM model...\n",
      "    [Trial 77 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 78 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:11:59,751] Trial 77 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 77 - Fold 1] F1-Score: 0.2647\n",
      "    [Trial 77 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.93     20479\n",
      "         1.0       0.20      0.39      0.26      1200\n",
      "\n",
      "    accuracy                           0.88     21679\n",
      "   macro avg       0.58      0.65      0.60     21679\n",
      "weighted avg       0.92      0.88      0.90     21679\n",
      "\n",
      "    [Trial 77] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 80] Starting with parameters: kernel=poly, C=5.8739, gamma=0.0313, tol=0.001121, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 80 - Fold 1/5] Preparing data...\n",
      "    [Trial 80 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 80 - Fold 1] Splitting features and target...\n",
      "    [Trial 80 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 80 - Fold 1] Training SVM model...\n",
      "    [Trial 78 - Fold 1] F1-Score: 0.2902\n",
      "    [Trial 78 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 78 - Fold 2/5] Preparing data...\n",
      "    [Trial 78 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 78 - Fold 2] Splitting features and target...\n",
      "    [Trial 78 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 78 - Fold 2] Training SVM model...\n",
      "    [Trial 73 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 79 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 79 - Fold 1] F1-Score: 0.2922\n",
      "    [Trial 79 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 79 - Fold 2/5] Preparing data...\n",
      "    [Trial 79 - Fold 2] Sampling 10% of training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:12:10,980] Trial 73 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 79 - Fold 2] Splitting features and target...\n",
      "    [Trial 79 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 79 - Fold 2] Training SVM model...\n",
      "    [Trial 73 - Fold 1] F1-Score: 0.2351\n",
      "    [Trial 73 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.19      0.32      0.24      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.57      0.62      0.59     21679\n",
      "weighted avg       0.92      0.89      0.90     21679\n",
      "\n",
      "    [Trial 73] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 81] Starting with parameters: kernel=poly, C=5.5101, gamma=0.0975, tol=0.001023, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 81 - Fold 1/5] Preparing data...\n",
      "    [Trial 81 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 81 - Fold 1] Splitting features and target...\n",
      "    [Trial 81 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 81 - Fold 1] Training SVM model...\n",
      "    [Trial 76 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:12:29,243] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 76 - Fold 1] F1-Score: 0.2590\n",
      "    [Trial 76 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     20479\n",
      "         1.0       0.19      0.40      0.26      1200\n",
      "\n",
      "    accuracy                           0.87     21679\n",
      "   macro avg       0.58      0.65      0.59     21679\n",
      "weighted avg       0.92      0.87      0.89     21679\n",
      "\n",
      "    [Trial 76] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 82] Starting with parameters: kernel=poly, C=5.3964, gamma=0.0311, tol=0.000990, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 82 - Fold 1/5] Preparing data...\n",
      "    [Trial 82 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 82 - Fold 1] Splitting features and target...\n",
      "    [Trial 82 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 82 - Fold 1] Training SVM model...\n",
      "    [Trial 78 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 78 - Fold 2] F1-Score: 0.3153\n",
      "    [Trial 78 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.41      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 78 - Fold 3/5] Preparing data...\n",
      "    [Trial 78 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 78 - Fold 3] Splitting features and target...\n",
      "    [Trial 78 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 78 - Fold 3] Training SVM model...\n",
      "    [Trial 79 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 79 - Fold 2] F1-Score: 0.3155\n",
      "    [Trial 79 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.41      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 79 - Fold 3/5] Preparing data...\n",
      "    [Trial 79 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 79 - Fold 3] Splitting features and target...\n",
      "    [Trial 79 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 79 - Fold 3] Training SVM model...\n",
      "    [Trial 81 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:13:11,767] Trial 81 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 81 - Fold 1] F1-Score: 0.2291\n",
      "    [Trial 81 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20479\n",
      "         1.0       0.16      0.39      0.23      1200\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.64      0.57     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "    [Trial 81] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 83] Starting with parameters: kernel=sigmoid, C=13.9459, gamma=0.0329, tol=0.000345, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 83 - Fold 1/5] Preparing data...\n",
      "    [Trial 83 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 83 - Fold 1] Splitting features and target...\n",
      "    [Trial 83 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 83 - Fold 1] Training SVM model...\n",
      "    [Trial 78 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 79 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 78 - Fold 3] F1-Score: 0.3088\n",
      "    [Trial 78 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 78 - Fold 4/5] Preparing data...\n",
      "    [Trial 78 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 78 - Fold 4] Splitting features and target...\n",
      "    [Trial 78 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 78 - Fold 4] Training SVM model...\n",
      "    [Trial 79 - Fold 3] F1-Score: 0.3077\n",
      "    [Trial 79 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 79 - Fold 4/5] Preparing data...\n",
      "    [Trial 79 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 79 - Fold 4] Splitting features and target...\n",
      "    [Trial 79 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 79 - Fold 4] Training SVM model...\n",
      "    [Trial 83 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:13:47,151] Trial 83 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 83 - Fold 1] F1-Score: 0.1011\n",
      "    [Trial 83 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.54      0.69     20479\n",
      "         1.0       0.06      0.47      0.10      1200\n",
      "\n",
      "    accuracy                           0.54     21679\n",
      "   macro avg       0.50      0.51      0.40     21679\n",
      "weighted avg       0.90      0.54      0.66     21679\n",
      "\n",
      "    [Trial 83] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 84] Starting with parameters: kernel=poly, C=23.7215, gamma=0.4124, tol=0.000132, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 84 - Fold 1/5] Preparing data...\n",
      "    [Trial 84 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 84 - Fold 1] Splitting features and target...\n",
      "    [Trial 84 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 84 - Fold 1] Training SVM model...\n",
      "    [Trial 79 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 78 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 79 - Fold 4] F1-Score: 0.3284\n",
      "    [Trial 79 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 79 - Fold 5/5] Preparing data...\n",
      "    [Trial 79 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 79 - Fold 5] Splitting features and target...\n",
      "    [Trial 79 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 79 - Fold 5] Training SVM model...\n",
      "    [Trial 78 - Fold 4] F1-Score: 0.3282\n",
      "    [Trial 78 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 78 - Fold 5/5] Preparing data...\n",
      "    [Trial 78 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 78 - Fold 5] Splitting features and target...\n",
      "    [Trial 78 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 78 - Fold 5] Training SVM model...\n",
      "    [Trial 79 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 78 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:14:27,029] Trial 79 finished with value: 0.31226942329772067 and parameters: {'kernel': 'poly', 'C': 9.788598689780606, 'gamma': 0.036047146900802435, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.0038288377494176797, 'coef0': 4.361968097929193, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 79 - Fold 5] F1-Score: 0.3175\n",
      "    [Trial 79 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 79] Mean F1-Score across all folds: 0.3123\n",
      "\n",
      "[Trial 85] Starting with parameters: kernel=poly, C=25.8564, gamma=0.0435, tol=0.001701, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 85 - Fold 1/5] Preparing data...\n",
      "    [Trial 85 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 85 - Fold 1] Splitting features and target...\n",
      "    [Trial 85 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 85 - Fold 1] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:14:30,239] Trial 78 finished with value: 0.31194149970075047 and parameters: {'kernel': 'poly', 'C': 9.69200348473291, 'gamma': 0.038127322123225414, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.0039755332360074044, 'coef0': 4.413463925867203, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 78 - Fold 5] F1-Score: 0.3172\n",
      "    [Trial 78 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 78] Mean F1-Score across all folds: 0.3119\n",
      "\n",
      "[Trial 86] Starting with parameters: kernel=poly, C=8.5106, gamma=0.0403, tol=0.006527, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 86 - Fold 1/5] Preparing data...\n",
      "    [Trial 86 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 86 - Fold 1] Splitting features and target...\n",
      "    [Trial 86 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 86 - Fold 1] Training SVM model...\n",
      "    [Trial 86 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 86 - Fold 1] F1-Score: 0.2901\n",
      "    [Trial 86 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 86 - Fold 2/5] Preparing data...\n",
      "    [Trial 86 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 86 - Fold 2] Splitting features and target...\n",
      "    [Trial 86 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 86 - Fold 2] Training SVM model...\n",
      "    [Trial 86 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 86 - Fold 2] F1-Score: 0.3161\n",
      "    [Trial 86 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.41      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 86 - Fold 3/5] Preparing data...\n",
      "    [Trial 86 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 86 - Fold 3] Splitting features and target...\n",
      "    [Trial 86 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 86 - Fold 3] Training SVM model...\n",
      "    [Trial 85 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:15:45,859] Trial 85 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 85 - Fold 1] F1-Score: 0.2843\n",
      "    [Trial 85 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.28      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.61     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 85] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 87] Starting with parameters: kernel=poly, C=2.7968, gamma=0.0307, tol=0.006535, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 87 - Fold 1/5] Preparing data...\n",
      "    [Trial 87 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 87 - Fold 1] Splitting features and target...\n",
      "    [Trial 87 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 87 - Fold 1] Training SVM model...\n",
      "    [Trial 80 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 87 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 86 - Fold 3] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:16:02,772] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 80 - Fold 1] F1-Score: 0.2266\n",
      "    [Trial 80 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20479\n",
      "         1.0       0.16      0.38      0.23      1200\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.63      0.57     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "    [Trial 80] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 88] Starting with parameters: kernel=poly, C=8.3259, gamma=0.0416, tol=0.006707, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 88 - Fold 1/5] Preparing data...\n",
      "    [Trial 88 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 88 - Fold 1] Splitting features and target...\n",
      "    [Trial 88 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 88 - Fold 1] Training SVM model...\n",
      "    [Trial 87 - Fold 1] F1-Score: 0.2874\n",
      "    [Trial 87 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 87 - Fold 2/5] Preparing data...\n",
      "    [Trial 87 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 87 - Fold 2] Splitting features and target...\n",
      "    [Trial 87 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 87 - Fold 2] Training SVM model...\n",
      "    [Trial 86 - Fold 3] F1-Score: 0.3082\n",
      "    [Trial 86 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 86 - Fold 4/5] Preparing data...\n",
      "    [Trial 86 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 86 - Fold 4] Splitting features and target...\n",
      "    [Trial 86 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 86 - Fold 4] Training SVM model...\n",
      "    [Trial 82 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:16:21,316] Trial 82 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 82 - Fold 1] F1-Score: 0.2251\n",
      "    [Trial 82 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92     20479\n",
      "         1.0       0.16      0.38      0.23      1200\n",
      "\n",
      "    accuracy                           0.85     21679\n",
      "   macro avg       0.56      0.63      0.57     21679\n",
      "weighted avg       0.92      0.85      0.88     21679\n",
      "\n",
      "    [Trial 82] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 89] Starting with parameters: kernel=poly, C=8.4908, gamma=0.0741, tol=0.003914, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 89 - Fold 1/5] Preparing data...\n",
      "    [Trial 89 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 89 - Fold 1] Splitting features and target...\n",
      "    [Trial 89 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 89 - Fold 1] Training SVM model...\n",
      "    [Trial 87 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 87 - Fold 2] F1-Score: 0.3119\n",
      "    [Trial 87 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 87 - Fold 3/5] Preparing data...\n",
      "    [Trial 87 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 87 - Fold 3] Splitting features and target...\n",
      "    [Trial 87 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 87 - Fold 3] Training SVM model...\n",
      "    [Trial 88 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 88 - Fold 1] F1-Score: 0.2899\n",
      "    [Trial 88 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 88 - Fold 2/5] Preparing data...\n",
      "    [Trial 88 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 88 - Fold 2] Splitting features and target...\n",
      "    [Trial 88 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 88 - Fold 2] Training SVM model...\n",
      "    [Trial 86 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 87 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 86 - Fold 4] F1-Score: 0.3276\n",
      "    [Trial 86 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 86 - Fold 5/5] Preparing data...\n",
      "    [Trial 86 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 86 - Fold 5] Splitting features and target...\n",
      "    [Trial 86 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 86 - Fold 5] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:16:46,859] Trial 87 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 87 - Fold 3] F1-Score: 0.3019\n",
      "    [Trial 87 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.40      0.30      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 87] Trial pruned after Fold 3\n",
      "\n",
      "[Trial 90] Starting with parameters: kernel=poly, C=8.4688, gamma=0.0398, tol=0.003871, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 90 - Fold 1/5] Preparing data...\n",
      "    [Trial 90 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 90 - Fold 1] Splitting features and target...\n",
      "    [Trial 90 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 90 - Fold 1] Training SVM model...\n",
      "    [Trial 88 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 89 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 88 - Fold 2] F1-Score: 0.3156\n",
      "    [Trial 88 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.41      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 88 - Fold 3/5] Preparing data...\n",
      "    [Trial 88 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 88 - Fold 3] Splitting features and target...\n",
      "    [Trial 88 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 88 - Fold 3] Training SVM model...\n",
      "    [Trial 86 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:17:15,463] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 89 - Fold 1] F1-Score: 0.2805\n",
      "    [Trial 89 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "    [Trial 89] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 91] Starting with parameters: kernel=poly, C=15.8170, gamma=0.0433, tol=0.004011, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 91 - Fold 1/5] Preparing data...\n",
      "    [Trial 91 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 91 - Fold 1] Splitting features and target...\n",
      "    [Trial 91 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 91 - Fold 1] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:17:17,326] Trial 86 finished with value: 0.31160134932727923 and parameters: {'kernel': 'poly', 'C': 8.510614970374407, 'gamma': 0.04033825324937899, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.0065269482565643395, 'coef0': 4.756186930941842, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 86 - Fold 5] F1-Score: 0.3160\n",
      "    [Trial 86 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 86] Mean F1-Score across all folds: 0.3116\n",
      "\n",
      "[Trial 92] Starting with parameters: kernel=poly, C=6.8176, gamma=0.0400, tol=0.008733, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 92 - Fold 1/5] Preparing data...\n",
      "    [Trial 92 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 92 - Fold 1] Splitting features and target...\n",
      "    [Trial 92 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 92 - Fold 1] Training SVM model...\n",
      "    [Trial 90 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 90 - Fold 1] F1-Score: 0.2906\n",
      "    [Trial 90 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 90 - Fold 2/5] Preparing data...\n",
      "    [Trial 90 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 90 - Fold 2] Splitting features and target...\n",
      "    [Trial 90 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 90 - Fold 2] Training SVM model...\n",
      "    [Trial 88 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 92 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 88 - Fold 3] F1-Score: 0.3072\n",
      "    [Trial 88 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 88 - Fold 4/5] Preparing data...\n",
      "    [Trial 88 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 88 - Fold 4] Splitting features and target...\n",
      "    [Trial 88 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 88 - Fold 4] Training SVM model...\n",
      "    [Trial 92 - Fold 1] F1-Score: 0.2941\n",
      "    [Trial 92 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.24      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 92 - Fold 2/5] Preparing data...\n",
      "    [Trial 92 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 92 - Fold 2] Splitting features and target...\n",
      "    [Trial 92 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 92 - Fold 2] Training SVM model...\n",
      "    [Trial 91 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 90 - Fold 2] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:18:01,309] Trial 91 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 91 - Fold 1] F1-Score: 0.2834\n",
      "    [Trial 91 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.23      0.38      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "    [Trial 91] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 93] Starting with parameters: kernel=poly, C=6.8961, gamma=0.0988, tol=0.006991, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 93 - Fold 1/5] Preparing data...\n",
      "    [Trial 93 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 93 - Fold 1] Splitting features and target...\n",
      "    [Trial 93 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 93 - Fold 1] Training SVM model...\n",
      "    [Trial 90 - Fold 2] F1-Score: 0.3158\n",
      "    [Trial 90 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.41      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 90 - Fold 3/5] Preparing data...\n",
      "    [Trial 90 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 90 - Fold 3] Splitting features and target...\n",
      "    [Trial 90 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 90 - Fold 3] Training SVM model...\n",
      "    [Trial 92 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 92 - Fold 2] F1-Score: 0.3125\n",
      "    [Trial 92 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 92 - Fold 3/5] Preparing data...\n",
      "    [Trial 92 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 92 - Fold 3] Splitting features and target...\n",
      "    [Trial 92 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 92 - Fold 3] Training SVM model...\n",
      "    [Trial 88 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 88 - Fold 4] F1-Score: 0.3285\n",
      "    [Trial 88 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 88 - Fold 5/5] Preparing data...\n",
      "    [Trial 88 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 88 - Fold 5] Splitting features and target...\n",
      "    [Trial 88 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 88 - Fold 5] Training SVM model...\n",
      "    [Trial 90 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 92 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 90 - Fold 3] F1-Score: 0.3071\n",
      "    [Trial 90 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 90 - Fold 4/5] Preparing data...\n",
      "    [Trial 90 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 90 - Fold 4] Splitting features and target...\n",
      "    [Trial 90 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 90 - Fold 4] Training SVM model...\n",
      "    [Trial 92 - Fold 3] F1-Score: 0.3054\n",
      "    [Trial 92 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.24      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 92 - Fold 4/5] Preparing data...\n",
      "    [Trial 92 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 92 - Fold 4] Splitting features and target...\n",
      "    [Trial 92 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 92 - Fold 4] Training SVM model...\n",
      "    [Trial 88 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 93 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:18:56,546] Trial 88 finished with value: 0.3116347306278322 and parameters: {'kernel': 'poly', 'C': 8.325866325450566, 'gamma': 0.04157793726384448, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.0067070090837589936, 'coef0': 5.26869705372426, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 88 - Fold 5] F1-Score: 0.3171\n",
      "    [Trial 88 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 88] Mean F1-Score across all folds: 0.3116\n",
      "\n",
      "[Trial 94] Starting with parameters: kernel=poly, C=6.7644, gamma=0.4708, tol=0.008156, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 94 - Fold 1/5] Preparing data...\n",
      "    [Trial 94 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 94 - Fold 1] Splitting features and target...\n",
      "    [Trial 94 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 94 - Fold 1] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:18:57,610] Trial 93 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 93 - Fold 1] F1-Score: 0.2773\n",
      "    [Trial 93 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.22      0.37      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "    [Trial 93] Trial pruned after Fold 1\n",
      "\n",
      "[Trial 95] Starting with parameters: kernel=poly, C=11.2273, gamma=0.0394, tol=0.001509, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 95 - Fold 1/5] Preparing data...\n",
      "    [Trial 95 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 95 - Fold 1] Splitting features and target...\n",
      "    [Trial 95 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 95 - Fold 1] Training SVM model...\n",
      "    [Trial 92 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 92 - Fold 4] F1-Score: 0.3309\n",
      "    [Trial 92 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 92 - Fold 5/5] Preparing data...\n",
      "    [Trial 92 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 92 - Fold 5] Splitting features and target...\n",
      "    [Trial 92 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 92 - Fold 5] Training SVM model...\n",
      "    [Trial 90 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 90 - Fold 4] F1-Score: 0.3280\n",
      "    [Trial 90 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 90 - Fold 5/5] Preparing data...\n",
      "    [Trial 90 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 90 - Fold 5] Splitting features and target...\n",
      "    [Trial 90 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 90 - Fold 5] Training SVM model...\n",
      "    [Trial 95 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 92 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 95 - Fold 1] F1-Score: 0.2882\n",
      "    [Trial 95 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.65      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 95 - Fold 2/5] Preparing data...\n",
      "    [Trial 95 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 95 - Fold 2] Splitting features and target...\n",
      "    [Trial 95 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 95 - Fold 2] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:19:48,482] Trial 92 finished with value: 0.31165952695968907 and parameters: {'kernel': 'poly', 'C': 6.817630232042937, 'gamma': 0.03998812303606994, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.008732758057360483, 'coef0': 5.17384317071811, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 92 - Fold 5] F1-Score: 0.3154\n",
      "    [Trial 92 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 92] Mean F1-Score across all folds: 0.3117\n",
      "\n",
      "[Trial 96] Starting with parameters: kernel=poly, C=8.5059, gamma=0.0379, tol=0.008088, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 96 - Fold 1/5] Preparing data...\n",
      "    [Trial 96 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 96 - Fold 1] Splitting features and target...\n",
      "    [Trial 96 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 96 - Fold 1] Training SVM model...\n",
      "    [Trial 90 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:20:06,753] Trial 90 finished with value: 0.31178697913360687 and parameters: {'kernel': 'poly', 'C': 8.468781450204212, 'gamma': 0.03976784310738738, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.003871240167474745, 'coef0': 6.747237951037496, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 90 - Fold 5] F1-Score: 0.3175\n",
      "    [Trial 90 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 90] Mean F1-Score across all folds: 0.3118\n",
      "\n",
      "[Trial 97] Starting with parameters: kernel=poly, C=8.6453, gamma=0.0473, tol=0.009367, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 97 - Fold 1/5] Preparing data...\n",
      "    [Trial 97 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 97 - Fold 1] Splitting features and target...\n",
      "    [Trial 97 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 97 - Fold 1] Training SVM model...\n",
      "    [Trial 96 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 96 - Fold 1] F1-Score: 0.2926\n",
      "    [Trial 96 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.24      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 96 - Fold 2/5] Preparing data...\n",
      "    [Trial 96 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 96 - Fold 2] Splitting features and target...\n",
      "    [Trial 96 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 96 - Fold 2] Training SVM model...\n",
      "    [Trial 95 - Fold 2] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:20:38,713] Trial 95 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 95 - Fold 2] F1-Score: 0.3103\n",
      "    [Trial 95 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.40      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 95] Trial pruned after Fold 2\n",
      "\n",
      "[Trial 98] Starting with parameters: kernel=poly, C=4.9546, gamma=0.0480, tol=0.009263, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 98 - Fold 1/5] Preparing data...\n",
      "    [Trial 98 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 98 - Fold 1] Splitting features and target...\n",
      "    [Trial 98 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 98 - Fold 1] Training SVM model...\n",
      "    [Trial 97 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 97 - Fold 1] F1-Score: 0.2867\n",
      "    [Trial 97 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.60      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 97 - Fold 2/5] Preparing data...\n",
      "    [Trial 97 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 97 - Fold 2] Splitting features and target...\n",
      "    [Trial 97 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 97 - Fold 2] Training SVM model...\n",
      "    [Trial 96 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 96 - Fold 2] F1-Score: 0.3140\n",
      "    [Trial 96 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.26      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 96 - Fold 3/5] Preparing data...\n",
      "    [Trial 96 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 96 - Fold 3] Splitting features and target...\n",
      "    [Trial 96 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 96 - Fold 3] Training SVM model...\n",
      "    [Trial 98 - Fold 1] Evaluating on validation data...\n",
      "    [Trial 98 - Fold 1] F1-Score: 0.2932\n",
      "    [Trial 98 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.24      0.39      0.29      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.66      0.62     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 98 - Fold 2/5] Preparing data...\n",
      "    [Trial 98 - Fold 2] Sampling 10% of training data...\n",
      "    [Trial 98 - Fold 2] Splitting features and target...\n",
      "    [Trial 98 - Fold 2] Scaling data with StandardScaler...\n",
      "    [Trial 98 - Fold 2] Training SVM model...\n",
      "    [Trial 96 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 98 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 97 - Fold 2] Evaluating on validation data...\n",
      "    [Trial 96 - Fold 3] F1-Score: 0.3065\n",
      "    [Trial 96 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 96 - Fold 4/5] Preparing data...\n",
      "    [Trial 96 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 96 - Fold 4] Splitting features and target...\n",
      "    [Trial 96 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 96 - Fold 4] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:21:43,091] Trial 97 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 97 - Fold 2] F1-Score: 0.3086\n",
      "    [Trial 97 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.40      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "    [Trial 97] Trial pruned after Fold 2\n",
      "\n",
      "[Trial 99] Starting with parameters: kernel=poly, C=5.1890, gamma=0.0709, tol=0.007471, class_weight=balanced, shrinking=True\n",
      "\n",
      "  [Trial 99 - Fold 1/5] Preparing data...\n",
      "    [Trial 99 - Fold 1] Sampling 10% of training data...\n",
      "    [Trial 99 - Fold 1] Splitting features and target...\n",
      "    [Trial 99 - Fold 1] Scaling data with StandardScaler...\n",
      "    [Trial 99 - Fold 1] Training SVM model...\n",
      "    [Trial 98 - Fold 2] F1-Score: 0.3118\n",
      "    [Trial 98 - Fold 2] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     20479\n",
      "         1.0       0.25      0.41      0.31      1200\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.61      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 98 - Fold 3/5] Preparing data...\n",
      "    [Trial 98 - Fold 3] Sampling 10% of training data...\n",
      "    [Trial 98 - Fold 3] Splitting features and target...\n",
      "    [Trial 98 - Fold 3] Scaling data with StandardScaler...\n",
      "    [Trial 98 - Fold 3] Training SVM model...\n",
      "    [Trial 98 - Fold 3] Evaluating on validation data...\n",
      "    [Trial 96 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 98 - Fold 3] F1-Score: 0.3066\n",
      "    [Trial 98 - Fold 3] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20478\n",
      "         1.0       0.25      0.41      0.31      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.60      0.67      0.63     21679\n",
      "weighted avg       0.92      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 98 - Fold 4/5] Preparing data...\n",
      "    [Trial 98 - Fold 4] Sampling 10% of training data...\n",
      "    [Trial 96 - Fold 4] F1-Score: 0.3278\n",
      "    [Trial 96 - Fold 4] Classification Report:\n",
      "    [Trial 98 - Fold 4] Splitting features and target...\n",
      "    [Trial 98 - Fold 4] Scaling data with StandardScaler...\n",
      "    [Trial 98 - Fold 4] Training SVM model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 96 - Fold 5/5] Preparing data...\n",
      "    [Trial 96 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 96 - Fold 5] Splitting features and target...\n",
      "    [Trial 96 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 96 - Fold 5] Training SVM model...\n",
      "    [Trial 99 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:22:26,223] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 99 - Fold 1] F1-Score: 0.2853\n",
      "    [Trial 99 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20479\n",
      "         1.0       0.23      0.38      0.29      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.60      0.65      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "    [Trial 99] Trial pruned after Fold 1\n",
      "    [Trial 98 - Fold 4] Evaluating on validation data...\n",
      "    [Trial 96 - Fold 5] Evaluating on validation data...\n",
      "    [Trial 98 - Fold 4] F1-Score: 0.3291\n",
      "    [Trial 98 - Fold 4] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     20478\n",
      "         1.0       0.27      0.43      0.33      1201\n",
      "\n",
      "    accuracy                           0.90     21679\n",
      "   macro avg       0.62      0.68      0.64     21679\n",
      "weighted avg       0.93      0.90      0.91     21679\n",
      "\n",
      "\n",
      "  [Trial 98 - Fold 5/5] Preparing data...\n",
      "    [Trial 98 - Fold 5] Sampling 10% of training data...\n",
      "    [Trial 98 - Fold 5] Splitting features and target...\n",
      "    [Trial 98 - Fold 5] Scaling data with StandardScaler...\n",
      "    [Trial 98 - Fold 5] Training SVM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:22:47,383] Trial 96 finished with value: 0.31124511275280253 and parameters: {'kernel': 'poly', 'C': 8.505935128227337, 'gamma': 0.03791773286661385, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.008088426689371377, 'coef0': 6.480037434244414, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 96 - Fold 5] F1-Score: 0.3153\n",
      "    [Trial 96 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 96] Mean F1-Score across all folds: 0.3112\n",
      "    [Trial 98 - Fold 5] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:23:07,599] Trial 98 finished with value: 0.3114120621319823 and parameters: {'kernel': 'poly', 'C': 4.954574509974943, 'gamma': 0.04799239088530669, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.009263057627521781, 'coef0': 7.102086073530075, 'degree': 2}. Best is trial 62 with value: 0.31227989461307626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 98 - Fold 5] F1-Score: 0.3163\n",
      "    [Trial 98 - Fold 5] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94     20478\n",
      "         1.0       0.25      0.43      0.32      1200\n",
      "\n",
      "    accuracy                           0.90     21678\n",
      "   macro avg       0.61      0.68      0.63     21678\n",
      "weighted avg       0.93      0.90      0.91     21678\n",
      "\n",
      "\n",
      "[Trial 98] Mean F1-Score across all folds: 0.3114\n",
      "    [Trial 94 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 19:24:59,650] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 94 - Fold 1] F1-Score: 0.2761\n",
      "    [Trial 94 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.22      0.36      0.28      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.64      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "    [Trial 94] Trial pruned after Fold 1\n",
      "    [Trial 84 - Fold 1] Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 21:08:37,834] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Trial 84 - Fold 1] F1-Score: 0.2691\n",
      "    [Trial 84 - Fold 1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     20479\n",
      "         1.0       0.22      0.35      0.27      1200\n",
      "\n",
      "    accuracy                           0.89     21679\n",
      "   macro avg       0.59      0.64      0.61     21679\n",
      "weighted avg       0.92      0.89      0.91     21679\n",
      "\n",
      "    [Trial 84] Trial pruned after Fold 1\n",
      "\n",
      "Best result:\n",
      "Optimal parameters: {'kernel': 'poly', 'C': 6.023202349974428, 'gamma': 0.0349598138793687, 'class_weight': 'balanced', 'shrinking': True, 'tol': 0.001036150304536677, 'coef0': 2.4478960760505553, 'degree': 2}\n",
      "Best F1-Score: 0.3123\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna for hyperparameter tuning with pruning\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, n_jobs=5, timeout=6*60*60)  # Runs for ~6 hours or 100 trials\n",
    "\n",
    "# Print the best result\n",
    "print(\"\\nBest result:\")\n",
    "print(f\"Optimal parameters: {study.best_params}\")\n",
    "print(f\"Best F1-Score: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter tuning process identified a well-balanced SVM configuration using a polynomial kernel with degree 2, with other numerical hyperparameters as stated in the output above. While the F1-Score of 0.3123 once again shows significant improvement, it highlights room for further enhancement through feature engineering, alternative models, or ensemble techniques. We then utilised these hyperparameters to train our final SVM model to take a look at its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model train-test with best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this final model, we utilised the hyperparameters as stated above as well as the entire training set which includes smote_folds 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data = pd.concat(smote_folds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./transformed_data/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SVM model has been trained.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = {\n",
    "    'kernel': 'poly',\n",
    "    'C': 6.023202349974428,\n",
    "    'gamma': 0.0349598138793687,\n",
    "    'class_weight': 'balanced',\n",
    "    'shrinking': True,\n",
    "    'tol': 0.001036150304536677,\n",
    "    'coef0': 2.4478960760505553,\n",
    "    'degree': 2\n",
    "}\n",
    "\n",
    "# Prepare data\n",
    "X_train_final = full_train_data[selected_features].values  # Use the selected features\n",
    "y_train_final = full_train_data['fraud_status'].values\n",
    "\n",
    "# Standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "\n",
    "# Train final SVM\n",
    "final_svm = SVC(**best_params, random_state=42)\n",
    "final_svm.fit(X_train_scaled, y_train_final)\n",
    "\n",
    "print(\"Final SVM model has been trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.88     25535\n",
      "         1.0       0.04      0.11      0.06      1564\n",
      "\n",
      "    accuracy                           0.79     27099\n",
      "   macro avg       0.49      0.47      0.47     27099\n",
      "weighted avg       0.89      0.79      0.83     27099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "X_test = test_data[selected_features].values\n",
    "y_test = test_data['fraud_status'].values\n",
    "\n",
    "test_predictions = final_svm.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Test data classification report:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[21158  4377]\n",
      " [ 1388   176]]\n"
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "The final results, contrary to the results obtained in the base model as well as throughout the hyperparameter tuning process highlights significant shortcomings i the SVM model's ability to detect fraudulent cases. While the model performs well on the majority class, its inability to generalise to the minority class undermines its utility for this classification task. This performance indicates a bias towards the majority class and struggles with the minotrity class. The overall accuracy and weighted average F1-score are misleadingly high, driven largely by the model's performance on the majority class. Perhaps, macro average metrics provide a better indication of the model's overall ability to generalize across both classes.\n",
    "\n",
    "While (RFE) identified features that improved F1-score during tuning, the selected features may not generalize well to the unseen test data. Some important features for identifying fraud may have been excluded during feature selection, leading to poor performance on the minority class.\n",
    "\n",
    "The high F1-score during hyperparameter tuning (0.3123) might indicate overfitting to the cross-validation folds. The smaller sampled training data (10% of the full data) used during tuning may have led to an overly optimistic evaluation as well.\n",
    "\n",
    "The poor performance might also have been attributed to the synthetic distribution of our fraud class which was created using SMOTE. With only an initial 5% of fraud classes out of the entire dataset, many datapoints were created artificially. This is a limitation that will be inherent through all our models as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
