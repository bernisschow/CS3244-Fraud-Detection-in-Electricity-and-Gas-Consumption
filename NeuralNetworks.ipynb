{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS3244 Project Neural Networks\n",
    "\n",
    "This file will contain the code for the neural network model that is being used for our project. In this code, we will be approaching it using a two types of models:\n",
    "\n",
    "1. MLP\n",
    "2. RNN (LSTM)\n",
    "\n",
    "We will follow this breakdown of sequencing in how we approach the problem using neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets and packages\n",
    "\n",
    "We will begin with importing all relevant datasets and packages needed in order to create our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###WAITING FOR ROBB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice = pd.read_csv('cleaned_invoice_train_undersampled.csv')\n",
    "client = pd.read_csv('cleaned_client_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP model\n",
    "\n",
    "The MLP model is a simple feed-forward neural network model. It will use the universally used aggregated dataset that we have used for all other models. We have decided to use an MLP model as it is the best neural network model when it comes to working with our aggregated dataset. This is because RNNs work with sequential data, which the aggregated dataset does not have, and CNN works best for matrix data (images), which again we do not have.\n",
    "\n",
    "We will proceed with this flow:\n",
    "1. Feature engineering for MLP\n",
    "2. Model MLP\n",
    "3. Evaluate MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for MLP\n",
    "\n",
    "We will begin with feature engineering that is specific to the MLP model. This is because neural networks require specific altercations to the data for it to function effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###WAITING FOR ROBB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MLP model\n",
    "\n",
    "We will train the neural network on our feature engineered train dataset. Our hyperparameters will be kept fixed (for now), and we will be using the scikit-learn inbuilt function. This is because we were having problems with tensorflow and its compatibility with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MLP model\n",
    "\n",
    "We will test our model on the feature engineered test dataset. We will be using accuracy, precision, recall, F1 score, as well as a confusion matrix for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model\n",
    "\n",
    "We understand that one of the limitations of the MLP model is that it does not take into account each individual invoice of a client. This results in the loss of some information regarding the sequential nature of the invoices. Hence, for the RNN model, we plan to approach this with a non-aggregated dataset. We will follow the same data cleaning as the previous dataset, but without the aggregation and SMOTE. We will then use an RNN with weight class adjustments in order to deal with the imbalanced data.\n",
    "\n",
    "We will proceed with this flow:\n",
    "1. Feature engineering for RNN\n",
    "2. Preparing data for RNN\n",
    "3. Model RNN\n",
    "4. Evaluate RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering for RNN\n",
    "\n",
    "The RNN model uses very different feature engineering techniques compared to the MLP model, and hence we need to handle them very differerntly. We will be looking at client first before invoice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 592340 entries, 0 to 592339\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   client_id            592340 non-null  object \n",
      " 1   invoice_date         592340 non-null  object \n",
      " 2   meter_number         592340 non-null  int64  \n",
      " 3   meter_status         592340 non-null  float64\n",
      " 4   meter_code           592340 non-null  int64  \n",
      " 5   reading_remark       592340 non-null  int64  \n",
      " 6   meter_coefficient    592340 non-null  int64  \n",
      " 7   consumption_level_1  592340 non-null  int64  \n",
      " 8   consumption_level_2  592340 non-null  int64  \n",
      " 9   consumption_level_3  592340 non-null  int64  \n",
      " 10  consumption_level_4  592340 non-null  int64  \n",
      " 11  old_index            592340 non-null  int64  \n",
      " 12  new_index            592340 non-null  int64  \n",
      " 13  months_number        592340 non-null  int64  \n",
      " 14  meter_type           592340 non-null  int64  \n",
      "dtypes: float64(1), int64(12), object(2)\n",
      "memory usage: 67.8+ MB\n"
     ]
    }
   ],
   "source": [
    "invoice.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   disrict        135493 non-null  int64  \n",
      " 1   client_id      135493 non-null  object \n",
      " 2   client_catg    135493 non-null  int64  \n",
      " 3   region         135493 non-null  int64  \n",
      " 4   creation_date  135493 non-null  object \n",
      " 5   fraud_status   135493 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client\n",
    "\n",
    "Here, we will deal with the client dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creation_date breakdown\n",
    "\n",
    "We breakdown creation_date into year, month, and day in order for our model to be able to process this feature, as it will not be able to process an object or a datetime datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tq/mlzr5gb55h9flpj2ql8zgd9w0000gn/T/ipykernel_17507/1433498131.py:1: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  client['creation_date'] = pd.to_datetime(client['creation_date'])\n"
     ]
    }
   ],
   "source": [
    "client['creation_date'] = pd.to_datetime(client['creation_date'])\n",
    "client['creation_date_year'] = client['creation_date'].dt.year\n",
    "client['creation_date_month'] = client['creation_date'].dt.month\n",
    "client['creation_date_day'] = client['creation_date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop creation_date\n",
    "\n",
    "We will drop creation_date as we already have its derived features of year month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = client.drop(columns=['creation_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot encoding\n",
    "\n",
    "We will one hot encode our non ordinal categorical features. This is because we do not want our model to assume ordinality or an order in these features, hence we have to one hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ordinal_categorical_client = ['disrict', 'client_catg', \n",
    "                                  'region']\n",
    "\n",
    "client = pd.get_dummies(client, columns=non_ordinal_categorical_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label encoding\n",
    "\n",
    "We will label the features which are categorical but have an order to them. This is to reduce the number of features we will have, and for the model to potentially learn from their ordinal nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_date_year\n",
      "2010    6275\n",
      "2008    5672\n",
      "2009    5644\n",
      "2011    5492\n",
      "2013    5291\n",
      "2007    5265\n",
      "2014    5230\n",
      "2012    5148\n",
      "2016    4869\n",
      "2015    4731\n",
      "2017    4420\n",
      "2002    4406\n",
      "2018    3973\n",
      "2000    3783\n",
      "2006    3482\n",
      "2003    3206\n",
      "2004    2926\n",
      "1999    2715\n",
      "1995    2705\n",
      "1994    2685\n",
      "1998    2591\n",
      "2005    2590\n",
      "2001    2578\n",
      "1997    2561\n",
      "1996    2297\n",
      "1989    2290\n",
      "1983    2272\n",
      "1988    2268\n",
      "1985    2225\n",
      "1990    2214\n",
      "1993    2195\n",
      "1991    2182\n",
      "1986    2063\n",
      "1987    1995\n",
      "1992    1966\n",
      "1984    1918\n",
      "1980    1850\n",
      "1981    1843\n",
      "1979    1724\n",
      "1982    1685\n",
      "1977    1658\n",
      "1978    1510\n",
      "2019    1100\n",
      "Name: count, dtype: int64\n",
      "creation_date_month\n",
      "12    20249\n",
      "11    14039\n",
      "10    13525\n",
      "5     12726\n",
      "9     12240\n",
      "6     11087\n",
      "3     10389\n",
      "4      9992\n",
      "2      8538\n",
      "8      7893\n",
      "7      7840\n",
      "1      6975\n",
      "Name: count, dtype: int64\n",
      "creation_date_day\n",
      "30    6405\n",
      "29    5589\n",
      "28    5471\n",
      "31    5244\n",
      "16    5000\n",
      "21    4953\n",
      "22    4857\n",
      "27    4816\n",
      "26    4774\n",
      "19    4737\n",
      "24    4699\n",
      "13    4591\n",
      "20    4540\n",
      "14    4532\n",
      "23    4519\n",
      "18    4500\n",
      "17    4490\n",
      "7     4453\n",
      "12    4423\n",
      "8     4335\n",
      "25    4255\n",
      "10    4236\n",
      "11    4053\n",
      "15    3861\n",
      "9     3767\n",
      "6     3729\n",
      "4     3481\n",
      "5     3392\n",
      "3     2900\n",
      "1     2532\n",
      "2     2359\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ordinal_categorical_client = ['creation_date_year', 'creation_date_month', 'creation_date_day']\n",
    "\n",
    "for col in ordinal_categorical_client:\n",
    "    counts = client[col].value_counts()\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### final client\n",
    "\n",
    "We will now be able to look at the final client dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Data columns (total 37 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   client_id            135493 non-null  object \n",
      " 1   fraud_status         135493 non-null  float64\n",
      " 2   creation_date_year   135493 non-null  int32  \n",
      " 3   creation_date_month  135493 non-null  int32  \n",
      " 4   creation_date_day    135493 non-null  int32  \n",
      " 5   disrict_60           135493 non-null  bool   \n",
      " 6   disrict_62           135493 non-null  bool   \n",
      " 7   disrict_63           135493 non-null  bool   \n",
      " 8   disrict_69           135493 non-null  bool   \n",
      " 9   client_catg_11       135493 non-null  bool   \n",
      " 10  client_catg_12       135493 non-null  bool   \n",
      " 11  client_catg_51       135493 non-null  bool   \n",
      " 12  region_101           135493 non-null  bool   \n",
      " 13  region_103           135493 non-null  bool   \n",
      " 14  region_104           135493 non-null  bool   \n",
      " 15  region_105           135493 non-null  bool   \n",
      " 16  region_106           135493 non-null  bool   \n",
      " 17  region_107           135493 non-null  bool   \n",
      " 18  region_199           135493 non-null  bool   \n",
      " 19  region_206           135493 non-null  bool   \n",
      " 20  region_301           135493 non-null  bool   \n",
      " 21  region_302           135493 non-null  bool   \n",
      " 22  region_303           135493 non-null  bool   \n",
      " 23  region_304           135493 non-null  bool   \n",
      " 24  region_305           135493 non-null  bool   \n",
      " 25  region_306           135493 non-null  bool   \n",
      " 26  region_307           135493 non-null  bool   \n",
      " 27  region_308           135493 non-null  bool   \n",
      " 28  region_309           135493 non-null  bool   \n",
      " 29  region_310           135493 non-null  bool   \n",
      " 30  region_311           135493 non-null  bool   \n",
      " 31  region_312           135493 non-null  bool   \n",
      " 32  region_313           135493 non-null  bool   \n",
      " 33  region_371           135493 non-null  bool   \n",
      " 34  region_372           135493 non-null  bool   \n",
      " 35  region_379           135493 non-null  bool   \n",
      " 36  region_399           135493 non-null  bool   \n",
      "dtypes: bool(32), float64(1), int32(3), object(1)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoice\n",
    "\n",
    "Here, we will deal with the invoice dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deal with invoice_date\n",
    "\n",
    "We will convert invoice_date to the datetime format for easier processing later down the line, as this will be the determining sequential feature that we will use for the RNN modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice['invoice_date'] = pd.to_datetime(invoice['invoice_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scaling \n",
    "\n",
    "We will scale continuous variables, to ensure that all features contribute equally when it comes to the gradient descent during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumption_level_1</th>\n",
       "      <th>consumption_level_2</th>\n",
       "      <th>consumption_level_3</th>\n",
       "      <th>consumption_level_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.546812</td>\n",
       "      <td>-0.170484</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.261371</td>\n",
       "      <td>0.081647</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.480501</td>\n",
       "      <td>-0.170484</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.514465</td>\n",
       "      <td>-0.170484</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.245683</td>\n",
       "      <td>-0.170484</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592335</th>\n",
       "      <td>-0.355966</td>\n",
       "      <td>0.092610</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592336</th>\n",
       "      <td>-0.355966</td>\n",
       "      <td>-0.036197</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592337</th>\n",
       "      <td>-0.376991</td>\n",
       "      <td>-0.170484</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592338</th>\n",
       "      <td>-0.525786</td>\n",
       "      <td>-0.170484</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592339</th>\n",
       "      <td>-0.355966</td>\n",
       "      <td>0.200862</td>\n",
       "      <td>-0.151988</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592340 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        consumption_level_1  consumption_level_2  consumption_level_3  \\\n",
       "0                 -0.546812            -0.170484            -0.151988   \n",
       "1                  1.261371             0.081647            -0.151988   \n",
       "2                 -0.480501            -0.170484            -0.151988   \n",
       "3                 -0.514465            -0.170484            -0.151988   \n",
       "4                  0.245683            -0.170484            -0.151988   \n",
       "...                     ...                  ...                  ...   \n",
       "592335            -0.355966             0.092610            -0.151988   \n",
       "592336            -0.355966            -0.036197            -0.151988   \n",
       "592337            -0.376991            -0.170484            -0.151988   \n",
       "592338            -0.525786            -0.170484            -0.151988   \n",
       "592339            -0.355966             0.200862            -0.151988   \n",
       "\n",
       "        consumption_level_4  \n",
       "0                 -0.088986  \n",
       "1                 -0.088986  \n",
       "2                 -0.088986  \n",
       "3                 -0.088986  \n",
       "4                 -0.088986  \n",
       "...                     ...  \n",
       "592335            -0.088986  \n",
       "592336            -0.088986  \n",
       "592337            -0.088986  \n",
       "592338            -0.088986  \n",
       "592339            -0.088986  \n",
       "\n",
       "[592340 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_features_invoice = ['consumption_level_1', 'consumption_level_2',\n",
    "                       'consumption_level_3', 'consumption_level_4',\n",
    "                        'new_index', 'old_index']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "invoice[continuous_features_invoice] = scaler.fit_transform(invoice[continuous_features_invoice])\n",
    "invoice[continuous_features_invoice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot encoding\n",
    "\n",
    "We will similarly one hot encode the non ordinal categorical features in invoice for the same reasons as we did for client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ordinal_categorical_invoice = [ 'meter_status', 'meter_code', \n",
    "                            'reading_remark', 'meter_type',\n",
    "                            'meter_coefficient']\n",
    "\n",
    "invoice = pd.get_dummies(invoice, columns=non_ordinal_categorical_invoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label encoding\n",
    "\n",
    "We will similarly label encode the ordinal categorical features in invoice for the same reasons we did for client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meter_number\n",
      "0                5434\n",
      "84750400          217\n",
      "630283            211\n",
      "963               169\n",
      "82201             150\n",
      "                 ... \n",
      "2185800087021       1\n",
      "1044931             1\n",
      "456881              1\n",
      "32041               1\n",
      "987192              1\n",
      "Name: count, Length: 28833, dtype: int64\n",
      "new_index\n",
      "0         24357\n",
      "1           622\n",
      "2           300\n",
      "3           264\n",
      "6           216\n",
      "          ...  \n",
      "179945        1\n",
      "197412        1\n",
      "195928        1\n",
      "190770        1\n",
      "142298        1\n",
      "Name: count, Length: 83792, dtype: int64\n",
      "old_index\n",
      "0         36881\n",
      "1           646\n",
      "2           345\n",
      "3           268\n",
      "5           209\n",
      "          ...  \n",
      "84011         1\n",
      "53386         1\n",
      "48183         1\n",
      "422343        1\n",
      "141551        1\n",
      "Name: count, Length: 82542, dtype: int64\n",
      "months_number\n",
      "4         476235\n",
      "8          36479\n",
      "2          35407\n",
      "1          26958\n",
      "12          6907\n",
      "           ...  \n",
      "30060          1\n",
      "257724         1\n",
      "27795          1\n",
      "282093         1\n",
      "60             1\n",
      "Name: count, Length: 294, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ordinal_categorical_invoice = ['meter_number', 'months_number']\n",
    "\n",
    "for col in ordinal_categorical_invoice:\n",
    "    counts = invoice[col].value_counts()\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### final invoice\n",
    "\n",
    "We will now be able to look at the final invoice dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 592340 entries, 0 to 592339\n",
      "Data columns (total 57 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   client_id             592340 non-null  object        \n",
      " 1   invoice_date          592340 non-null  datetime64[ns]\n",
      " 2   meter_number          592340 non-null  int64         \n",
      " 3   consumption_level_1   592340 non-null  float64       \n",
      " 4   consumption_level_2   592340 non-null  float64       \n",
      " 5   consumption_level_3   592340 non-null  float64       \n",
      " 6   consumption_level_4   592340 non-null  float64       \n",
      " 7   old_index             592340 non-null  int64         \n",
      " 8   new_index             592340 non-null  int64         \n",
      " 9   months_number         592340 non-null  int64         \n",
      " 10  meter_status_0.0      592340 non-null  bool          \n",
      " 11  meter_status_1.0      592340 non-null  bool          \n",
      " 12  meter_status_2.0      592340 non-null  bool          \n",
      " 13  meter_status_3.0      592340 non-null  bool          \n",
      " 14  meter_status_4.0      592340 non-null  bool          \n",
      " 15  meter_code_5          592340 non-null  bool          \n",
      " 16  meter_code_10         592340 non-null  bool          \n",
      " 17  meter_code_16         592340 non-null  bool          \n",
      " 18  meter_code_25         592340 non-null  bool          \n",
      " 19  meter_code_40         592340 non-null  bool          \n",
      " 20  meter_code_101        592340 non-null  bool          \n",
      " 21  meter_code_102        592340 non-null  bool          \n",
      " 22  meter_code_201        592340 non-null  bool          \n",
      " 23  meter_code_202        592340 non-null  bool          \n",
      " 24  meter_code_203        592340 non-null  bool          \n",
      " 25  meter_code_204        592340 non-null  bool          \n",
      " 26  meter_code_207        592340 non-null  bool          \n",
      " 27  meter_code_210        592340 non-null  bool          \n",
      " 28  meter_code_214        592340 non-null  bool          \n",
      " 29  meter_code_227        592340 non-null  bool          \n",
      " 30  meter_code_307        592340 non-null  bool          \n",
      " 31  meter_code_310        592340 non-null  bool          \n",
      " 32  meter_code_403        592340 non-null  bool          \n",
      " 33  meter_code_407        592340 non-null  bool          \n",
      " 34  meter_code_410        592340 non-null  bool          \n",
      " 35  meter_code_413        592340 non-null  bool          \n",
      " 36  meter_code_420        592340 non-null  bool          \n",
      " 37  meter_code_433        592340 non-null  bool          \n",
      " 38  meter_code_442        592340 non-null  bool          \n",
      " 39  meter_code_450        592340 non-null  bool          \n",
      " 40  meter_code_453        592340 non-null  bool          \n",
      " 41  meter_code_467        592340 non-null  bool          \n",
      " 42  meter_code_483        592340 non-null  bool          \n",
      " 43  meter_code_506        592340 non-null  bool          \n",
      " 44  meter_code_532        592340 non-null  bool          \n",
      " 45  meter_code_565        592340 non-null  bool          \n",
      " 46  meter_code_600        592340 non-null  bool          \n",
      " 47  reading_remark_6      592340 non-null  bool          \n",
      " 48  reading_remark_7      592340 non-null  bool          \n",
      " 49  reading_remark_8      592340 non-null  bool          \n",
      " 50  reading_remark_9      592340 non-null  bool          \n",
      " 51  meter_type_0          592340 non-null  bool          \n",
      " 52  meter_type_1          592340 non-null  bool          \n",
      " 53  meter_coefficient_0   592340 non-null  bool          \n",
      " 54  meter_coefficient_1   592340 non-null  bool          \n",
      " 55  meter_coefficient_2   592340 non-null  bool          \n",
      " 56  meter_coefficient_10  592340 non-null  bool          \n",
      "dtypes: bool(47), datetime64[ns](1), float64(4), int64(4), object(1)\n",
      "memory usage: 71.7+ MB\n"
     ]
    }
   ],
   "source": [
    "invoice.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for RNN\n",
    "\n",
    "In order to prepare our dataset for RNN, we will need to firstly group our invoices by clients, in order of invoice date. We will then be able to extract their informational features. We also need to extract, for the client, their client data, as well as label data (fraud or not fraud). This is so that our RNN is able to use the sequential nature of invoices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get informational columns\n",
    "\n",
    "We will obtain the informational features of both invoice and clients, which as the features that we want our model to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoice feature columns\n",
    "invoice_feature_cols = invoice.columns.difference(['client_id', 'invoice_date'])\n",
    "\n",
    "# Client feature columns\n",
    "client_feature_cols = client.columns.difference(['client_id', 'fraud_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(invoice_feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(client_feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort the dataset\n",
    "\n",
    "We will sort our dataset by client_id and invoice_date, followed by grouping invoices by client_id. This helps us obtain the sequences of of invoices that the RNN will input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice = invoice.sort_values(by=['client_id', 'invoice_date'])\n",
    "grouped_invoices = invoice.groupby('client_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain max_length\n",
    "\n",
    "We need to obtain the max_length of each group (max number of invoices per client), as only then are we able to apply padding to our sequences to ensure that they are all of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = grouped_invoices.size().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create containers\n",
    "\n",
    "We will create 3 containers to store the features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_features = []\n",
    "client_features = []\n",
    "targets = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iterate each client\n",
    "\n",
    "For each client, we will select informational invoice features, pad them, and add them to invoice features, then obtain their informational client features and add them to client features, followed by adding their target to the targets container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client_id, group in grouped_invoices:\n",
    "    # Extract and pad invoice features dynamically\n",
    "    invoices_seq = group[invoice_feature_cols].values  # Select relevant columns\n",
    "    padded_invoices = np.zeros((max_length, invoices_seq.shape[1]))\n",
    "    padded_invoices[:len(invoices_seq)] = invoices_seq\n",
    "    invoice_features.append(padded_invoices)\n",
    "    \n",
    "    # Extract client features dynamically\n",
    "    client_row = client[client['client_id'] == client_id].iloc[0]\n",
    "    client_feat = client_row[client_feature_cols].values\n",
    "    client_features.append(client_feat)\n",
    "    \n",
    "    # Append target\n",
    "    targets.append(client_row['fraud_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch dataset\n",
    "\n",
    "We will create a custom pytorch dataset to wrap the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(Dataset):\n",
    "    def __init__(self, invoice_features, client_features, targets):\n",
    "        self.invoice_features = torch.tensor(invoice_features, dtype=torch.float32)\n",
    "        self.client_features = torch.tensor(client_features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'invoices': self.invoice_features[idx],\n",
    "            'clients': self.client_features[idx],\n",
    "            'target': self.targets[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FraudDataset(np.array(invoice_features), np.array(client_features), np.array(targets))\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RNN model\n",
    "\n",
    "Training the RNN model with pyTorch would require us to define a FraudRNN class. We will then set a method for forward, as well as define hyperparameters, which it will take in as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create FraudRNN class\n",
    "\n",
    "We will create the FraudRNN class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudRNN(nn.Module):\n",
    "    def __init__(self, seq_input_dim, client_input_dim, hidden_dim, output_dim, num_layers=1, dropout=0.5):\n",
    "        super(FraudRNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=seq_input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.client_dense = nn.Linear(client_input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x_seq, x_client):\n",
    "        _, (h_n, _) = self.lstm(x_seq)\n",
    "        lstm_out = h_n[-1]\n",
    "        client_out = torch.relu(self.client_dense(x_client))\n",
    "        combined = torch.cat((lstm_out, client_out), dim=1)\n",
    "        output = self.sigmoid(self.fc(combined))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model, criterion and optimizer.\n",
    "\n",
    "We will then create our model with fixed hyperparameters, while setting a criterion for the loss function and an optimizer for efficient gradient upadtes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "seq_input_dim = np.array(invoice_features).shape[2]\n",
    "client_input_dim = np.array(client_features).shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "model = FraudRNN(seq_input_dim, client_input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop\n",
    "\n",
    "Here, we will loop the training so that the model can update its weights to reduce loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_seq_batch, X_client_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_seq_batch, X_client_batch).squeeze()\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test RNN model\n",
    "\n",
    "\n",
    "We will test our model on the feature engineered RNN test dataset. We will be using accuracy, precision, recall, F1 score, as well as a confusion matrix for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
