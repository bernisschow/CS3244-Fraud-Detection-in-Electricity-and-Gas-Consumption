{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load client and invoice datasets\n",
    "client_train = pd.read_csv('data/client_train.csv')\n",
    "client_test = pd.read_csv('data/client_test.csv')\n",
    "\n",
    "invoice_train = pd.read_parquet('data/invoice_train_compressed.csv.parquet')\n",
    "invoice_test = pd.read_parquet('data/invoice_test_compressed.csv.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge client and invoice training and testing dataset\n",
    "merged_df = pd.merge(invoice_train, client_train, on='client_id', how='inner')\n",
    "\n",
    "merged_test = pd.merge(invoice_test, client_test, on='client_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   disrict  client_catg  region  tarif_type  counter_statue  reading_remarque  \\\n",
      "0        0            0       0           1               0                 6   \n",
      "1        0            0       0           1               0                 4   \n",
      "2        0            0       0           1               0                 6   \n",
      "3        0            0       0           1               0                 6   \n",
      "4        0            0       0           1               0                 7   \n",
      "\n",
      "   counter_type  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n"
     ]
    }
   ],
   "source": [
    "# Define the list of categorical columns\n",
    "categorical_columns = ['disrict', 'client_catg', 'region', 'tarif_type', \n",
    "                       'counter_statue', 'reading_remarque', 'counter_type']\n",
    "\n",
    "# Apply Label Encoding to each categorical feature\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    merged_df[col] = le.fit_transform(merged_df[col].astype(str))  # Convert to string in case there are mixed types\n",
    "    label_encoders[col] = le  # Store the encoder for potential inverse_transform\n",
    "\n",
    "# Verify the encoding\n",
    "print(merged_df[categorical_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'tarif_type', 'counter_number', 'counter_code', 'reading_remarque',\n",
    "    'counter_coefficient', 'consommation_level_1', 'consommation_level_2',\n",
    "    'consommation_level_3', 'consommation_level_4', 'old_index', 'new_index',\n",
    "    'months_number', 'disrict', 'client_catg', 'region', 'counter_statue', 'counter_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances:  3133724 \n",
      "Number of test instances:  1343025\n"
     ]
    }
   ],
   "source": [
    "# Partion the features from the class to predict\n",
    "df_X = merged_df[features]\n",
    "df_y = merged_df['target'].astype(int)  # Convert 'target' to integer (1/0)  # Convert 'Fraud'/'Not Fraud' to 1/0\n",
    "\n",
    "# Split the training data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=1)\n",
    "\n",
    "print (\"Number of training instances: \", len(X_train), \"\\nNumber of test instances: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a 5% sample of the training data for tuning\n",
    "# Ensure you sample row indices, not column indices\n",
    "sample_size = int(0.05 * len(X_train))  # 5% of the training data\n",
    "sample_indices = np.random.choice(X_train.index, sample_size, replace=False)\n",
    "\n",
    "# Use `.loc[]` for selecting rows based on indices\n",
    "X_sample = X_train.loc[sample_indices]\n",
    "y_sample = y_train.loc[sample_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9111029206455576\n",
      "Confusion Matrix:\n",
      " [[1221053   16127]\n",
      " [ 103264    2581]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95   1237180\n",
      "           1       0.14      0.02      0.04    105845\n",
      "\n",
      "    accuracy                           0.91   1343025\n",
      "   macro avg       0.53      0.51      0.50   1343025\n",
      "weighted avg       0.86      0.91      0.88   1343025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MultinomialNB model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
